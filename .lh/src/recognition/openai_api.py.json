{
    "sourceFile": "src/recognition/openai_api.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1764463354753,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1764469648942,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,8 +33,13 @@\n \r\n     config: OpenAIRecognitionConfig\r\n \r\n     def _build_url(self) -> str:\r\n+        \"\"\"\r\n+        URL для OpenAI ASR берётся из recognition.openai.base_url,\r\n+        которое задаётся в настройках (поле 'OpenAI Base URL').\r\n+        Если пользователь ничего не указал — используем дефолтный https://api.openai.com/v1.\r\n+        \"\"\"\r\n         base = (self.config.base_url or \"https://api.openai.com/v1\").rstrip(\"/\")\r\n         return f\"{base}{OPENAI_TRANSCRIBE_PATH}\"\r\n \r\n     def transcribe(self, audio: AudioData) -> str:\r\n"
                }
            ],
            "date": 1764463354753,
            "name": "Commit-0",
            "content": "from __future__ import annotations\r\n\r\nimport io\r\nfrom dataclasses import dataclass\r\nfrom typing import Any\r\n\r\nimport numpy as np\r\nimport requests  # type: ignore[import]\r\nimport soundfile as sf  # type: ignore[import]\r\nfrom loguru import logger  # type: ignore[import]\r\n\r\nfrom audio.recorder import AudioData\r\nfrom config.settings import OpenAIRecognitionConfig\r\n\r\n\r\nOPENAI_TRANSCRIBE_PATH = \"/audio/transcriptions\"\r\n\r\n\r\n@dataclass\r\nclass OpenAIWhisperRecognizer:\r\n    \"\"\"\r\n    OpenAI Whisper recognizer.\r\n\r\n    Конвертирует AudioData в in-memory WAV и отправляет на OpenAI-совместимый\r\n    endpoint (base_url из конфига + /audio/transcriptions).\r\n\r\n    Использует:\r\n      - recognition.openai.api_key\r\n      - recognition.openai.model\r\n      - recognition.openai.language\r\n      - recognition.openai.base_url\r\n    \"\"\"\r\n\r\n    config: OpenAIRecognitionConfig\r\n\r\n    def _build_url(self) -> str:\r\n        base = (self.config.base_url or \"https://api.openai.com/v1\").rstrip(\"/\")\r\n        return f\"{base}{OPENAI_TRANSCRIBE_PATH}\"\r\n\r\n    def transcribe(self, audio: AudioData) -> str:\r\n        wav_bytes = self._audio_to_wav_bytes(audio)\r\n\r\n        url = self._build_url()\r\n        headers = {\r\n            \"Authorization\": f\"Bearer {self.config.api_key}\",\r\n        }\r\n\r\n        files = {\r\n            \"file\": (\"audio.wav\", wav_bytes, \"audio/wav\"),\r\n        }\r\n\r\n        data = {\r\n            \"model\": self.config.model,\r\n            \"language\": self.config.language,\r\n        }\r\n\r\n        try:\r\n            resp = requests.post(\r\n                url,\r\n                headers=headers,\r\n                files=files,\r\n                data=data,\r\n                timeout=60,\r\n            )\r\n        except requests.Timeout as exc:  # type: ignore[attr-defined]\r\n            logger.exception(\"OpenAI request timeout: {}\", exc)\r\n            raise RuntimeError(\"OpenAI: превышено время ожидания ответа.\") from exc\r\n        except requests.RequestException as exc:  # type: ignore[attr-defined]\r\n            logger.exception(\"OpenAI network error: {}\", exc)\r\n            raise RuntimeError(\"OpenAI: сетевая ошибка при обращении к API.\") from exc\r\n\r\n        if resp.status_code == 401:\r\n            logger.error(\"OpenAI returned 401 Unauthorized\")\r\n            raise RuntimeError(\"OpenAI: неверный или отсутствующий API‑ключ (401).\")\r\n        if resp.status_code == 429:\r\n            logger.error(\"OpenAI returned 429 Too Many Requests\")\r\n            raise RuntimeError(\r\n                \"OpenAI: превышен лимит запросов (429). Попробуйте позже.\"\r\n            )\r\n        if not resp.ok:\r\n            logger.error(\r\n                \"OpenAI returned HTTP {}: {}\",\r\n                resp.status_code,\r\n                resp.text[:500],\r\n            )\r\n            raise RuntimeError(f\"OpenAI: ошибка сервера ({resp.status_code}).\")\r\n\r\n        try:\r\n            payload: dict[str, Any] = resp.json()\r\n        except ValueError as exc:\r\n            logger.exception(\"OpenAI JSON parse error: {}\", exc)\r\n            raise RuntimeError(\"OpenAI: не удалось разобрать ответ сервера.\") from exc\r\n\r\n        text = payload.get(\"text\", \"\")\r\n        if not isinstance(text, str):\r\n            logger.error(\"OpenAI response does not contain 'text' field: {}\", payload)\r\n            raise RuntimeError(\"OpenAI: в ответе нет поля 'text'.\")\r\n\r\n        return text\r\n\r\n    @staticmethod\r\n    def _audio_to_wav_bytes(audio: AudioData) -> bytes:\r\n        \"\"\"\r\n        Convert AudioData (float32 numpy) to WAV bytes (16kHz mono).\r\n        \"\"\"\r\n        # На всякий случай приводим к float32 numpy\r\n        samples = audio.samples\r\n        if not isinstance(samples, np.ndarray):\r\n            samples = np.asarray(samples, dtype=np.float32)\r\n        elif samples.dtype != np.float32:\r\n            samples = samples.astype(np.float32)\r\n\r\n        buf = io.BytesIO()\r\n        sf.write(buf, samples, audio.sample_rate, format=\"WAV\", subtype=\"PCM_16\")\r\n        buf.seek(0)\r\n        return buf.read()"
        }
    ]
}
{
    "sourceFile": "src/recognition/__init__.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1764289647989,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1764457739186,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,8 +4,9 @@\n \r\n from audio.recorder import AudioData\r\n from config.settings import RecognitionConfig\r\n from recognition.groq_api import GroqWhisperRecognizer\r\n+from recognition.gigaam_local import GigaAMRecognizer\r\n \r\n \r\n class IRecognizer(Protocol):\r\n     def transcribe(self, audio: AudioData) -> str:  # pragma: no cover - protocol\r\n@@ -15,13 +16,20 @@\n def create_recognizer(config: RecognitionConfig) -> IRecognizer:\r\n     \"\"\"\r\n     Factory for recognizers.\r\n \r\n-    MVP: only Groq backend is fully implemented.\r\n+    Поддерживаем три backend'а:\r\n+      - \"groq\"   — облачный Groq Whisper\r\n+      - \"openai\" — (зарезервировано, можно добавить позже)\r\n+      - \"local\"  — локальный GigaAM-v3-CTC (v2_ctc)\r\n     \"\"\"\r\n-    backend = config.backend.lower()\r\n+    backend = (config.backend or \"groq\").lower()\r\n \r\n+    if backend == \"local\":\r\n+        # Локальный GigaAM, модель фиксированная: v2_ctc\r\n+        return GigaAMRecognizer(model_name=\"v2_ctc\")\r\n+\r\n     if backend == \"groq\":\r\n         return GroqWhisperRecognizer(config.groq)\r\n \r\n-    # Fallback: use Groq even if config says otherwise, to keep MVP working.\r\n+    # Fallback: по умолчанию Groq\r\n     return GroqWhisperRecognizer(config.groq)\n\\ No newline at end of file\n"
                }
            ],
            "date": 1764289647989,
            "name": "Commit-0",
            "content": "from __future__ import annotations\r\n\r\nfrom typing import Protocol\r\n\r\nfrom audio.recorder import AudioData\r\nfrom config.settings import RecognitionConfig\r\nfrom recognition.groq_api import GroqWhisperRecognizer\r\n\r\n\r\nclass IRecognizer(Protocol):\r\n    def transcribe(self, audio: AudioData) -> str:  # pragma: no cover - protocol\r\n        ...\r\n\r\n\r\ndef create_recognizer(config: RecognitionConfig) -> IRecognizer:\r\n    \"\"\"\r\n    Factory for recognizers.\r\n\r\n    MVP: only Groq backend is fully implemented.\r\n    \"\"\"\r\n    backend = config.backend.lower()\r\n\r\n    if backend == \"groq\":\r\n        return GroqWhisperRecognizer(config.groq)\r\n\r\n    # Fallback: use Groq even if config says otherwise, to keep MVP working.\r\n    return GroqWhisperRecognizer(config.groq)"
        }
    ]
}
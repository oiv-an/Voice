{
    "sourceFile": "src/recognition/gigaam_local.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1764627434485,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1764628077552,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,16 +24,20 @@\n     \"\"\"\r\n \r\n     HF_MODEL_ID: Final[str] = \"ai-sage/GigaAM-v3\"\r\n     HF_REVISION: Final[str] = \"e2e_rnnt\"\r\n+    LONGFORM_THRESHOLD_SEC: Final[float] = 120.0\r\n \r\n-    def __init__(self, device: Optional[str] = None) -> None:\r\n+    def __init__(self, hf_token: Optional[str] = None, device: Optional[str] = None) -> None:\r\n         \"\"\"\r\n+        :param hf_token: Hugging Face токен (HF_TOKEN) для longform-распознавания.\r\n         :param device: \"cuda\" / \"cpu\" / None\r\n                        None -> автоопределение по torch.cuda.is_available().\r\n         \"\"\"\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n+        self.hf_token: str = (hf_token or \"\").strip()\r\n+\r\n         requested_device = (device or \"\").lower().strip() or None\r\n \r\n         if requested_device is None:\r\n             # Автоопределение, как в исходной версии\r\n@@ -92,19 +96,34 @@\n         \"\"\"\r\n         Принимает AudioData и возвращает текст с пунктуацией.\r\n \r\n         ВНИМАНИЕ: официальный API модели ожидает путь к аудиофайлу.\r\n-        Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe().\r\n+        Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe() /\r\n+        model.transcribe_longform() в зависимости от длительности.\r\n         \"\"\"\r\n         import tempfile\r\n         import soundfile as sf  # type: ignore[import]\r\n         import numpy as np  # type: ignore[import]\r\n \r\n+        # Оценка длительности аудио\r\n+        samples = audio.samples\r\n+        sample_rate = float(audio.sample_rate)\r\n+        try:\r\n+            import numpy as _np  # type: ignore[import]\r\n+\r\n+            if isinstance(samples, _np.ndarray):\r\n+                num_samples = samples.shape[0]\r\n+            else:\r\n+                num_samples = len(samples)\r\n+        except Exception:  # noqa: BLE001\r\n+            num_samples = len(samples)  # type: ignore[arg-type]\r\n+\r\n+        duration_sec = num_samples / sample_rate if sample_rate > 0 else 0.0\r\n+\r\n         # Создаём временный WAV-файл\r\n         with tempfile.TemporaryDirectory() as tmpdir:\r\n             wav_path = Path(tmpdir) / \"input.wav\"\r\n \r\n-            samples = audio.samples\r\n             if isinstance(samples, np.ndarray):\r\n                 if samples.ndim == 2 and samples.shape[1] == 1:\r\n                     samples = samples[:, 0]\r\n                 samples = samples.astype(\"float32\")\r\n@@ -117,11 +136,76 @@\n                 audio.sample_rate,\r\n                 format=\"WAV\",\r\n             )\r\n \r\n+            use_longform = duration_sec > self.LONGFORM_THRESHOLD_SEC\r\n+\r\n+            # Если аудио длинное, но токена нет — сразу даём понятную ошибку.\r\n+            if use_longform and not self.hf_token:\r\n+                msg = (\r\n+                    \"GigaAM-v3: аудио слишком длинное для обычного режима. \"\r\n+                    \"Укажите Hugging Face токен (HF_TOKEN) в настройках для поддержки длинных файлов.\"\r\n+                )\r\n+                logger.error(msg + \" Примерная длительность: {:.1f} сек.\", duration_sec)\r\n+                raise RuntimeError(msg)\r\n+\r\n             try:\r\n-                # Официальный API: модель сама читает файл и делает всю обработку\r\n-                transcription = self.model.transcribe(str(wav_path))\r\n+                if use_longform and self.hf_token:\r\n+                    logger.info(\r\n+                        \"GigaAM-v3 longform: model='{}', device='{}', duration≈{:.1f}s\",\r\n+                        self.HF_MODEL_ID,\r\n+                        self.device,\r\n+                        duration_sec,\r\n+                    )\r\n+                    transcription = self.model.transcribe_longform(\r\n+                        str(wav_path),\r\n+                        hf_token=self.hf_token,\r\n+                    )\r\n+                else:\r\n+                    try:\r\n+                        transcription = self.model.transcribe(str(wav_path))\r\n+                    except ValueError as exc:\r\n+                        # Специальный случай: слишком длинный файл для обычного режима\r\n+                        msg_text = str(exc)\r\n+                        if \"Too long wav file, use 'transcribe_longform' method.\" in msg_text:\r\n+                            if not self.hf_token:\r\n+                                user_msg = (\r\n+                                    \"GigaAM-v3: аудио слишком длинное для обычного режима. \"\r\n+                                    \"Укажите Hugging Face токен (HF_TOKEN) в настройках для поддержки длинных файлов.\"\r\n+                                )\r\n+                                logger.error(\r\n+                                    \"{} Примерная длительность: {:.1f} сек. Исходная ошибка: {}\",\r\n+                                    user_msg,\r\n+                                    duration_sec,\r\n+                                    exc,\r\n+                                )\r\n+                                raise RuntimeError(user_msg) from exc\r\n+\r\n+                            logger.warning(\r\n+                                \"GigaAM-v3: получена ошибка о слишком длинном файле, \"\r\n+                                \"повторяем распознавание в режиме longform. \"\r\n+                                \"duration≈{:.1f}s\",\r\n+                                duration_sec,\r\n+                            )\r\n+                            try:\r\n+                                transcription = self.model.transcribe_longform(\r\n+                                    str(wav_path),\r\n+                                    hf_token=self.hf_token,\r\n+                                )\r\n+                            except Exception as lf_exc:  # noqa: BLE001\r\n+                                logger.exception(\r\n+                                    \"GigaAM-v3 longform transcribe error after fallback: {}\", lf_exc\r\n+                                )\r\n+                                raise RuntimeError(\r\n+                                    \"GigaAM-v3: ошибка longform-распознавания.\"\r\n+                                ) from lf_exc\r\n+                        else:\r\n+                            logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n+                            raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n+                # Конец основного try\r\n+            except RuntimeError:\r\n+                # Уже обёрнуто и залогировано выше — просто пробрасываем дальше\r\n+                raise\r\n             except Exception as exc:  # noqa: BLE001\r\n                 logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n                 raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n \r\n"
                },
                {
                    "date": 1764628443164,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,12 +155,11 @@\n                         self.HF_MODEL_ID,\r\n                         self.device,\r\n                         duration_sec,\r\n                     )\r\n-                    transcription = self.model.transcribe_longform(\r\n-                        str(wav_path),\r\n-                        hf_token=self.hf_token,\r\n-                    )\r\n+                    # Официальный API transcribe_longform не принимает hf_token как аргумент.\r\n+                    # Токен используется самим HF/transformers через окружение/кэш.\r\n+                    transcription = self.model.transcribe_longform(str(wav_path))\r\n                 else:\r\n                     try:\r\n                         transcription = self.model.transcribe(str(wav_path))\r\n                     except ValueError as exc:\r\n@@ -186,12 +185,10 @@\n                                 \"duration≈{:.1f}s\",\r\n                                 duration_sec,\r\n                             )\r\n                             try:\r\n-                                transcription = self.model.transcribe_longform(\r\n-                                    str(wav_path),\r\n-                                    hf_token=self.hf_token,\r\n-                                )\r\n+                                # Официальный API transcribe_longform не принимает hf_token\r\n+                                transcription = self.model.transcribe_longform(str(wav_path))\r\n                             except Exception as lf_exc:  # noqa: BLE001\r\n                                 logger.exception(\r\n                                     \"GigaAM-v3 longform transcribe error after fallback: {}\", lf_exc\r\n                                 )\r\n"
                },
                {
                    "date": 1764628665855,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -157,9 +157,33 @@\n                         duration_sec,\r\n                     )\r\n                     # Официальный API transcribe_longform не принимает hf_token как аргумент.\r\n                     # Токен используется самим HF/transformers через окружение/кэш.\r\n-                    transcription = self.model.transcribe_longform(str(wav_path))\r\n+                    import os as _os\r\n+\r\n+                    if not _os.environ.get(\"HF_TOKEN\"):\r\n+                        # У пользователя в настройках есть токен, но он не проброшен в окружение.\r\n+                        # Без этого GigaAM-v3 longform падает с ValueError(\"HF_TOKEN environment variable is not set\").\r\n+                        _os.environ[\"HF_TOKEN\"] = self.hf_token\r\n+\r\n+                    try:\r\n+                        transcription = self.model.transcribe_longform(str(wav_path))\r\n+                    except ValueError as lf_exc:\r\n+                        # Специальный случай: HF внутри всё ещё считает, что токена нет.\r\n+                        msg_text = str(lf_exc)\r\n+                        if \"HF_TOKEN environment variable is not set\" in msg_text:\r\n+                            user_msg = (\r\n+                                \"GigaAM-v3: для longform-распознавания требуется HF_TOKEN в окружении. \"\r\n+                                \"Проверьте, что Hugging Face токен принят на сайте и корректно установлен.\"\r\n+                            )\r\n+                            logger.error(\r\n+                                \"{} Примерная длительность: {:.1f} сек. Исходная ошибка: {}\",\r\n+                                user_msg,\r\n+                                duration_sec,\r\n+                                lf_exc,\r\n+                            )\r\n+                            raise RuntimeError(user_msg) from lf_exc\r\n+                        raise\r\n                 else:\r\n                     try:\r\n                         transcription = self.model.transcribe(str(wav_path))\r\n                     except ValueError as exc:\r\n@@ -185,10 +209,35 @@\n                                 \"duration≈{:.1f}s\",\r\n                                 duration_sec,\r\n                             )\r\n                             try:\r\n+                                import os as _os\r\n+\r\n+                                if not _os.environ.get(\"HF_TOKEN\"):\r\n+                                    _os.environ[\"HF_TOKEN\"] = self.hf_token\r\n+\r\n                                 # Официальный API transcribe_longform не принимает hf_token\r\n                                 transcription = self.model.transcribe_longform(str(wav_path))\r\n+                            except ValueError as lf_exc:\r\n+                                msg_text = str(lf_exc)\r\n+                                if \"HF_TOKEN environment variable is not set\" in msg_text:\r\n+                                    user_msg = (\r\n+                                        \"GigaAM-v3: для longform-распознавания требуется HF_TOKEN в окружении. \"\r\n+                                        \"Проверьте, что Hugging Face токен принят на сайте и корректно установлен.\"\r\n+                                    )\r\n+                                    logger.error(\r\n+                                        \"{} Примерная длительность: {:.1f} сек. Исходная ошибка: {}\",\r\n+                                        user_msg,\r\n+                                        duration_sec,\r\n+                                        lf_exc,\r\n+                                    )\r\n+                                    raise RuntimeError(user_msg) from lf_exc\r\n+                                logger.exception(\r\n+                                    \"GigaAM-v3 longform transcribe error after fallback: {}\", lf_exc\r\n+                                )\r\n+                                raise RuntimeError(\r\n+                                    \"GigaAM-v3: ошибка longform-распознавания.\"\r\n+                                ) from lf_exc\r\n                             except Exception as lf_exc:  # noqa: BLE001\r\n                                 logger.exception(\r\n                                     \"GigaAM-v3 longform transcribe error after fallback: {}\", lf_exc\r\n                                 )\r\n"
                },
                {
                    "date": 1764629417407,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,9 +24,9 @@\n     \"\"\"\r\n \r\n     HF_MODEL_ID: Final[str] = \"ai-sage/GigaAM-v3\"\r\n     HF_REVISION: Final[str] = \"e2e_rnnt\"\r\n-    LONGFORM_THRESHOLD_SEC: Final[float] = 120.0\r\n+    LONGFORM_THRESHOLD_SEC: Final[float] = 30.0\r\n \r\n     def __init__(self, hf_token: Optional[str] = None, device: Optional[str] = None) -> None:\r\n         \"\"\"\r\n         :param hf_token: Hugging Face токен (HF_TOKEN) для longform-распознавания.\r\n"
                },
                {
                    "date": 1764647601613,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,38 +10,29 @@\n \r\n \r\n class GigaAMRecognizer:\r\n     \"\"\"\r\n-    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n+    Упрощённый локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n \r\n-    Использует официальный API:\r\n-      - модель:   ai-sage/GigaAM-v3\r\n-      - revision: \"e2e_rnnt\" (лучшее качество + пунктуация)\r\n-      - встроенный метод model.transcribe(path) для распознавания\r\n-\r\n-    Требует заранее установленного окружения (см. requirements проекта):\r\n-      - torch, torchaudio, transformers, pyannote-audio, torchcodec, hydra-core,\r\n-        omegaconf, sentencepiece, ffmpeg в PATH.\r\n+    Использует только стандартный метод model.transcribe(path) без longform\r\n+    и без Hugging Face токена. Если аудио слишком длинное и модель просит\r\n+    использовать transcribe_longform, мы считаем, что локальный backend\r\n+    не справился, и даём понятную ошибку, чтобы пайплайн мог перейти на Groq.\r\n     \"\"\"\r\n \r\n     HF_MODEL_ID: Final[str] = \"ai-sage/GigaAM-v3\"\r\n     HF_REVISION: Final[str] = \"e2e_rnnt\"\r\n-    LONGFORM_THRESHOLD_SEC: Final[float] = 30.0\r\n \r\n-    def __init__(self, hf_token: Optional[str] = None, device: Optional[str] = None) -> None:\r\n+    def __init__(self, device: Optional[str] = None) -> None:\r\n         \"\"\"\r\n-        :param hf_token: Hugging Face токен (HF_TOKEN) для longform-распознавания.\r\n         :param device: \"cuda\" / \"cpu\" / None\r\n                        None -> автоопределение по torch.cuda.is_available().\r\n         \"\"\"\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        self.hf_token: str = (hf_token or \"\").strip()\r\n-\r\n         requested_device = (device or \"\").lower().strip() or None\r\n \r\n         if requested_device is None:\r\n-            # Автоопределение, как в исходной версии\r\n             self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n         elif requested_device == \"cuda\":\r\n             if torch.cuda.is_available():\r\n                 self.device = \"cuda\"\r\n@@ -68,14 +59,9 @@\n             self.HF_REVISION,\r\n             self.device,\r\n         )\r\n \r\n-        # ВАЖНО:\r\n-        # Из-за бага cuFFT на float16 и n_fft=320 (ошибка:\r\n-        #   'cuFFT only supports dimensions whose sizes are powers of two\r\n-        #    when computing in half precision, but got a signal size of [320]')\r\n-        # мы намеренно используем float32 и на GPU, и на CPU.\r\n-        # Это чуть медленнее, но полностью избавляет от падений в STFT.\r\n+        # Используем float32, чтобы избежать проблем с half precision в STFT.\r\n         torch_dtype = torch.float32\r\n \r\n         try:\r\n             self.model = AutoModel.from_pretrained(\r\n@@ -83,9 +69,8 @@\n                 revision=self.HF_REVISION,\r\n                 trust_remote_code=True,\r\n                 torch_dtype=torch_dtype,\r\n             ).to(self.device)\r\n-            # На всякий случай приводим модель к нужному dtype ещё раз\r\n             self.model = self.model.to(dtype=torch_dtype, device=self.device)\r\n         except Exception as exc:  # noqa: BLE001\r\n             logger.exception(\"Failed to load GigaAM-v3 model: {}\", exc)\r\n             raise RuntimeError(\"GigaAM-v3: ошибка загрузки модели.\") from exc\r\n@@ -96,31 +81,16 @@\n         \"\"\"\r\n         Принимает AudioData и возвращает текст с пунктуацией.\r\n \r\n         ВНИМАНИЕ: официальный API модели ожидает путь к аудиофайлу.\r\n-        Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe() /\r\n-        model.transcribe_longform() в зависимости от длительности.\r\n+        Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe().\r\n         \"\"\"\r\n         import tempfile\r\n         import soundfile as sf  # type: ignore[import]\r\n         import numpy as np  # type: ignore[import]\r\n \r\n-        # Оценка длительности аудио\r\n         samples = audio.samples\r\n-        sample_rate = float(audio.sample_rate)\r\n-        try:\r\n-            import numpy as _np  # type: ignore[import]\r\n \r\n-            if isinstance(samples, _np.ndarray):\r\n-                num_samples = samples.shape[0]\r\n-            else:\r\n-                num_samples = len(samples)\r\n-        except Exception:  # noqa: BLE001\r\n-            num_samples = len(samples)  # type: ignore[arg-type]\r\n-\r\n-        duration_sec = num_samples / sample_rate if sample_rate > 0 else 0.0\r\n-\r\n-        # Создаём временный WAV-файл\r\n         with tempfile.TemporaryDirectory() as tmpdir:\r\n             wav_path = Path(tmpdir) / \"input.wav\"\r\n \r\n             if isinstance(samples, np.ndarray):\r\n@@ -136,122 +106,25 @@\n                 audio.sample_rate,\r\n                 format=\"WAV\",\r\n             )\r\n \r\n-            use_longform = duration_sec > self.LONGFORM_THRESHOLD_SEC\r\n-\r\n-            # Если аудио длинное, но токена нет — сразу даём понятную ошибку.\r\n-            if use_longform and not self.hf_token:\r\n-                msg = (\r\n-                    \"GigaAM-v3: аудио слишком длинное для обычного режима. \"\r\n-                    \"Укажите Hugging Face токен (HF_TOKEN) в настройках для поддержки длинных файлов.\"\r\n-                )\r\n-                logger.error(msg + \" Примерная длительность: {:.1f} сек.\", duration_sec)\r\n-                raise RuntimeError(msg)\r\n-\r\n             try:\r\n-                if use_longform and self.hf_token:\r\n-                    logger.info(\r\n-                        \"GigaAM-v3 longform: model='{}', device='{}', duration≈{:.1f}s\",\r\n-                        self.HF_MODEL_ID,\r\n-                        self.device,\r\n-                        duration_sec,\r\n+                transcription = self.model.transcribe(str(wav_path))\r\n+            except ValueError as exc:\r\n+                msg_text = str(exc)\r\n+                # Специальный случай: модель просит использовать longform.\r\n+                if \"Too long wav file, use 'transcribe_longform' method.\" in msg_text:\r\n+                    logger.error(\r\n+                        \"GigaAM-v3: аудио слишком длинное для локального режима без longform. \"\r\n+                        \"Локальный backend пропускаем, даём шанс Groq/OpenAI. Исходная ошибка: {}\",\r\n+                        exc,\r\n                     )\r\n-                    # Официальный API transcribe_longform не принимает hf_token как аргумент.\r\n-                    # Токен используется самим HF/transformers через окружение/кэш.\r\n-                    import os as _os\r\n+                    raise RuntimeError(\r\n+                        \"GigaAM-v3: аудио слишком длинное для локального режима без longform.\"\r\n+                    ) from exc\r\n \r\n-                    if not _os.environ.get(\"HF_TOKEN\"):\r\n-                        # У пользователя в настройках есть токен, но он не проброшен в окружение.\r\n-                        # Без этого GigaAM-v3 longform падает с ValueError(\"HF_TOKEN environment variable is not set\").\r\n-                        _os.environ[\"HF_TOKEN\"] = self.hf_token\r\n-\r\n-                    try:\r\n-                        transcription = self.model.transcribe_longform(str(wav_path))\r\n-                    except ValueError as lf_exc:\r\n-                        # Специальный случай: HF внутри всё ещё считает, что токена нет.\r\n-                        msg_text = str(lf_exc)\r\n-                        if \"HF_TOKEN environment variable is not set\" in msg_text:\r\n-                            user_msg = (\r\n-                                \"GigaAM-v3: для longform-распознавания требуется HF_TOKEN в окружении. \"\r\n-                                \"Проверьте, что Hugging Face токен принят на сайте и корректно установлен.\"\r\n-                            )\r\n-                            logger.error(\r\n-                                \"{} Примерная длительность: {:.1f} сек. Исходная ошибка: {}\",\r\n-                                user_msg,\r\n-                                duration_sec,\r\n-                                lf_exc,\r\n-                            )\r\n-                            raise RuntimeError(user_msg) from lf_exc\r\n-                        raise\r\n-                else:\r\n-                    try:\r\n-                        transcription = self.model.transcribe(str(wav_path))\r\n-                    except ValueError as exc:\r\n-                        # Специальный случай: слишком длинный файл для обычного режима\r\n-                        msg_text = str(exc)\r\n-                        if \"Too long wav file, use 'transcribe_longform' method.\" in msg_text:\r\n-                            if not self.hf_token:\r\n-                                user_msg = (\r\n-                                    \"GigaAM-v3: аудио слишком длинное для обычного режима. \"\r\n-                                    \"Укажите Hugging Face токен (HF_TOKEN) в настройках для поддержки длинных файлов.\"\r\n-                                )\r\n-                                logger.error(\r\n-                                    \"{} Примерная длительность: {:.1f} сек. Исходная ошибка: {}\",\r\n-                                    user_msg,\r\n-                                    duration_sec,\r\n-                                    exc,\r\n-                                )\r\n-                                raise RuntimeError(user_msg) from exc\r\n-\r\n-                            logger.warning(\r\n-                                \"GigaAM-v3: получена ошибка о слишком длинном файле, \"\r\n-                                \"повторяем распознавание в режиме longform. \"\r\n-                                \"duration≈{:.1f}s\",\r\n-                                duration_sec,\r\n-                            )\r\n-                            try:\r\n-                                import os as _os\r\n-\r\n-                                if not _os.environ.get(\"HF_TOKEN\"):\r\n-                                    _os.environ[\"HF_TOKEN\"] = self.hf_token\r\n-\r\n-                                # Официальный API transcribe_longform не принимает hf_token\r\n-                                transcription = self.model.transcribe_longform(str(wav_path))\r\n-                            except ValueError as lf_exc:\r\n-                                msg_text = str(lf_exc)\r\n-                                if \"HF_TOKEN environment variable is not set\" in msg_text:\r\n-                                    user_msg = (\r\n-                                        \"GigaAM-v3: для longform-распознавания требуется HF_TOKEN в окружении. \"\r\n-                                        \"Проверьте, что Hugging Face токен принят на сайте и корректно установлен.\"\r\n-                                    )\r\n-                                    logger.error(\r\n-                                        \"{} Примерная длительность: {:.1f} сек. Исходная ошибка: {}\",\r\n-                                        user_msg,\r\n-                                        duration_sec,\r\n-                                        lf_exc,\r\n-                                    )\r\n-                                    raise RuntimeError(user_msg) from lf_exc\r\n-                                logger.exception(\r\n-                                    \"GigaAM-v3 longform transcribe error after fallback: {}\", lf_exc\r\n-                                )\r\n-                                raise RuntimeError(\r\n-                                    \"GigaAM-v3: ошибка longform-распознавания.\"\r\n-                                ) from lf_exc\r\n-                            except Exception as lf_exc:  # noqa: BLE001\r\n-                                logger.exception(\r\n-                                    \"GigaAM-v3 longform transcribe error after fallback: {}\", lf_exc\r\n-                                )\r\n-                                raise RuntimeError(\r\n-                                    \"GigaAM-v3: ошибка longform-распознавания.\"\r\n-                                ) from lf_exc\r\n-                        else:\r\n-                            logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n-                            raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n-                # Конец основного try\r\n-            except RuntimeError:\r\n-                # Уже обёрнуто и залогировано выше — просто пробрасываем дальше\r\n-                raise\r\n+                logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n+                raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n             except Exception as exc:  # noqa: BLE001\r\n                 logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n                 raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n \r\n"
                },
                {
                    "date": 1764647837668,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,15 +13,19 @@\n     \"\"\"\r\n     Упрощённый локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n \r\n     Использует только стандартный метод model.transcribe(path) без longform\r\n-    и без Hugging Face токена. Если аудио слишком длинное и модель просит\r\n-    использовать transcribe_longform, мы считаем, что локальный backend\r\n-    не справился, и даём понятную ошибку, чтобы пайплайн мог перейти на Groq.\r\n+    и без Hugging Face токена.\r\n+\r\n+    Дополнительное ограничение:\r\n+    - если длительность аудио превышает 25 секунд, локальный backend\r\n+      сразу возвращает контролируемую ошибку, чтобы пайплайн переключился\r\n+      на Groq/OpenAI.\r\n     \"\"\"\r\n \r\n     HF_MODEL_ID: Final[str] = \"ai-sage/GigaAM-v3\"\r\n     HF_REVISION: Final[str] = \"e2e_rnnt\"\r\n+    MAX_DURATION_SEC: Final[float] = 25.0\r\n \r\n     def __init__(self, device: Optional[str] = None) -> None:\r\n         \"\"\"\r\n         :param device: \"cuda\" / \"cpu\" / None\r\n@@ -82,15 +86,44 @@\n         Принимает AudioData и возвращает текст с пунктуацией.\r\n \r\n         ВНИМАНИЕ: официальный API модели ожидает путь к аудиофайлу.\r\n         Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe().\r\n+\r\n+        Дополнительно:\r\n+        - если длительность аудио > MAX_DURATION_SEC (25 сек),\r\n+          локальный backend сразу отдаёт контролируемую ошибку,\r\n+          чтобы пайплайн переключился на Groq/OpenAI.\r\n         \"\"\"\r\n         import tempfile\r\n         import soundfile as sf  # type: ignore[import]\r\n         import numpy as np  # type: ignore[import]\r\n \r\n         samples = audio.samples\r\n+        sample_rate = float(audio.sample_rate)\r\n \r\n+        # Оценка длительности\r\n+        try:\r\n+            if isinstance(samples, np.ndarray):\r\n+                num_samples = samples.shape[0]\r\n+            else:\r\n+                num_samples = len(samples)\r\n+        except Exception:  # noqa: BLE001\r\n+            num_samples = len(samples)  # type: ignore[arg-type]\r\n+\r\n+        duration_sec = num_samples / sample_rate if sample_rate > 0 else 0.0\r\n+\r\n+        # Жёсткое ограничение: всё, что длиннее 25 секунд, сразу уходит на Groq/OpenAI.\r\n+        if duration_sec > self.MAX_DURATION_SEC:\r\n+            logger.info(\r\n+                \"GigaAM-v3: длительность {:.1f}s превышает лимит {:.1f}s для локального backend'а. \"\r\n+                \"Пропускаем GigaAM и даём шанс Groq/OpenAI.\",\r\n+                duration_sec,\r\n+                self.MAX_DURATION_SEC,\r\n+            )\r\n+            raise RuntimeError(\r\n+                \"GigaAM-v3: аудио длиннее 25 секунд, используем облачный backend.\"\r\n+            )\r\n+\r\n         with tempfile.TemporaryDirectory() as tmpdir:\r\n             wav_path = Path(tmpdir) / \"input.wav\"\r\n \r\n             if isinstance(samples, np.ndarray):\r\n"
                },
                {
                    "date": 1764658814055,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -88,14 +88,53 @@\n                 \"torch_dtype\": torch_dtype,\r\n                 \"cache_dir\": cache_dir,\r\n             }\r\n \r\n-            self.model = AutoModel.from_pretrained(\r\n-                self.HF_MODEL_ID,\r\n-                **from_kwargs,\r\n-            ).to(self.device)\r\n-            # На всякий случай приводим модель к нужному dtype ещё раз\r\n-            self.model = self.model.to(dtype=torch_dtype, device=self.device)\r\n+            def _load_model() -> None:\r\n+                self.model = AutoModel.from_pretrained(\r\n+                    self.HF_MODEL_ID,\r\n+                    **from_kwargs,\r\n+                ).to(self.device)\r\n+                # На всякий случай приводим модель к нужному dtype ещё раз\r\n+                self.model = self.model.to(dtype=torch_dtype, device=self.device)\r\n+\r\n+            try:\r\n+                _load_model()\r\n+            except Exception as exc:\r\n+                msg = str(exc)\r\n+                # Типовой кейс: локальный кэш HuggingFace повреждён\r\n+                # (битый/обрубленный pytorch_model.bin и т.п.).\r\n+                if isinstance(exc, (OSError, ValueError)) and (\r\n+                    \"Unable to load weights from pytorch checkpoint file\" in msg\r\n+                    or \"Unable to locate the file\" in msg\r\n+                ):\r\n+                    logger.warning(\r\n+                        \"GigaAM-v3: локальный кэш модели повреждён, \"\r\n+                        \"очищаю {} и перезапускаю загрузку.\",\r\n+                        GIGAAM_DIR,\r\n+                    )\r\n+                    import shutil  # локальный импорт, чтобы не тянуть при импорте модуля\r\n+\r\n+                    try:\r\n+                        shutil.rmtree(GIGAAM_DIR)\r\n+                    except Exception as cleanup_exc:  # noqa: BLE001\r\n+                        logger.exception(\r\n+                            \"GigaAM-v3: не удалось удалить повреждённый кэш {}: {}\",\r\n+                            GIGAAM_DIR,\r\n+                            cleanup_exc,\r\n+                        )\r\n+\r\n+                    GIGAAM_DIR.mkdir(parents=True, exist_ok=True)\r\n+                    from_kwargs[\"cache_dir\"] = str(GIGAAM_DIR)\r\n+\r\n+                    _load_model()\r\n+                    logger.info(\r\n+                        \"GigaAM-v3: модель успешно перезаписана после очистки кэша {}\",\r\n+                        GIGAAM_DIR,\r\n+                    )\r\n+                else:\r\n+                    # Не наш кейс — пробрасываем исключение выше.\r\n+                    raise\r\n         except Exception as exc:  # noqa: BLE001\r\n             logger.exception(\"Failed to load GigaAM-v3 model from {}: {}\", GIGAAM_DIR, exc)\r\n             raise RuntimeError(\"GigaAM-v3: ошибка загрузки модели.\") from exc\r\n \r\n"
                },
                {
                    "date": 1764659374102,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,198 @@\n+from __future__ import annotations\r\n+\r\n+import sys\r\n+from pathlib import Path\r\n+from typing import Final\r\n+\r\n+from loguru import logger  # type: ignore[import]\r\n+from transformers import AutoModel  # type: ignore[import]\r\n+\r\n+from audio.recorder import AudioData\r\n+\r\n+\r\n+# Базовая директория приложения:\r\n+# - в dev-режиме: корень проекта (родитель src)\r\n+# - в собранном .exe: папка, где лежит exe\r\n+if getattr(sys, \"frozen\", False):\r\n+    _BASE_DIR: Final[Path] = Path(sys.executable).resolve().parent\r\n+else:\r\n+    _BASE_DIR = Path(__file__).resolve().parents[2]\r\n+\r\n+MODELS_DIR: Final[Path] = _BASE_DIR / \"models\"\r\n+GIGAAM_DIR: Final[Path] = MODELS_DIR / \"GigaAM-v3-e2e_rnnt\"\r\n+\r\n+\r\n+class GigaAMRecognizer:\r\n+    \"\"\"\r\n+    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n+\r\n+    Использует официальный API:\r\n+      - модель:   ai-sage/GigaAM-v3\r\n+      - revision: \"e2e_rnnt\" (лучшее качество + пунктуация)\r\n+      - встроенный метод model.transcribe(path) для распознавания\r\n+\r\n+    Требует заранее установленного окружения (см. requirements проекта):\r\n+      - torch, torchaudio, transformers, pyannote-audio, torchcodec, hydra-core, omegaconf, sentencepiece, ffmpeg в PATH.\r\n+\r\n+    ВАЖНО: веса модели хранятся в папке:\r\n+        {BASE_DIR}/models/GigaAM-v3-e2e_rnnt\r\n+\r\n+    где BASE_DIR:\r\n+      - рядом с exe в портативной сборке,\r\n+      - корень проекта при запуске из исходников.\r\n+    \"\"\"\r\n+\r\n+    HF_MODEL_ID: Final[str] = \"ai-sage/GigaAM-v3\"\r\n+    HF_REVISION: Final[str] = \"e2e_rnnt\"\r\n+\r\n+    def __init__(self) -> None:\r\n+        import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n+\r\n+        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n+\r\n+        # Всегда используем локальную папку {BASE_DIR}/models/GigaAM-v3-e2e_rnnt\r\n+        # как cache_dir HuggingFace, чтобы веса модели лежали РЯДОМ с exe\r\n+        # и могли быть упакованы в портативную сборку.\r\n+        GIGAAM_DIR.mkdir(parents=True, exist_ok=True)\r\n+        cache_dir = str(GIGAAM_DIR)\r\n+        logger.info(\r\n+            \"GigaAM-v3 local model directory: {} (using as cache_dir).\",\r\n+            GIGAAM_DIR,\r\n+        )\r\n+\r\n+        logger.info(\r\n+            \"Loading GigaAM-v3 model '{}' (revision='{}') on {}\",\r\n+            self.HF_MODEL_ID,\r\n+            self.HF_REVISION,\r\n+            self.device,\r\n+        )\r\n+\r\n+        # ВАЖНО:\r\n+        # На практике half-precision (float16) на некоторых связках CUDA/cuFFT\r\n+        # приводит к падениям вида:\r\n+        #   \"cuFFT only supports dimensions whose sizes are powers of two\r\n+        #    when computing in half precision, but got a signal size of [320]\"\r\n+        # Поэтому для десктоп-приложения надёжнее всегда использовать float32\r\n+        # и на GPU, и на CPU.\r\n+        import torch  # локальный импорт\r\n+\r\n+        torch_dtype = torch.float32\r\n+\r\n+        try:\r\n+            # Жёстко используем локальный cache_dir, чтобы веса всегда лежали\r\n+            # в {BASE_DIR}/models/GigaAM-v3-e2e_rnnt и могли быть добавлены\r\n+            # в портативный exe через --add-data \"models;models\".\r\n+            from_kwargs = {\r\n+                \"revision\": self.HF_REVISION,\r\n+                \"trust_remote_code\": True,\r\n+                \"dtype\": torch_dtype,  # torch_dtype устарел, используем dtype\r\n+                \"cache_dir\": cache_dir,\r\n+            }\r\n+\r\n+            def _load_model() -> None:\r\n+                self.model = AutoModel.from_pretrained(\r\n+                    self.HF_MODEL_ID,\r\n+                    **from_kwargs,\r\n+                ).to(self.device)\r\n+                # На всякий случай приводим модель к нужному dtype ещё раз\r\n+                self.model = self.model.to(dtype=torch_dtype, device=self.device)\r\n+\r\n+            try:\r\n+                _load_model()\r\n+            except Exception as exc:\r\n+                msg = str(exc)\r\n+                # Типовой кейс: локальный кэш HuggingFace повреждён\r\n+                # (битый/обрубленный pytorch_model.bin и т.п.).\r\n+                if isinstance(exc, (OSError, ValueError)) and (\r\n+                    \"Unable to load weights from pytorch checkpoint file\" in msg\r\n+                    or \"Unable to locate the file\" in msg\r\n+                ):\r\n+                    logger.warning(\r\n+                        \"GigaAM-v3: локальный кэш модели повреждён, \"\r\n+                        \"очищаю {} и перезапускаю загрузку.\",\r\n+                        GIGAAM_DIR,\r\n+                    )\r\n+                    import shutil  # локальный импорт, чтобы не тянуть при импорте модуля\r\n+\r\n+                    try:\r\n+                        shutil.rmtree(GIGAAM_DIR)\r\n+                    except Exception as cleanup_exc:  # noqa: BLE001\r\n+                        logger.exception(\r\n+                            \"GigaAM-v3: не удалось удалить повреждённый кэш {}: {}\",\r\n+                            GIGAAM_DIR,\r\n+                            cleanup_exc,\r\n+                        )\r\n+\r\n+                    GIGAAM_DIR.mkdir(parents=True, exist_ok=True)\r\n+                    from_kwargs[\"cache_dir\"] = str(GIGAAM_DIR)\r\n+\r\n+                    _load_model()\r\n+                    logger.info(\r\n+                        \"GigaAM-v3: модель успешно перезаписана после очистки кэша {}\",\r\n+                        GIGAAM_DIR,\r\n+                    )\r\n+                else:\r\n+                    # Не наш кейс — пробрасываем исключение выше.\r\n+                    raise\r\n+        except Exception as exc:  # noqa: BLE001\r\n+            logger.exception(\"Failed to load GigaAM-v3 model from {}: {}\", GIGAAM_DIR, exc)\r\n+            raise RuntimeError(\"GigaAM-v3: ошибка загрузки модели.\") from exc\r\n+\r\n+        logger.info(\"GigaAM-v3 model loaded successfully from {}\", GIGAAM_DIR)\r\n+\r\n+    def transcribe(self, audio: AudioData) -> str:\r\n+        \"\"\"\r\n+        Принимает AudioData и возвращает текст с пунктуацией.\r\n+\r\n+        ВНИМАНИЕ: официальный API модели ожидает путь к аудиофайлу.\r\n+        Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe().\r\n+        \"\"\"\r\n+        import tempfile\r\n+        import soundfile as sf  # type: ignore[import]\r\n+        import numpy as np  # type: ignore[import]\r\n+\r\n+        # Создаём временный WAV-файл\r\n+        with tempfile.TemporaryDirectory() as tmpdir:\r\n+            wav_path = Path(tmpdir) / \"input.wav\"\r\n+\r\n+            samples = audio.samples\r\n+            if isinstance(samples, np.ndarray):\r\n+                if samples.ndim == 2 and samples.shape[1] == 1:\r\n+                    samples = samples[:, 0]\r\n+                samples = samples.astype(\"float32\")\r\n+            else:\r\n+                samples = np.asarray(samples, dtype=\"float32\")\r\n+\r\n+            sf.write(\r\n+                wav_path,\r\n+                samples,\r\n+                audio.sample_rate,\r\n+                format=\"WAV\",\r\n+            )\r\n+\r\n+            try:\r\n+                # Официальный API: модель сама читает файл и делает всю обработку.\r\n+                # Сначала пробуем быстрый путь .transcribe() для коротких файлов.\r\n+                try:\r\n+                    transcription = self.model.transcribe(str(wav_path))\r\n+                except ValueError as exc:\r\n+                    msg = str(exc)\r\n+                    # Специальный кейс GigaAM: \"Too long wav file, use 'transcribe_longform' method.\"\r\n+                    if \"Too long wav file\" in msg and \"transcribe_longform\" in msg:\r\n+                        logger.warning(\r\n+                            \"GigaAM-v3: wav too long for 'transcribe', \"\r\n+                            \"falling back to 'transcribe_longform'.\",\r\n+                        )\r\n+                        transcription = self.model.transcribe_longform(str(wav_path))\r\n+                    else:\r\n+                        logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n+                        raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n+                raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n+\r\n+        if not isinstance(transcription, str):\r\n+            logger.error(\"GigaAM-v3 returned non-string transcription: {}\", transcription)\r\n+            raise RuntimeError(\"GigaAM-v3: некорректный формат ответа.\")\r\n+\r\n+        return transcription or \"\"\n\\ No newline at end of file\n"
                }
            ],
            "date": 1764627434485,
            "name": "Commit-0",
            "content": "from __future__ import annotations\r\n\r\nfrom pathlib import Path\r\nfrom typing import Final, Optional\r\n\r\nfrom loguru import logger  # type: ignore[import]\r\nfrom transformers import AutoModel  # type: ignore[import]\r\n\r\nfrom audio.recorder import AudioData\r\n\r\n\r\nclass GigaAMRecognizer:\r\n    \"\"\"\r\n    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n\r\n    Использует официальный API:\r\n      - модель:   ai-sage/GigaAM-v3\r\n      - revision: \"e2e_rnnt\" (лучшее качество + пунктуация)\r\n      - встроенный метод model.transcribe(path) для распознавания\r\n\r\n    Требует заранее установленного окружения (см. requirements проекта):\r\n      - torch, torchaudio, transformers, pyannote-audio, torchcodec, hydra-core,\r\n        omegaconf, sentencepiece, ffmpeg в PATH.\r\n    \"\"\"\r\n\r\n    HF_MODEL_ID: Final[str] = \"ai-sage/GigaAM-v3\"\r\n    HF_REVISION: Final[str] = \"e2e_rnnt\"\r\n\r\n    def __init__(self, device: Optional[str] = None) -> None:\r\n        \"\"\"\r\n        :param device: \"cuda\" / \"cpu\" / None\r\n                       None -> автоопределение по torch.cuda.is_available().\r\n        \"\"\"\r\n        import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n\r\n        requested_device = (device or \"\").lower().strip() or None\r\n\r\n        if requested_device is None:\r\n            # Автоопределение, как в исходной версии\r\n            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n        elif requested_device == \"cuda\":\r\n            if torch.cuda.is_available():\r\n                self.device = \"cuda\"\r\n            else:\r\n                logger.warning(\r\n                    \"GigaAM: в конфиге запрошен device='cuda', \"\r\n                    \"но torch.cuda.is_available() == False. \"\r\n                    \"Переходим на CPU.\"\r\n                )\r\n                self.device = \"cpu\"\r\n        elif requested_device == \"cpu\":\r\n            self.device = \"cpu\"\r\n        else:\r\n            logger.warning(\r\n                \"GigaAM: неизвестное значение device='{}'. \"\r\n                \"Ожидалось 'cuda' или 'cpu'. Используем автоопределение.\",\r\n                requested_device,\r\n            )\r\n            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n\r\n        logger.info(\r\n            \"Loading GigaAM-v3 model '{}' (revision='{}') on {}\",\r\n            self.HF_MODEL_ID,\r\n            self.HF_REVISION,\r\n            self.device,\r\n        )\r\n\r\n        # ВАЖНО:\r\n        # Из-за бага cuFFT на float16 и n_fft=320 (ошибка:\r\n        #   'cuFFT only supports dimensions whose sizes are powers of two\r\n        #    when computing in half precision, but got a signal size of [320]')\r\n        # мы намеренно используем float32 и на GPU, и на CPU.\r\n        # Это чуть медленнее, но полностью избавляет от падений в STFT.\r\n        torch_dtype = torch.float32\r\n\r\n        try:\r\n            self.model = AutoModel.from_pretrained(\r\n                self.HF_MODEL_ID,\r\n                revision=self.HF_REVISION,\r\n                trust_remote_code=True,\r\n                torch_dtype=torch_dtype,\r\n            ).to(self.device)\r\n            # На всякий случай приводим модель к нужному dtype ещё раз\r\n            self.model = self.model.to(dtype=torch_dtype, device=self.device)\r\n        except Exception as exc:  # noqa: BLE001\r\n            logger.exception(\"Failed to load GigaAM-v3 model: {}\", exc)\r\n            raise RuntimeError(\"GigaAM-v3: ошибка загрузки модели.\") from exc\r\n\r\n        logger.info(\"GigaAM-v3 model loaded successfully\")\r\n\r\n    def transcribe(self, audio: AudioData) -> str:\r\n        \"\"\"\r\n        Принимает AudioData и возвращает текст с пунктуацией.\r\n\r\n        ВНИМАНИЕ: официальный API модели ожидает путь к аудиофайлу.\r\n        Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe().\r\n        \"\"\"\r\n        import tempfile\r\n        import soundfile as sf  # type: ignore[import]\r\n        import numpy as np  # type: ignore[import]\r\n\r\n        # Создаём временный WAV-файл\r\n        with tempfile.TemporaryDirectory() as tmpdir:\r\n            wav_path = Path(tmpdir) / \"input.wav\"\r\n\r\n            samples = audio.samples\r\n            if isinstance(samples, np.ndarray):\r\n                if samples.ndim == 2 and samples.shape[1] == 1:\r\n                    samples = samples[:, 0]\r\n                samples = samples.astype(\"float32\")\r\n            else:\r\n                samples = np.asarray(samples, dtype=\"float32\")\r\n\r\n            sf.write(\r\n                wav_path,\r\n                samples,\r\n                audio.sample_rate,\r\n                format=\"WAV\",\r\n            )\r\n\r\n            try:\r\n                # Официальный API: модель сама читает файл и делает всю обработку\r\n                transcription = self.model.transcribe(str(wav_path))\r\n            except Exception as exc:  # noqa: BLE001\r\n                logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n                raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n\r\n        if not isinstance(transcription, str):\r\n            logger.error(\"GigaAM-v3 returned non-string transcription: {}\", transcription)\r\n            raise RuntimeError(\"GigaAM-v3: некорректный формат ответа.\")\r\n\r\n        return transcription or \"\""
        }
    ]
}
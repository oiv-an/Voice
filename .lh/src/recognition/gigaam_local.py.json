{
    "sourceFile": "src/recognition/gigaam_local.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 14,
            "patches": [
                {
                    "date": 1764457705620,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1764458438516,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,12 +18,27 @@\n     Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n     \"\"\"\r\n \r\n     def __init__(self, model_name: str = \"v2_ctc\") -> None:\r\n+        import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n+\r\n         self.model_name = model_name\r\n-        logger.info(\"Loading GigaAM model: {}\", model_name)\r\n+\r\n+        # Определяем, есть ли CUDA\r\n+        has_cuda = torch.cuda.is_available()\r\n+        device = \"cuda\" if has_cuda else \"cpu\"\r\n+\r\n+        if has_cuda:\r\n+            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", model_name)\r\n+        else:\r\n+            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", model_name)\r\n+\r\n         # Модель автоматически скачивается при первом запуске.\r\n-        self.model = gigaam.load_model(model_name)\r\n+        # Явно указываем device, чтобы при наличии CUDA использовать GPU.\r\n+        self.model = gigaam.load_model(\r\n+            model_name,\r\n+            device=device,\r\n+        )\r\n \r\n     def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n         Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n"
                },
                {
                    "date": 1764464842635,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,34 +11,47 @@\n \r\n \r\n class GigaAMRecognizer:\r\n     \"\"\"\r\n-    Локальный распознаватель на базе GigaAM-v3-CTC (API: v2_ctc).\r\n+    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt (с пунктуацией).\r\n \r\n     Используется как backend \"local\" наряду с Groq и OpenAI.\r\n     Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n     \"\"\"\r\n \r\n-    def __init__(self, model_name: str = \"v2_ctc\") -> None:\r\n+    def __init__(self, model_name: str = \"e2e_rnnt\") -> None:\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        self.model_name = model_name\r\n+        # Жёстко фиксируем e2e_rnnt как основную модель, как ты просил.\r\n+        self.model_name = model_name or \"e2e_rnnt\"\r\n \r\n         # Определяем, есть ли CUDA\r\n         has_cuda = torch.cuda.is_available()\r\n         device = \"cuda\" if has_cuda else \"cpu\"\r\n \r\n         if has_cuda:\r\n-            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", model_name)\r\n+            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", self.model_name)\r\n         else:\r\n-            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", model_name)\r\n+            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n         # Модель автоматически скачивается при первом запуске.\r\n-        # Явно указываем device, чтобы при наличии CUDA использовать GPU.\r\n-        self.model = gigaam.load_model(\r\n-            model_name,\r\n-            device=device,\r\n-        )\r\n+        # Пытаемся включить пунктуацию, если библиотека это поддерживает.\r\n+        try:\r\n+            self.model = gigaam.load_model(\r\n+                self.model_name,\r\n+                device=device,\r\n+                punctuation=True,  # если параметр поддерживается — будет с пунктуацией\r\n+            )\r\n+        except TypeError:\r\n+            logger.warning(\r\n+                \"gigaam.load_model does not support 'punctuation' parameter, \"\r\n+                \"loading model '{}' without it.\",\r\n+                self.model_name,\r\n+            )\r\n+            self.model = gigaam.load_model(\r\n+                self.model_name,\r\n+                device=device,\r\n+            )\r\n \r\n     def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n         Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n"
                },
                {
                    "date": 1764464938738,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,10 +20,10 @@\n \r\n     def __init__(self, model_name: str = \"e2e_rnnt\") -> None:\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        # Жёстко фиксируем e2e_rnnt как основную модель, как ты просил.\r\n-        self.model_name = model_name or \"e2e_rnnt\"\r\n+        # Жёстко фиксируем e2e_rnnt как единственную модель, как ты просил.\r\n+        self.model_name = \"e2e_rnnt\"\r\n \r\n         # Определяем, есть ли CUDA\r\n         has_cuda = torch.cuda.is_available()\r\n         device = \"cuda\" if has_cuda else \"cpu\"\r\n@@ -33,25 +33,14 @@\n         else:\r\n             logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n         # Модель автоматически скачивается при первом запуске.\r\n-        # Пытаемся включить пунктуацию, если библиотека это поддерживает.\r\n-        try:\r\n-            self.model = gigaam.load_model(\r\n-                self.model_name,\r\n-                device=device,\r\n-                punctuation=True,  # если параметр поддерживается — будет с пунктуацией\r\n-            )\r\n-        except TypeError:\r\n-            logger.warning(\r\n-                \"gigaam.load_model does not support 'punctuation' parameter, \"\r\n-                \"loading model '{}' without it.\",\r\n-                self.model_name,\r\n-            )\r\n-            self.model = gigaam.load_model(\r\n-                self.model_name,\r\n-                device=device,\r\n-            )\r\n+        # Библиотека gigaam не поддерживает параметр punctuation, поэтому\r\n+        # просто грузим e2e_rnnt без лишних попыток.\r\n+        self.model = gigaam.load_model(\r\n+            self.model_name,\r\n+            device=device,\r\n+        )\r\n \r\n     def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n         Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n"
                },
                {
                    "date": 1764465154203,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,72 +1,114 @@\n from __future__ import annotations\r\n \r\n-import tempfile\r\n from pathlib import Path\r\n+from typing import Tuple\r\n \r\n-import gigaam  # type: ignore[import]\r\n-import soundfile as sf  # type: ignore[import]\r\n+import numpy as np  # type: ignore[import]\r\n from loguru import logger  # type: ignore[import]\r\n+import torchaudio  # type: ignore[import]\r\n+from transformers import AutoModel, AutoProcessor  # type: ignore[import]\r\n \r\n from audio.recorder import AudioData\r\n \r\n \r\n class GigaAMRecognizer:\r\n     \"\"\"\r\n-    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt (с пунктуацией).\r\n+    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n \r\n-    Используется как backend \"local\" наряду с Groq и OpenAI.\r\n+    Использует:\r\n+      - модель:   ai-sage/GigaAM-v3, revision=\"e2e_rnnt\"\r\n+      - AutoModel + AutoProcessor с trust_remote_code=True\r\n+      - torchaudio для ресемплинга до 16kHz\r\n+\r\n     Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n     \"\"\"\r\n \r\n-    def __init__(self, model_name: str = \"e2e_rnnt\") -> None:\r\n+    def __init__(self) -> None:\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        # Жёстко фиксируем e2e_rnnt как единственную модель, как ты просил.\r\n-        self.model_name = \"e2e_rnnt\"\r\n+        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n \r\n-        # Определяем, есть ли CUDA\r\n-        has_cuda = torch.cuda.is_available()\r\n-        device = \"cuda\" if has_cuda else \"cpu\"\r\n+        logger.info(\r\n+            \"Loading HuggingFace GigaAM-v3 e2e_rnnt model on {}\",\r\n+            self.device,\r\n+        )\r\n \r\n-        if has_cuda:\r\n-            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", self.model_name)\r\n-        else:\r\n-            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n+        # Загружаем RNNT модель и процессор с HuggingFace\r\n+        self.model = AutoModel.from_pretrained(\r\n+            \"ai-sage/GigaAM-v3\",\r\n+            revision=\"e2e_rnnt\",\r\n+            trust_remote_code=True,\r\n+        ).to(self.device)\r\n \r\n-        # Модель автоматически скачивается при первом запуске.\r\n-        # Библиотека gigaam не поддерживает параметр punctuation, поэтому\r\n-        # просто грузим e2e_rnnt без лишних попыток.\r\n-        self.model = gigaam.load_model(\r\n-            self.model_name,\r\n-            device=device,\r\n+        self.processor = AutoProcessor.from_pretrained(\r\n+            \"ai-sage/GigaAM-v3\",\r\n+            revision=\"e2e_rnnt\",\r\n+            trust_remote_code=True,\r\n         )\r\n \r\n-    def transcribe(self, audio: AudioData) -> str:\r\n+    # ------------------------------------------------------------------ helpers\r\n+\r\n\\ No newline at end of file\n+    def _audio_to_waveform(self, audio: AudioData) -> Tuple[\"torchaudio.Tensor\", int]:\r\n         \"\"\"\r\n-        Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n+        Конвертирует AudioData (numpy float32, 16kHz mono) в torch.Tensor [1, T] 16kHz.\r\n+        \"\"\"\r\n+        import torch\r\n \r\n-        Для надёжности пишем во временный WAV и даём путь модели.\r\n+        samples = audio.samples\r\n+        # audio.samples может быть shape (N,) или (N,1) — приводим к (N,)\r\n+        if isinstance(samples, np.ndarray):\r\n+            if samples.ndim == 2 and samples.shape[1] == 1:\r\n+                samples = samples[:, 0]\r\n+            samples = samples.astype(np.float32)\r\n+        else:\r\n+            samples = np.asarray(samples, dtype=np.float32)\r\n+\r\n+        waveform = torch.from_numpy(samples).unsqueeze(0)  # [1, T]\r\n+        sample_rate = audio.sample_rate\r\n+\r\n+        if sample_rate != 16000:\r\n+            logger.info(\r\n+                \"Resampling local audio from {} Hz to 16000 Hz for GigaAM-v3\",\r\n+                sample_rate,\r\n+            )\r\n+            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\r\n+            waveform = resampler(waveform)\r\n+\r\n+        return waveform, 16000\r\n+\r\n+    # ------------------------------------------------------------------ public API\r\n+\r\n+    def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n-        with tempfile.TemporaryDirectory() as tmpdir:\r\n-            wav_path = Path(tmpdir) / \"input.wav\"\r\n+        Принимает AudioData и возвращает текст с пунктуацией через e2e_rnnt.\r\n+        \"\"\"\r\n+        import torch\r\n \r\n-            # Сохраняем numpy → WAV (16kHz mono, PCM_16)\r\n-            sf.write(\r\n-                wav_path,\r\n-                audio.samples,\r\n-                audio.sample_rate,\r\n-                format=\"WAV\",\r\n-                subtype=\"PCM_16\",\r\n+        try:\r\n+            waveform, sr = self._audio_to_waveform(audio)\r\n+\r\n+            # Препроцессинг\r\n+            inputs = self.processor(\r\n+                waveform.squeeze(0),\r\n+                sampling_rate=sr,\r\n+                return_tensors=\"pt\",\r\n             )\r\n+            inputs = {k: v.to(self.device) for k, v in inputs.items()}\r\n \r\n-            try:\r\n-                text = self.model.transcribe(str(wav_path))\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"GigaAM transcribe error: {}\", exc)\r\n-                raise RuntimeError(\"GigaAM: ошибка распознавания.\") from exc\r\n+            # Инференс\r\n+            with torch.no_grad():\r\n+                output = self.model(**inputs)\r\n \r\n-        if not isinstance(text, str):\r\n-            logger.error(\"GigaAM returned non-string transcription: {}\", text)\r\n-            raise RuntimeError(\"GigaAM: некорректный формат ответа.\")\r\n+            # Декодирование с пунктуацией\r\n+            logits = output.logits  # type: ignore[attr-defined]\r\n+            pred_ids = logits.argmax(dim=-1)[0]\r\n+            transcription = self.processor.decode(pred_ids)\r\n+        except Exception as exc:  # noqa: BLE001\r\n+            logger.exception(\"GigaAM HF e2e_rnnt transcribe error: {}\", exc)\r\n+            raise RuntimeError(\"GigaAM HF: ошибка распознавания.\") from exc\r\n \r\n-        return text or \"\"\n+        if not isinstance(transcription, str):\r\n+            logger.error(\"GigaAM HF returned non-string transcription: {}\", transcription)\r\n+            raise RuntimeError(\"GigaAM HF: некорректный формат ответа.\")\r\n+\r\n+        return transcription or \"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764465486028,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,114 +1,70 @@\n from __future__ import annotations\r\n \r\n+import tempfile\r\n from pathlib import Path\r\n-from typing import Tuple\r\n \r\n-import numpy as np  # type: ignore[import]\r\n+import gigaam  # type: ignore[import]\r\n+import soundfile as sf  # type: ignore[import]\r\n from loguru import logger  # type: ignore[import]\r\n-import torchaudio  # type: ignore[import]\r\n-from transformers import AutoModel, AutoProcessor  # type: ignore[import]\r\n \r\n from audio.recorder import AudioData\r\n \r\n \r\n class GigaAMRecognizer:\r\n     \"\"\"\r\n-    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n+    Локальный распознаватель на базе GigaAM-v2 RNNT (v2_rnnt).\r\n \r\n-    Использует:\r\n-      - модель:   ai-sage/GigaAM-v3, revision=\"e2e_rnnt\"\r\n-      - AutoModel + AutoProcessor с trust_remote_code=True\r\n-      - torchaudio для ресемплинга до 16kHz\r\n-\r\n+    Используется как backend \"local\" наряду с Groq и OpenAI.\r\n     Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n     \"\"\"\r\n \r\n-    def __init__(self) -> None:\r\n+    def __init__(self, model_name: str = \"v2_rnnt\") -> None:\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n+        # Жёстко фиксируем v2_rnnt как единственную модель.\r\n+        self.model_name = \"v2_rnnt\"\r\n \r\n-        logger.info(\r\n-            \"Loading HuggingFace GigaAM-v3 e2e_rnnt model on {}\",\r\n-            self.device,\r\n-        )\r\n+        # Определяем, есть ли CUDA\r\n+        has_cuda = torch.cuda.is_available()\r\n+        device = \"cuda\" if has_cuda else \"cpu\"\r\n \r\n-        # Загружаем RNNT модель и процессор с HuggingFace\r\n-        self.model = AutoModel.from_pretrained(\r\n-            \"ai-sage/GigaAM-v3\",\r\n-            revision=\"e2e_rnnt\",\r\n-            trust_remote_code=True,\r\n-        ).to(self.device)\r\n+        if has_cuda:\r\n+            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", self.model_name)\r\n+        else:\r\n+            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n-        self.processor = AutoProcessor.from_pretrained(\r\n-            \"ai-sage/GigaAM-v3\",\r\n-            revision=\"e2e_rnnt\",\r\n-            trust_remote_code=True,\r\n+        # Модель автоматически скачивается при первом запуске.\r\n+        self.model = gigaam.load_model(\r\n+            self.model_name,\r\n+            device=device,\r\n         )\r\n \r\n-    # ------------------------------------------------------------------ helpers\r\n-\r\n-    def _audio_to_waveform(self, audio: AudioData) -> Tuple[\"torchaudio.Tensor\", int]:\r\n+    def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n-        Конвертирует AudioData (numpy float32, 16kHz mono) в torch.Tensor [1, T] 16kHz.\r\n-        \"\"\"\r\n-        import torch\r\n+        Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n \r\n-        samples = audio.samples\r\n-        # audio.samples может быть shape (N,) или (N,1) — приводим к (N,)\r\n-        if isinstance(samples, np.ndarray):\r\n-            if samples.ndim == 2 and samples.shape[1] == 1:\r\n-                samples = samples[:, 0]\r\n-            samples = samples.astype(np.float32)\r\n-        else:\r\n-            samples = np.asarray(samples, dtype=np.float32)\r\n-\r\n-        waveform = torch.from_numpy(samples).unsqueeze(0)  # [1, T]\r\n-        sample_rate = audio.sample_rate\r\n-\r\n-        if sample_rate != 16000:\r\n-            logger.info(\r\n-                \"Resampling local audio from {} Hz to 16000 Hz for GigaAM-v3\",\r\n-                sample_rate,\r\n-            )\r\n-            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\r\n-            waveform = resampler(waveform)\r\n-\r\n-        return waveform, 16000\r\n-\r\n-    # ------------------------------------------------------------------ public API\r\n-\r\n-    def transcribe(self, audio: AudioData) -> str:\r\n+        Для надёжности пишем во временный WAV и даём путь модели.\r\n         \"\"\"\r\n-        Принимает AudioData и возвращает текст с пунктуацией через e2e_rnnt.\r\n-        \"\"\"\r\n-        import torch\r\n+        with tempfile.TemporaryDirectory() as tmpdir:\r\n+            wav_path = Path(tmpdir) / \"input.wav\"\r\n \r\n-        try:\r\n-            waveform, sr = self._audio_to_waveform(audio)\r\n-\r\n-            # Препроцессинг\r\n\\ No newline at end of file\n-            inputs = self.processor(\r\n-                waveform.squeeze(0),\r\n-                sampling_rate=sr,\r\n-                return_tensors=\"pt\",\r\n+            # Сохраняем numpy → WAV (16kHz mono, PCM_16)\r\n+            sf.write(\r\n+                wav_path,\r\n+                audio.samples,\r\n+                audio.sample_rate,\r\n+                format=\"WAV\",\r\n+                subtype=\"PCM_16\",\r\n             )\r\n-            inputs = {k: v.to(self.device) for k, v in inputs.items()}\r\n \r\n-            # Инференс\r\n-            with torch.no_grad():\r\n-                output = self.model(**inputs)\r\n+            try:\r\n+                text = self.model.transcribe(str(wav_path))\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                logger.exception(\"GigaAM transcribe error: {}\", exc)\r\n+                raise RuntimeError(\"GigaAM: ошибка распознавания.\") from exc\r\n \r\n-            # Декодирование с пунктуацией\r\n-            logits = output.logits  # type: ignore[attr-defined]\r\n-            pred_ids = logits.argmax(dim=-1)[0]\r\n-            transcription = self.processor.decode(pred_ids)\r\n-        except Exception as exc:  # noqa: BLE001\r\n-            logger.exception(\"GigaAM HF e2e_rnnt transcribe error: {}\", exc)\r\n-            raise RuntimeError(\"GigaAM HF: ошибка распознавания.\") from exc\r\n+        if not isinstance(text, str):\r\n+            logger.error(\"GigaAM returned non-string transcription: {}\", text)\r\n+            raise RuntimeError(\"GigaAM: некорректный формат ответа.\")\r\n \r\n-        if not isinstance(transcription, str):\r\n-            logger.error(\"GigaAM HF returned non-string transcription: {}\", transcription)\r\n-            raise RuntimeError(\"GigaAM HF: некорректный формат ответа.\")\r\n-\r\n-        return transcription or \"\"\n+        return text or \"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764465859100,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,70 +1,113 @@\n from __future__ import annotations\r\n \r\n-import tempfile\r\n-from pathlib import Path\r\n+from typing import Tuple\r\n \r\n-import gigaam  # type: ignore[import]\r\n-import soundfile as sf  # type: ignore[import]\r\n+import numpy as np  # type: ignore[import]\r\n from loguru import logger  # type: ignore[import]\r\n+import torchaudio  # type: ignore[import]\r\n+from transformers import AutoModel, AutoProcessor  # type: ignore[import]\r\n \r\n from audio.recorder import AudioData\r\n \r\n \r\n class GigaAMRecognizer:\r\n     \"\"\"\r\n-    Локальный распознаватель на базе GigaAM-v2 RNNT (v2_rnnt).\r\n+    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n \r\n-    Используется как backend \"local\" наряду с Groq и OpenAI.\r\n+    Использует:\r\n+      - модель:   ai-sage/GigaAM-v3, revision=\"e2e_rnnt\"\r\n+      - AutoModel + AutoProcessor с trust_remote_code=True\r\n+      - torchaudio для ресемплинга до 16kHz\r\n+\r\n     Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n     \"\"\"\r\n \r\n-    def __init__(self, model_name: str = \"v2_rnnt\") -> None:\r\n+    def __init__(self) -> None:\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        # Жёстко фиксируем v2_rnnt как единственную модель.\r\n-        self.model_name = \"v2_rnnt\"\r\n+        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n \r\n-        # Определяем, есть ли CUDA\r\n-        has_cuda = torch.cuda.is_available()\r\n-        device = \"cuda\" if has_cuda else \"cpu\"\r\n+        logger.info(\r\n+            \"Loading HuggingFace GigaAM-v3 e2e_rnnt model on {}\",\r\n+            self.device,\r\n+        )\r\n \r\n-        if has_cuda:\r\n-            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", self.model_name)\r\n-        else:\r\n-            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n+        # Загружаем RNNT модель и процессор с HuggingFace\r\n+        self.model = AutoModel.from_pretrained(\r\n+            \"ai-sage/GigaAM-v3\",\r\n+            revision=\"e2e_rnnt\",\r\n+            trust_remote_code=True,\r\n+        ).to(self.device)\r\n \r\n-        # Модель автоматически скачивается при первом запуске.\r\n-        self.model = gigaam.load_model(\r\n-            self.model_name,\r\n-            device=device,\r\n+        self.processor = AutoProcessor.from_pretrained(\r\n+            \"ai-sage/GigaAM-v3\",\r\n+            revision=\"e2e_rnnt\",\r\n+            trust_remote_code=True,\r\n         )\r\n \r\n-    def transcribe(self, audio: AudioData) -> str:\r\n+    # ------------------------------------------------------------------ helpers\r\n+\r\n\\ No newline at end of file\n+    def _audio_to_waveform(self, audio: AudioData) -> Tuple[\"torchaudio.Tensor\", int]:\r\n         \"\"\"\r\n-        Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n+        Конвертирует AudioData (numpy float32, 16kHz mono) в torch.Tensor [1, T] 16kHz.\r\n+        \"\"\"\r\n+        import torch\r\n \r\n-        Для надёжности пишем во временный WAV и даём путь модели.\r\n+        samples = audio.samples\r\n+        # audio.samples может быть shape (N,) или (N,1) — приводим к (N,)\r\n+        if isinstance(samples, np.ndarray):\r\n+            if samples.ndim == 2 and samples.shape[1] == 1:\r\n+                samples = samples[:, 0]\r\n+            samples = samples.astype(np.float32)\r\n+        else:\r\n+            samples = np.asarray(samples, dtype=np.float32)\r\n+\r\n+        waveform = torch.from_numpy(samples).unsqueeze(0)  # [1, T]\r\n+        sample_rate = audio.sample_rate\r\n+\r\n+        if sample_rate != 16000:\r\n+            logger.info(\r\n+                \"Resampling local audio from {} Hz to 16000 Hz for GigaAM-v3\",\r\n+                sample_rate,\r\n+            )\r\n+            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\r\n+            waveform = resampler(waveform)\r\n+\r\n+        return waveform, 16000\r\n+\r\n+    # ------------------------------------------------------------------ public API\r\n+\r\n+    def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n-        with tempfile.TemporaryDirectory() as tmpdir:\r\n-            wav_path = Path(tmpdir) / \"input.wav\"\r\n+        Принимает AudioData и возвращает текст с пунктуацией через e2e_rnnt.\r\n+        \"\"\"\r\n+        import torch\r\n \r\n-            # Сохраняем numpy → WAV (16kHz mono, PCM_16)\r\n-            sf.write(\r\n-                wav_path,\r\n-                audio.samples,\r\n-                audio.sample_rate,\r\n-                format=\"WAV\",\r\n-                subtype=\"PCM_16\",\r\n+        try:\r\n+            waveform, sr = self._audio_to_waveform(audio)\r\n+\r\n+            # Препроцессинг\r\n+            inputs = self.processor(\r\n+                waveform.squeeze(0),\r\n+                sampling_rate=sr,\r\n+                return_tensors=\"pt\",\r\n             )\r\n+            inputs = {k: v.to(self.device) for k, v in inputs.items()}\r\n \r\n-            try:\r\n-                text = self.model.transcribe(str(wav_path))\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"GigaAM transcribe error: {}\", exc)\r\n-                raise RuntimeError(\"GigaAM: ошибка распознавания.\") from exc\r\n+            # Инференс\r\n+            with torch.no_grad():\r\n+                output = self.model(**inputs)\r\n \r\n-        if not isinstance(text, str):\r\n-            logger.error(\"GigaAM returned non-string transcription: {}\", text)\r\n-            raise RuntimeError(\"GigaAM: некорректный формат ответа.\")\r\n+            # Декодирование с пунктуацией\r\n+            logits = output.logits  # type: ignore[attr-defined]\r\n+            pred_ids = logits.argmax(dim=-1)[0]\r\n+            transcription = self.processor.decode(pred_ids)\r\n+        except Exception as exc:  # noqa: BLE001\r\n+            logger.exception(\"GigaAM HF e2e_rnnt transcribe error: {}\", exc)\r\n+            raise RuntimeError(\"GigaAM HF: ошибка распознавания.\") from exc\r\n \r\n-        return text or \"\"\n+        if not isinstance(transcription, str):\r\n+            logger.error(\"GigaAM HF returned non-string transcription: {}\", transcription)\r\n+            raise RuntimeError(\"GigaAM HF: некорректный формат ответа.\")\r\n+\r\n+        return transcription or \"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764466093803,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,113 +1,70 @@\n from __future__ import annotations\r\n \r\n-from typing import Tuple\r\n+import tempfile\r\n+from pathlib import Path\r\n \r\n-import numpy as np  # type: ignore[import]\r\n+import gigaam  # type: ignore[import]\r\n+import soundfile as sf  # type: ignore[import]\r\n from loguru import logger  # type: ignore[import]\r\n-import torchaudio  # type: ignore[import]\r\n-from transformers import AutoModel, AutoProcessor  # type: ignore[import]\r\n \r\n from audio.recorder import AudioData\r\n \r\n \r\n class GigaAMRecognizer:\r\n     \"\"\"\r\n-    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n+    Локальный распознаватель на базе GigaAM-v2 RNNT (v2_rnnt).\r\n \r\n-    Использует:\r\n-      - модель:   ai-sage/GigaAM-v3, revision=\"e2e_rnnt\"\r\n-      - AutoModel + AutoProcessor с trust_remote_code=True\r\n-      - torchaudio для ресемплинга до 16kHz\r\n-\r\n+    Используется как backend \"local\" наряду с Groq и OpenAI.\r\n     Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n     \"\"\"\r\n \r\n-    def __init__(self) -> None:\r\n+    def __init__(self, model_name: str = \"v2_rnnt\") -> None:\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n+        # Жёстко фиксируем v2_rnnt как единственную модель.\r\n+        self.model_name = \"v2_rnnt\"\r\n \r\n-        logger.info(\r\n-            \"Loading HuggingFace GigaAM-v3 e2e_rnnt model on {}\",\r\n-            self.device,\r\n-        )\r\n+        # Определяем, есть ли CUDA\r\n+        has_cuda = torch.cuda.is_available()\r\n+        device = \"cuda\" if has_cuda else \"cpu\"\r\n \r\n-        # Загружаем RNNT модель и процессор с HuggingFace\r\n-        self.model = AutoModel.from_pretrained(\r\n-            \"ai-sage/GigaAM-v3\",\r\n-            revision=\"e2e_rnnt\",\r\n-            trust_remote_code=True,\r\n-        ).to(self.device)\r\n+        if has_cuda:\r\n+            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", self.model_name)\r\n+        else:\r\n+            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n-        self.processor = AutoProcessor.from_pretrained(\r\n-            \"ai-sage/GigaAM-v3\",\r\n-            revision=\"e2e_rnnt\",\r\n-            trust_remote_code=True,\r\n+        # Модель автоматически скачивается при первом запуске.\r\n+        self.model = gigaam.load_model(\r\n+            self.model_name,\r\n+            device=device,\r\n         )\r\n \r\n-    # ------------------------------------------------------------------ helpers\r\n-\r\n-    def _audio_to_waveform(self, audio: AudioData) -> Tuple[\"torchaudio.Tensor\", int]:\r\n+    def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n-        Конвертирует AudioData (numpy float32, 16kHz mono) в torch.Tensor [1, T] 16kHz.\r\n-        \"\"\"\r\n-        import torch\r\n+        Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n \r\n-        samples = audio.samples\r\n-        # audio.samples может быть shape (N,) или (N,1) — приводим к (N,)\r\n-        if isinstance(samples, np.ndarray):\r\n-            if samples.ndim == 2 and samples.shape[1] == 1:\r\n-                samples = samples[:, 0]\r\n-            samples = samples.astype(np.float32)\r\n-        else:\r\n-            samples = np.asarray(samples, dtype=np.float32)\r\n-\r\n-        waveform = torch.from_numpy(samples).unsqueeze(0)  # [1, T]\r\n-        sample_rate = audio.sample_rate\r\n-\r\n-        if sample_rate != 16000:\r\n-            logger.info(\r\n-                \"Resampling local audio from {} Hz to 16000 Hz for GigaAM-v3\",\r\n-                sample_rate,\r\n-            )\r\n-            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\r\n-            waveform = resampler(waveform)\r\n-\r\n-        return waveform, 16000\r\n-\r\n-    # ------------------------------------------------------------------ public API\r\n-\r\n-    def transcribe(self, audio: AudioData) -> str:\r\n+        Для надёжности пишем во временный WAV и даём путь модели.\r\n         \"\"\"\r\n-        Принимает AudioData и возвращает текст с пунктуацией через e2e_rnnt.\r\n-        \"\"\"\r\n-        import torch\r\n+        with tempfile.TemporaryDirectory() as tmpdir:\r\n+            wav_path = Path(tmpdir) / \"input.wav\"\r\n \r\n-        try:\r\n-            waveform, sr = self._audio_to_waveform(audio)\r\n-\r\n\\ No newline at end of file\n-            # Препроцессинг\r\n-            inputs = self.processor(\r\n-                waveform.squeeze(0),\r\n-                sampling_rate=sr,\r\n-                return_tensors=\"pt\",\r\n+            # Сохраняем numpy → WAV (16kHz mono, PCM_16)\r\n+            sf.write(\r\n+                wav_path,\r\n+                audio.samples,\r\n+                audio.sample_rate,\r\n+                format=\"WAV\",\r\n+                subtype=\"PCM_16\",\r\n             )\r\n-            inputs = {k: v.to(self.device) for k, v in inputs.items()}\r\n \r\n-            # Инференс\r\n-            with torch.no_grad():\r\n-                output = self.model(**inputs)\r\n+            try:\r\n+                text = self.model.transcribe(str(wav_path))\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                logger.exception(\"GigaAM transcribe error: {}\", exc)\r\n+                raise RuntimeError(\"GigaAM: ошибка распознавания.\") from exc\r\n \r\n-            # Декодирование с пунктуацией\r\n-            logits = output.logits  # type: ignore[attr-defined]\r\n-            pred_ids = logits.argmax(dim=-1)[0]\r\n-            transcription = self.processor.decode(pred_ids)\r\n-        except Exception as exc:  # noqa: BLE001\r\n-            logger.exception(\"GigaAM HF e2e_rnnt transcribe error: {}\", exc)\r\n-            raise RuntimeError(\"GigaAM HF: ошибка распознавания.\") from exc\r\n+        if not isinstance(text, str):\r\n+            logger.error(\"GigaAM returned non-string transcription: {}\", text)\r\n+            raise RuntimeError(\"GigaAM: некорректный формат ответа.\")\r\n \r\n-        if not isinstance(transcription, str):\r\n-            logger.error(\"GigaAM HF returned non-string transcription: {}\", transcription)\r\n-            raise RuntimeError(\"GigaAM HF: некорректный формат ответа.\")\r\n-\r\n-        return transcription or \"\"\n+        return text or \"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764466137039,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,13 +33,20 @@\n         else:\r\n             logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n         # Модель автоматически скачивается при первом запуске.\r\n-        self.model = gigaam.load_model(\r\n-            self.model_name,\r\n-            device=device,\r\n-        )\r\n+        # Оборачиваем загрузку в безопасный контекст torch.serialization.safe_globals,\r\n+        # чтобы разрешить omegaconf.dictconfig.DictConfig и обойти weights_only ошибку.\r\n+        import torch.serialization as _ts  # локальный импорт\r\n \r\n+        from omegaconf.dictconfig import DictConfig  # type: ignore[import]\r\n+\r\n+        with _ts.safe_globals([DictConfig]):\r\n+            self.model = gigaam.load_model(\r\n+                self.model_name,\r\n+                device=device,\r\n+            )\r\n+\r\n     def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n         Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n \r\n"
                },
                {
                    "date": 1764466187775,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,15 +33,21 @@\n         else:\r\n             logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n         # Модель автоматически скачивается при первом запуске.\r\n-        # Оборачиваем загрузку в безопасный контекст torch.serialization.safe_globals,\r\n-        # чтобы разрешить omegaconf.dictconfig.DictConfig и обойти weights_only ошибку.\r\n+        # В PyTorch 2.6+ по умолчанию weights_only=True, что ломает старые чекпоинты.\r\n+        # Явно разрешаем необходимые классы и отключаем weights_only.\r\n+        import torch\r\n         import torch.serialization as _ts  # локальный импорт\r\n \r\n         from omegaconf.dictconfig import DictConfig  # type: ignore[import]\r\n+        from omegaconf.base import ContainerMetadata  # type: ignore[import]\r\n \r\n-        with _ts.safe_globals([DictConfig]):\r\n+        _ts.add_safe_globals([DictConfig, ContainerMetadata])\r\n+\r\n+        # gigaam внутри вызывает torch.load(...), поэтому перед этим глобально\r\n+        # возвращаем поведение weights_only=False через контекст.\r\n+        with _ts.weights_only_off():\r\n             self.model = gigaam.load_model(\r\n                 self.model_name,\r\n                 device=device,\r\n             )\r\n"
                },
                {
                    "date": 1764466225214,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,20 +34,29 @@\n             logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n         # Модель автоматически скачивается при первом запуске.\r\n         # В PyTorch 2.6+ по умолчанию weights_only=True, что ломает старые чекпоинты.\r\n-        # Явно разрешаем необходимые классы и отключаем weights_only.\r\n+        # Явно разрешаем необходимые классы и отключаем weights_only через контекст.\r\n         import torch\r\n         import torch.serialization as _ts  # локальный импорт\r\n \r\n         from omegaconf.dictconfig import DictConfig  # type: ignore[import]\r\n         from omegaconf.base import ContainerMetadata  # type: ignore[import]\r\n \r\n         _ts.add_safe_globals([DictConfig, ContainerMetadata])\r\n \r\n-        # gigaam внутри вызывает torch.load(...), поэтому перед этим глобально\r\n-        # возвращаем поведение weights_only=False через контекст.\r\n-        with _ts.weights_only_off():\r\n+        class _WeightsOnlyOff:\r\n+            def __enter__(self):\r\n+                # сохраняем старое значение и выставляем False\r\n+                self._prev = getattr(torch.serialization, \"_weights_only_by_default\", False)\r\n+                torch.serialization._weights_only_by_default = False  # type: ignore[attr-defined]\r\n+                return self\r\n+\r\n+            def __exit__(self, exc_type, exc, tb):\r\n+                # возвращаем предыдущее значение\r\n+                torch.serialization._weights_only_by_default = self._prev  # type: ignore[attr-defined]\r\n+\r\n+        with _WeightsOnlyOff():\r\n             self.model = gigaam.load_model(\r\n                 self.model_name,\r\n                 device=device,\r\n             )\r\n"
                },
                {
                    "date": 1764466272905,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,34 +34,28 @@\n             logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n         # Модель автоматически скачивается при первом запуске.\r\n         # В PyTorch 2.6+ по умолчанию weights_only=True, что ломает старые чекпоинты.\r\n-        # Явно разрешаем необходимые классы и отключаем weights_only через контекст.\r\n+        # Явно разрешаем необходимые классы и отключаем weights_only через глобальные настройки.\r\n         import torch\r\n         import torch.serialization as _ts  # локальный импорт\r\n+        from typing import Any  # noqa: F401\r\n \r\n         from omegaconf.dictconfig import DictConfig  # type: ignore[import]\r\n         from omegaconf.base import ContainerMetadata  # type: ignore[import]\r\n \r\n-        _ts.add_safe_globals([DictConfig, ContainerMetadata])\r\n+        _ts.add_safe_globals([DictConfig, ContainerMetadata, Any])\r\n \r\n-        class _WeightsOnlyOff:\r\n-            def __enter__(self):\r\n-                # сохраняем старое значение и выставляем False\r\n-                self._prev = getattr(torch.serialization, \"_weights_only_by_default\", False)\r\n-                torch.serialization._weights_only_by_default = False  # type: ignore[attr-defined]\r\n-                return self\r\n+        # ЯВНО отключаем режим weights_only по умолчанию, как до PyTorch 2.6.\r\n+        # Это глобальная настройка процесса, но нам это нужно для совместимости с чекпоинтом GigaAM.\r\n+        if hasattr(torch.serialization, \"_weights_only_by_default\"):\r\n+            torch.serialization._weights_only_by_default = False  # type: ignore[attr-defined]\r\n \r\n-            def __exit__(self, exc_type, exc, tb):\r\n-                # возвращаем предыдущее значение\r\n-                torch.serialization._weights_only_by_default = self._prev  # type: ignore[attr-defined]\r\n+        self.model = gigaam.load_model(\r\n+            self.model_name,\r\n+            device=device,\r\n+        )\r\n \r\n-        with _WeightsOnlyOff():\r\n-            self.model = gigaam.load_model(\r\n-                self.model_name,\r\n-                device=device,\r\n-            )\r\n-\r\n     def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n         Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n \r\n"
                },
                {
                    "date": 1764466310283,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,23 +34,35 @@\n             logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n \r\n         # Модель автоматически скачивается при первом запуске.\r\n         # В PyTorch 2.6+ по умолчанию weights_only=True, что ломает старые чекпоинты.\r\n-        # Явно разрешаем необходимые классы и отключаем weights_only через глобальные настройки.\r\n+        # Полностью отключаем безопасный режим и разрешаем все необходимые типы.\r\n         import torch\r\n         import torch.serialization as _ts  # локальный импорт\r\n         from typing import Any  # noqa: F401\r\n \r\n         from omegaconf.dictconfig import DictConfig  # type: ignore[import]\r\n         from omegaconf.base import ContainerMetadata  # type: ignore[import]\r\n \r\n-        _ts.add_safe_globals([DictConfig, ContainerMetadata, Any])\r\n+        # Разрешаем используемые типы\r\n+        _ts.add_safe_globals([DictConfig, ContainerMetadata, Any, dict])\r\n \r\n-        # ЯВНО отключаем режим weights_only по умолчанию, как до PyTorch 2.6.\r\n-        # Это глобальная настройка процесса, но нам это нужно для совместимости с чекпоинтом GigaAM.\r\n+        # Глобально возвращаем поведение torch.load как до 2.6:\r\n+        # weights_only=False по умолчанию.\r\n         if hasattr(torch.serialization, \"_weights_only_by_default\"):\r\n             torch.serialization._weights_only_by_default = False  # type: ignore[attr-defined]\r\n \r\n+        # Дополнительно переопределяем torch.load, чтобы всегда вызывать его с weights_only=False.\r\n+        _orig_torch_load = torch.load\r\n+\r\n+        def _patched_torch_load(*args, **kwargs):\r\n+            # если явно не передан weights_only, принудительно ставим False\r\n+            if \"weights_only\" not in kwargs:\r\n+                kwargs[\"weights_only\"] = False\r\n+            return _orig_torch_load(*args, **kwargs)\r\n+\r\n+        torch.load = _patched_torch_load  # type: ignore[assignment]\r\n+\r\n         self.model = gigaam.load_model(\r\n             self.model_name,\r\n             device=device,\r\n         )\r\n"
                },
                {
                    "date": 1764466617300,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,98 +1,97 @@\n from __future__ import annotations\r\n \r\n-import tempfile\r\n from pathlib import Path\r\n+from typing import Final\r\n \r\n-import gigaam  # type: ignore[import]\r\n-import soundfile as sf  # type: ignore[import]\r\n from loguru import logger  # type: ignore[import]\r\n+from transformers import AutoModel  # type: ignore[import]\r\n \r\n from audio.recorder import AudioData\r\n \r\n \r\n class GigaAMRecognizer:\r\n     \"\"\"\r\n-    Локальный распознаватель на базе GigaAM-v2 RNNT (v2_rnnt).\r\n+    Локальный распознаватель на базе GigaAM-v3 e2e_rnnt через HuggingFace.\r\n \r\n-    Используется как backend \"local\" наряду с Groq и OpenAI.\r\n-    Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n+    Использует официальный API:\r\n+      - модель:   ai-sage/GigaAM-v3\r\n+      - revision: \"e2e_rnnt\" (лучшее качество + пунктуация)\r\n+      - встроенный метод model.transcribe(path) для распознавания\r\n+\r\n+    Требует заранее установленного окружения (см. requirements проекта):\r\n+      - torch, torchaudio, transformers, pyannote-audio, torchcodec, hydra-core, omegaconf, sentencepiece, ffmpeg в PATH.\r\n     \"\"\"\r\n \r\n-    def __init__(self, model_name: str = \"v2_rnnt\") -> None:\r\n+    HF_MODEL_ID: Final[str] = \"ai-sage/GigaAM-v3\"\r\n+    HF_REVISION: Final[str] = \"e2e_rnnt\"\r\n+\r\n+    def __init__(self) -> None:\r\n         import torch  # локальный импорт, чтобы не тянуть при импорте модуля\r\n \r\n-        # Жёстко фиксируем v2_rnnt как единственную модель.\r\n-        self.model_name = \"v2_rnnt\"\r\n+        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n \r\n-        # Определяем, есть ли CUDA\r\n-        has_cuda = torch.cuda.is_available()\r\n-        device = \"cuda\" if has_cuda else \"cpu\"\r\n+        logger.info(\r\n+            \"Loading GigaAM-v3 model '{}' (revision='{}') on {}\",\r\n+            self.HF_MODEL_ID,\r\n+            self.HF_REVISION,\r\n+            self.device,\r\n+        )\r\n \r\n-        if has_cuda:\r\n-            logger.info(\"Loading GigaAM model: {} on GPU (cuda)\", self.model_name)\r\n-        else:\r\n-            logger.info(\"Loading GigaAM model: {} on CPU (no CUDA detected)\", self.model_name)\r\n+        # Загружаем модель с trust_remote_code=True и корректным dtype\r\n+        torch_dtype = torch.float16 if self.device == \"cuda\" else torch.float32\r\n \r\n-        # Модель автоматически скачивается при первом запуске.\r\n-        # В PyTorch 2.6+ по умолчанию weights_only=True, что ломает старые чекпоинты.\r\n-        # Полностью отключаем безопасный режим и разрешаем все необходимые типы.\r\n-        import torch\r\n-        import torch.serialization as _ts  # локальный импорт\r\n-        from typing import Any  # noqa: F401\r\n+        try:\r\n+            self.model = AutoModel.from_pretrained(\r\n+                self.HF_MODEL_ID,\r\n+                revision=self.HF_REVISION,\r\n+                trust_remote_code=True,\r\n+                torch_dtype=torch_dtype,\r\n+            ).to(self.device)\r\n+        except Exception as exc:  # noqa: BLE001\r\n+            logger.exception(\"Failed to load GigaAM-v3 model: {}\", exc)\r\n+            raise RuntimeError(\"GigaAM-v3: ошибка загрузки модели.\") from exc\r\n \r\n-        from omegaconf.dictconfig import DictConfig  # type: ignore[import]\r\n-        from omegaconf.base import ContainerMetadata  # type: ignore[import]\r\n+        logger.info(\"GigaAM-v3 model loaded successfully\")\r\n \r\n-        # Разрешаем используемые типы\r\n-        _ts.add_safe_globals([DictConfig, ContainerMetadata, Any, dict])\r\n-\r\n-        # Глобально возвращаем поведение torch.load как до 2.6:\r\n-        # weights_only=False по умолчанию.\r\n-        if hasattr(torch.serialization, \"_weights_only_by_default\"):\r\n-            torch.serialization._weights_only_by_default = False  # type: ignore[attr-defined]\r\n-\r\n-        # Дополнительно переопределяем torch.load, чтобы всегда вызывать его с weights_only=False.\r\n-        _orig_torch_load = torch.load\r\n-\r\n-        def _patched_torch_load(*args, **kwargs):\r\n-            # если явно не передан weights_only, принудительно ставим False\r\n-            if \"weights_only\" not in kwargs:\r\n-                kwargs[\"weights_only\"] = False\r\n-            return _orig_torch_load(*args, **kwargs)\r\n-\r\n-        torch.load = _patched_torch_load  # type: ignore[assignment]\r\n-\r\n\\ No newline at end of file\n-        self.model = gigaam.load_model(\r\n-            self.model_name,\r\n-            device=device,\r\n-        )\r\n-\r\n     def transcribe(self, audio: AudioData) -> str:\r\n         \"\"\"\r\n-        Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n+        Принимает AudioData и возвращает текст с пунктуацией.\r\n \r\n-        Для надёжности пишем во временный WAV и даём путь модели.\r\n+        ВНИМАНИЕ: официальный API модели ожидает путь к аудиофайлу.\r\n+        Поэтому мы сохраняем временный WAV и передаём путь в model.transcribe().\r\n         \"\"\"\r\n+        import tempfile\r\n+        import soundfile as sf  # type: ignore[import]\r\n+        import numpy as np  # type: ignore[import]\r\n+\r\n+        # Создаём временный WAV-файл\r\n         with tempfile.TemporaryDirectory() as tmpdir:\r\n             wav_path = Path(tmpdir) / \"input.wav\"\r\n \r\n-            # Сохраняем numpy → WAV (16kHz mono, PCM_16)\r\n+            samples = audio.samples\r\n+            if isinstance(samples, np.ndarray):\r\n+                if samples.ndim == 2 and samples.shape[1] == 1:\r\n+                    samples = samples[:, 0]\r\n+                samples = samples.astype(\"float32\")\r\n+            else:\r\n+                samples = np.asarray(samples, dtype=\"float32\")\r\n+\r\n             sf.write(\r\n                 wav_path,\r\n-                audio.samples,\r\n+                samples,\r\n                 audio.sample_rate,\r\n                 format=\"WAV\",\r\n-                subtype=\"PCM_16\",\r\n             )\r\n \r\n             try:\r\n-                text = self.model.transcribe(str(wav_path))\r\n+                # Официальный API: модель сама читает файл и делает всю обработку\r\n+                transcription = self.model.transcribe(str(wav_path))\r\n             except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"GigaAM transcribe error: {}\", exc)\r\n-                raise RuntimeError(\"GigaAM: ошибка распознавания.\") from exc\r\n+                logger.exception(\"GigaAM-v3 transcribe error: {}\", exc)\r\n+                raise RuntimeError(\"GigaAM-v3: ошибка распознавания.\") from exc\r\n \r\n-        if not isinstance(text, str):\r\n-            logger.error(\"GigaAM returned non-string transcription: {}\", text)\r\n-            raise RuntimeError(\"GigaAM: некорректный формат ответа.\")\r\n+        if not isinstance(transcription, str):\r\n+            logger.error(\"GigaAM-v3 returned non-string transcription: {}\", transcription)\r\n+            raise RuntimeError(\"GigaAM-v3: некорректный формат ответа.\")\r\n \r\n-        return text or \"\"\n+        return transcription or \"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764466690652,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,18 +36,28 @@\n             self.HF_REVISION,\r\n             self.device,\r\n         )\r\n \r\n-        # Загружаем модель с trust_remote_code=True и корректным dtype\r\n-        torch_dtype = torch.float16 if self.device == \"cuda\" else torch.float32\r\n+        # ВАЖНО:\r\n+        # Официальные примеры используют float16 только на GPU.\r\n+        # На CPU должны быть и входы, и веса в float32, иначе получаем:\r\n+        # \"Input type (float) and bias type (struct c10::Half) should be the same\".\r\n+        import torch  # локальный импорт\r\n \r\n+        if self.device == \"cuda\":\r\n+            torch_dtype = torch.float16\r\n+        else:\r\n+            torch_dtype = torch.float32\r\n+\r\n         try:\r\n             self.model = AutoModel.from_pretrained(\r\n                 self.HF_MODEL_ID,\r\n                 revision=self.HF_REVISION,\r\n                 trust_remote_code=True,\r\n                 torch_dtype=torch_dtype,\r\n             ).to(self.device)\r\n+            # На всякий случай приводим модель к нужному dtype ещё раз\r\n+            self.model = self.model.to(dtype=torch_dtype, device=self.device)\r\n         except Exception as exc:  # noqa: BLE001\r\n             logger.exception(\"Failed to load GigaAM-v3 model: {}\", exc)\r\n             raise RuntimeError(\"GigaAM-v3: ошибка загрузки модели.\") from exc\r\n \r\n"
                }
            ],
            "date": 1764457705620,
            "name": "Commit-0",
            "content": "from __future__ import annotations\r\n\r\nimport tempfile\r\nfrom pathlib import Path\r\n\r\nimport gigaam  # type: ignore[import]\r\nimport soundfile as sf  # type: ignore[import]\r\nfrom loguru import logger  # type: ignore[import]\r\n\r\nfrom audio.recorder import AudioData\r\n\r\n\r\nclass GigaAMRecognizer:\r\n    \"\"\"\r\n    Локальный распознаватель на базе GigaAM-v3-CTC (API: v2_ctc).\r\n\r\n    Используется как backend \"local\" наряду с Groq и OpenAI.\r\n    Интерфейс совместим с GroqWhisperRecognizer: метод transcribe(audio) -> str.\r\n    \"\"\"\r\n\r\n    def __init__(self, model_name: str = \"v2_ctc\") -> None:\r\n        self.model_name = model_name\r\n        logger.info(\"Loading GigaAM model: {}\", model_name)\r\n        # Модель автоматически скачивается при первом запуске.\r\n        self.model = gigaam.load_model(model_name)\r\n\r\n    def transcribe(self, audio: AudioData) -> str:\r\n        \"\"\"\r\n        Принимает AudioData (float32 numpy, 16kHz mono) и возвращает текст.\r\n\r\n        Для надёжности пишем во временный WAV и даём путь модели.\r\n        \"\"\"\r\n        with tempfile.TemporaryDirectory() as tmpdir:\r\n            wav_path = Path(tmpdir) / \"input.wav\"\r\n\r\n            # Сохраняем numpy → WAV (16kHz mono, PCM_16)\r\n            sf.write(\r\n                wav_path,\r\n                audio.samples,\r\n                audio.sample_rate,\r\n                format=\"WAV\",\r\n                subtype=\"PCM_16\",\r\n            )\r\n\r\n            try:\r\n                text = self.model.transcribe(str(wav_path))\r\n            except Exception as exc:  # noqa: BLE001\r\n                logger.exception(\"GigaAM transcribe error: {}\", exc)\r\n                raise RuntimeError(\"GigaAM: ошибка распознавания.\") from exc\r\n\r\n        if not isinstance(text, str):\r\n            logger.error(\"GigaAM returned non-string transcription: {}\", text)\r\n            raise RuntimeError(\"GigaAM: некорректный формат ответа.\")\r\n\r\n        return text or \"\""
        }
    ]
}
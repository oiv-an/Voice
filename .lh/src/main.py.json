{
    "sourceFile": "src/main.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 37,
            "patches": [
                {
                    "date": 1764291847746,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1764294103165,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,10 +115,24 @@\n         try:\r\n             self.window.set_state(\"processing\")\r\n             text = self.recognizer.transcribe(audio_data)\r\n             text = self.postprocessor.process(text)\r\n+\r\n+            # показать распознанный текст в окне\r\n+            try:\r\n+                # result_label добавлен во FloatingWindow\r\n+                self.window.result_label.setText(text)\r\n+            except Exception:\r\n+                # если по какой-то причине нет result_label — просто игнорируем\r\n+                pass\r\n+\r\n+            # положить текст в буфер обмена\r\n             self.clipboard.copy(text)\r\n+\r\n+            # авто-вставка сейчас отключена (paste() — заглушка),\r\n+            # пользователь вставляет текст вручную через Ctrl+V\r\n             self.clipboard.paste()\r\n+\r\n             self.window.set_state(\"ready\")\r\n         except Exception as exc:  # noqa: BLE001\r\n             from loguru import logger\r\n \r\n"
                },
                {
                    "date": 1764295812842,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,11 +76,33 @@\n         else:\r\n             self.show_window()\r\n \r\n     def open_settings_dialog(self) -> None:\r\n-        # Placeholder: real implementation will open SettingsDialog\r\n-        self.window.show_message(\"Settings dialog is not implemented yet (MVP skeleton).\")\r\n+        \"\"\"\r\n+        Открыть диалог настроек:\r\n+        - выбор backend'а (Groq / OpenAI)\r\n+        - ввод API-ключей и base URL\r\n+        - обновление настроек и пересоздание recognizer'а\r\n+        \"\"\"\r\n+        from ui.settings_dialog import SettingsDialog\r\n \r\n+        dlg = SettingsDialog(self.settings, parent=self.window)\r\n+        if dlg.exec() != dlg.DialogCode.Accepted:\r\n+            return\r\n+\r\n+        new_settings = dlg.get_result()\r\n+        if new_settings is None:\r\n+            return\r\n+\r\n+        # обновляем настройки в приложении\r\n+        self.settings = new_settings\r\n+\r\n+        # пересоздаём recognizer с новыми параметрами\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+\r\n+        # сообщаем пользователю\r\n+        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+\r\n     # ----------------------------------------------------------------- Hotkeys\r\n \r\n     def start_recording(self) -> None:\r\n         if self._is_recording:\r\n"
                },
                {
                    "date": 1764295922499,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -70,13 +70,19 @@\n         self.window.raise_()\r\n         self.window.activateWindow()\r\n \r\n     def toggle_window_visibility(self) -> None:\r\n-        if self.window.isVisible():\r\n-            self.window.hide()\r\n-        else:\r\n-            self.show_window()\r\n+        \"\"\"\r\n+        Горячая клавиша \"Показать/скрыть окно\".\r\n \r\n+        Для твоего сценария окно должно быть ВСЕГДА видно, поэтому\r\n+        мы больше не будем его прятать, а только:\r\n+        - если оно свернуто в компактный режим — разворачивать,\r\n+        - если оно где-то \"потерялось\" — показывать и поднимать наверх.\r\n+        \"\"\"\r\n+        # просто гарантируем, что окно показано и на переднем плане\r\n+        self.show_window()\r\n+\r\n     def open_settings_dialog(self) -> None:\r\n         \"\"\"\r\n         Открыть диалог настроек:\r\n         - выбор backend'а (Groq / OpenAI)\r\n"
                },
                {
                    "date": 1764300224731,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -83,31 +83,41 @@\n         self.show_window()\r\n \r\n     def open_settings_dialog(self) -> None:\r\n         \"\"\"\r\n-        Открыть диалог настроек:\r\n-        - выбор backend'а (Groq / OpenAI)\r\n-        - ввод API-ключей и base URL\r\n-        - обновление настроек и пересоздание recognizer'а\r\n+        Открыть панель настроек внутри основного окна.\r\n+\r\n+        ВАЖНО: все значения берём/кладём только в config.yaml через AppSettings.\r\n         \"\"\"\r\n-        from ui.settings_dialog import SettingsDialog\r\n+        # показать окно\r\n+        self.show_window()\r\n \r\n-        dlg = SettingsDialog(self.settings, parent=self.window)\r\n-        if dlg.exec() != dlg.DialogCode.Accepted:\r\n-            return\r\n+        # заполнить UI текущими значениями из self.settings\r\n+        rec = self.settings.recognition\r\n+        post = self.settings.postprocess\r\n \r\n-        new_settings = dlg.get_result()\r\n-        if new_settings is None:\r\n-            return\r\n+        # backend\r\n+        backend_value = (rec.backend or \"groq\").lower()\r\n+        idx = self.window.settings_backend_combo.findData(backend_value)\r\n+        if idx >= 0:\r\n+            self.window.settings_backend_combo.setCurrentIndex(idx)\r\n \r\n-        # обновляем настройки в приложении\r\n-        self.settings = new_settings\r\n+        # API keys / base URL\r\n+        self.window.settings_groq_key.setText(rec.groq.api_key or \"\")\r\n+        self.window.settings_openai_key.setText(rec.openai.api_key or \"\")\r\n+        self.window.settings_openai_url.setText(rec.openai.base_url or \"\")\r\n \r\n-        # пересоздаём recognizer с новыми параметрами\r\n-        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        # postprocess\r\n+        self.window.postprocess_enabled_checkbox.setChecked(post.enabled)\r\n+        self.window.postprocess_groq_model.setText(\r\n+            (post.groq.model or \"moonshotai/kimi-k2-instruct\")\r\n+        )\r\n+        self.window.postprocess_openai_model.setText(\r\n+            (post.openai.model or \"gpt-4\")\r\n+        )\r\n \r\n-        # сообщаем пользователю\r\n-        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+        # переключаем окно в режим настроек\r\n+        self.window._enter_settings_mode()\r\n \r\n     # ----------------------------------------------------------------- Hotkeys\r\n \r\n     def start_recording(self) -> None:\r\n"
                },
                {
                    "date": 1764300336323,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,8 +56,9 @@\n         )\r\n \r\n         # Wire UI signals\r\n         self.window.settings_requested.connect(self.open_settings_dialog)\r\n+        self.window.settings_save_requested.connect(self._on_settings_save_requested)\r\n         self.window.exit_requested.connect(self.quit)\r\n         self.tray.show_window_requested.connect(self.show_window)\r\n         self.tray.settings_requested.connect(self.open_settings_dialog)\r\n         self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n"
                },
                {
                    "date": 1764300531469,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -184,8 +184,50 @@\n     def toggle_debug_mode(self) -> None:\r\n         # Placeholder: will reconfigure logging level later\r\n         self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n \r\n+    # ----------------------------------------------------------- Settings save\r\n+\r\n+    def _on_settings_save_requested(self) -> None:\r\n+        \"\"\"\r\n+        Пользователь нажал «Сохранить» в панели настроек.\r\n+        Читаем значения из UI, обновляем self.settings, сохраняем в config.yaml\r\n+        и пересоздаём recognizer/postprocessor.\r\n+        \"\"\"\r\n+        from config.settings import AppSettings  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        rec = self.settings.recognition\r\n+        post = self.settings.postprocess\r\n+\r\n+        # 1) backend\r\n+        backend_data = self.window.settings_backend_combo.currentData()\r\n+        if backend_data in (\"groq\", \"openai\", \"local\"):\r\n+            rec.backend = backend_data\r\n+\r\n+        # 2) API keys / base URL\r\n+        rec.groq.api_key = self.window.settings_groq_key.text().strip()\r\n+        rec.openai.api_key = self.window.settings_openai_key.text().strip()\r\n+        base_url = self.window.settings_openai_url.text().strip()\r\n+        if base_url:\r\n+            rec.openai.base_url = base_url\r\n+\r\n+        # 3) postprocess\r\n+        post.enabled = self.window.postprocess_enabled_checkbox.isChecked()\r\n+        groq_model = self.window.postprocess_groq_model.text().strip()\r\n+        openai_model = self.window.postprocess_openai_model.text().strip()\r\n+        post.groq.model = groq_model or \"moonshotai/kimi-k2-instruct\"\r\n+        post.openai.model = openai_model or \"gpt-4\"\r\n+\r\n+        # 4) сохранить всё в config.yaml\r\n+        AppSettings.save_default(self.settings)\r\n+\r\n+        # 5) пересоздать recognizer и postprocessor\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        self.postprocessor = TextPostprocessor(self.settings.postprocess)\r\n+\r\n+        # 6) показать уведомление\r\n+        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+\r\n     # -------------------------------------------------------------- Lifecycle\r\n \r\n     def quit(self) -> None:\r\n         self.hotkeys.stop()\r\n"
                },
                {
                    "date": 1764300667772,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -38,8 +38,21 @@\n         self.audio_recorder = AudioRecorder(self.settings.audio)\r\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n         self.postprocessor = TextPostprocessor(self.settings.postprocess)\r\n \r\n+        # Первое сообщение: если нет ключа для текущего backend'а — подсказка пользователю\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        missing_key = False\r\n+        if backend == \"groq\" and not (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            missing_key = True\r\n+        elif backend == \"openai\" and not (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            missing_key = True\r\n+\r\n+        if missing_key:\r\n+            self.window.result_label.setText(\r\n+                \"Добавьте API‑ключ в настройках (⚙️) перед использованием распознавания.\"\r\n+            )\r\n+\r\n         # State\r\n         self._is_recording: bool = False\r\n \r\n         # Hotkeys\r\n"
                },
                {
                    "date": 1764301634152,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -163,8 +163,10 @@\n     # ----------------------------------------------------------- Processing\r\n \r\n     def _process_audio(self, audio_data) -> None:\r\n         \"\"\"Synchronous processing for MVP; later can be moved to worker thread.\"\"\"\r\n+        from loguru import logger\r\n+\r\n         try:\r\n             self.window.set_state(\"processing\")\r\n             text = self.recognizer.transcribe(audio_data)\r\n             text = self.postprocessor.process(text)\r\n@@ -174,24 +176,27 @@\n                 # result_label добавлен во FloatingWindow\r\n                 self.window.result_label.setText(text)\r\n             except Exception:\r\n                 # если по какой-то причине нет result_label — просто игнорируем\r\n-                pass\r\n+                logger.debug(\"result_label is not available on window\")\r\n \r\n             # положить текст в буфер обмена\r\n             self.clipboard.copy(text)\r\n \r\n-            # авто-вставка сейчас отключена (paste() — заглушка),\r\n-            # пользователь вставляет текст вручную через Ctrl+V\r\n+            # авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n             self.clipboard.paste()\r\n \r\n             self.window.set_state(\"ready\")\r\n+        except RuntimeError as exc:\r\n+            # Осмысленные ошибки от распознавания (например, Groq API)\r\n+            logger.error(\"Processing error: {}\", exc)\r\n+            self.window.set_state(\"error\")\r\n+            # Показываем пользователю человекочитаемое сообщение\r\n+            self.window.show_message(str(exc))\r\n         except Exception as exc:  # noqa: BLE001\r\n-            from loguru import logger\r\n-\r\n-            logger.exception(\"Error during processing: {}\", exc)\r\n+            logger.exception(\"Unexpected error during processing: {}\", exc)\r\n             self.window.set_state(\"error\")\r\n-            self.window.show_message(\"Error during recognition. See logs.\")\r\n+            self.window.show_message(\"Неизвестная ошибка распознавания. См. логи.\")\r\n \r\n     # -------------------------------------------------------------- Debug\r\n \r\n     def toggle_debug_mode(self) -> None:\r\n"
                },
                {
                    "date": 1764301744720,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -121,15 +121,17 @@\n         self.window.settings_openai_url.setText(rec.openai.base_url or \"\")\r\n \r\n         # postprocess\r\n         self.window.postprocess_enabled_checkbox.setChecked(post.enabled)\r\n-        self.window.postprocess_groq_model.setText(\r\n-            (post.groq.model or \"moonshotai/kimi-k2-instruct\")\r\n-        )\r\n-        self.window.postprocess_openai_model.setText(\r\n-            (post.openai.model or \"gpt-4\")\r\n-        )\r\n \r\n+        # Если в конфиге пустые строки, подставляем дефолты,\r\n+        # чтобы поля в UI были уже заполнены при первом открытии.\r\n+        groq_model = (post.groq.model or \"\").strip() or \"moonshotai/kimi-k2-instruct\"\r\n+        openai_model = (post.openai.model or \"\").strip() or \"gpt-4\"\r\n+\r\n+        self.window.postprocess_groq_model.setText(groq_model)\r\n+        self.window.postprocess_openai_model.setText(openai_model)\r\n+\r\n         # переключаем окно в режим настроек\r\n         self.window._enter_settings_mode()\r\n \r\n     # ----------------------------------------------------------------- Hotkeys\r\n"
                },
                {
                    "date": 1764302203231,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -124,10 +124,13 @@\n         self.window.postprocess_enabled_checkbox.setChecked(post.enabled)\r\n \r\n         # Если в конфиге пустые строки, подставляем дефолты,\r\n         # чтобы поля в UI были уже заполнены при первом открытии.\r\n-        groq_model = (post.groq.model or \"\").strip() or \"moonshotai/kimi-k2-instruct\"\r\n-        openai_model = (post.openai.model or \"\").strip() or \"gpt-4\"\r\n+        # По твоему запросу:\r\n+        #   - Groq postprocess model:   llama-3.1-70b-versatile\r\n+        #   - OpenAI postprocess model: gpt-4.1\r\n+        groq_model = (post.groq.model or \"\").strip() or \"llama-3.1-70b-versatile\"\r\n+        openai_model = (post.openai.model or \"\").strip() or \"gpt-4.1\"\r\n \r\n         self.window.postprocess_groq_model.setText(groq_model)\r\n         self.window.postprocess_openai_model.setText(openai_model)\r\n \r\n"
                },
                {
                    "date": 1764302316559,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,12 +125,12 @@\n \r\n         # Если в конфиге пустые строки, подставляем дефолты,\r\n         # чтобы поля в UI были уже заполнены при первом открытии.\r\n         # По твоему запросу:\r\n-        #   - Groq postprocess model:   llama-3.1-70b-versatile\r\n-        #   - OpenAI postprocess model: gpt-4.1\r\n-        groq_model = (post.groq.model or \"\").strip() or \"llama-3.1-70b-versatile\"\r\n-        openai_model = (post.openai.model or \"\").strip() or \"gpt-4.1\"\r\n+        #   - Groq postprocess model:   moonshotai/kimi-k2-instruct\r\n+        #   - OpenAI postprocess model: gpt-5.1\r\n+        groq_model = (post.groq.model or \"\").strip() or \"moonshotai/kimi-k2-instruct\"\r\n+        openai_model = (post.openai.model or \"\").strip() or \"gpt-5.1\"\r\n \r\n         self.window.postprocess_groq_model.setText(groq_model)\r\n         self.window.postprocess_openai_model.setText(openai_model)\r\n \r\n"
                },
                {
                    "date": 1764303019785,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -172,21 +172,44 @@\n         from loguru import logger\r\n \r\n         try:\r\n             self.window.set_state(\"processing\")\r\n-            text = self.recognizer.transcribe(audio_data)\r\n-            text = self.postprocessor.process(text)\r\n+            # 1) сырой текст от Whisper\r\n+            raw_text = self.recognizer.transcribe(audio_data)\r\n \r\n-            # показать распознанный текст в окне\r\n+            # 2) regex-очистка (базовый препроцессинг всегда)\r\n+            from recognition.postprocessor import TextPostprocessor as TP  # локальный импорт для статик-метода\r\n+            regex_text = TP._simple_cleanup(raw_text or \"\")\r\n+\r\n+            # 3) LLM-постпроцессинг (если включён в конфиге)\r\n+            processed_text = regex_text\r\n             try:\r\n-                # result_label добавлен во FloatingWindow\r\n-                self.window.result_label.setText(text)\r\n+                processed_text = self.postprocessor.process(raw_text or \"\")\r\n+            except RuntimeError as exc:\r\n+                # осмысленные ошибки LLM\r\n+                logger.error(\"LLM postprocess error: {}\", exc)\r\n+                self.window.show_message(str(exc))\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n+\r\n+            # 4) показать оба варианта в окне\r\n+            try:\r\n+                # верхний блок — сырой текст от Whisper\r\n+                if hasattr(self.window, \"set_raw_text\"):\r\n+                    self.window.set_raw_text(raw_text or \"\")\r\n+                else:\r\n+                    # fallback в старый result_label\r\n+                    self.window.result_label.setText(processed_text)\r\n+\r\n+                # нижний блок — обработанный текст (regex/LLM)\r\n+                if hasattr(self.window, \"set_processed_text\"):\r\n+                    self.window.set_processed_text(processed_text)\r\n             except Exception:\r\n-                # если по какой-то причине нет result_label — просто игнорируем\r\n-                logger.debug(\"result_label is not available on window\")\r\n+                logger.debug(\"window text update failed\", exc_info=True)\r\n \r\n-            # положить текст в буфер обмена\r\n-            self.clipboard.copy(text)\r\n+            # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+            self.clipboard.copy(processed_text)\r\n \r\n             # авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n             self.clipboard.paste()\r\n \r\n"
                },
                {
                    "date": 1764305709575,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -249,28 +249,46 @@\n         if backend_data in (\"groq\", \"openai\", \"local\"):\r\n             rec.backend = backend_data\r\n \r\n         # 2) API keys / base URL\r\n-        rec.groq.api_key = self.window.settings_groq_key.text().strip()\r\n-        rec.openai.api_key = self.window.settings_openai_key.text().strip()\r\n+        rec.groq.api_key = self.window.settings_groq_key.text().strip() or rec.groq.api_key\r\n+        rec.openai.api_key = self.window.settings_openai_key.text().strip() or rec.openai.api_key\r\n         base_url = self.window.settings_openai_url.text().strip()\r\n         if base_url:\r\n             rec.openai.base_url = base_url\r\n \r\n         # 3) postprocess\r\n         post.enabled = self.window.postprocess_enabled_checkbox.isChecked()\r\n-        groq_model = self.window.postprocess_groq_model.text().strip()\r\n-        openai_model = self.window.postprocess_openai_model.text().strip()\r\n-        post.groq.model = groq_model or \"moonshotai/kimi-k2-instruct\"\r\n-        post.openai.model = openai_model or \"gpt-4\"\r\n \r\n+        # модели LLM: пишем в recognition.*.model_process и синхронизируем postprocess.*.model\r\n+        groq_model_proc = self.window.postprocess_groq_model.text().strip()\r\n+        if groq_model_proc:\r\n+            rec.groq.model_process = groq_model_proc\r\n+            post.groq.model = groq_model_proc\r\n+\r\n+        openai_model_proc = self.window.postprocess_openai_model.text().strip()\r\n+        if openai_model_proc:\r\n+            rec.openai.model_process = openai_model_proc\r\n+            post.openai.model = openai_model_proc\r\n+\r\n         # 4) сохранить всё в config.yaml\r\n         AppSettings.save_default(self.settings)\r\n \r\n         # 5) пересоздать recognizer и postprocessor\r\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n-        self.postprocessor = TextPostprocessor(self.settings.postprocess)\r\n \r\n+        post_cfg = self.settings.postprocess\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            post_cfg.groq.api_key = rec.groq.api_key\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec.groq.model_process)\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            post_cfg.openai.api_key = rec.openai.api_key\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec.openai.model_process)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n         # 6) показать уведомление\r\n         self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n \r\n     # -------------------------------------------------------------- Lifecycle\r\n"
                },
                {
                    "date": 1764305899180,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,10 +36,29 @@\n         self.tray = SystemTrayIcon(self.window, self.settings.app)\r\n         self.clipboard = ClipboardManager()\r\n         self.audio_recorder = AudioRecorder(self.settings.audio)\r\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n-        self.postprocessor = TextPostprocessor(self.settings.postprocess)\r\n \r\n+        # Постпроцессинг текста.\r\n+        # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ и model_process,\r\n+        # что и в recognition.*, чтобы LLM работал уже при первом запуске.\r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            # один ключ Groq: берём из recognition.groq.api_key\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            # модель LLM: из recognition.groq.model_process\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n         # Первое сообщение: если нет ключа для текущего backend'а — подсказка пользователю\r\n         backend = (self.settings.recognition.backend or \"groq\").lower()\r\n         missing_key = False\r\n         if backend == \"groq\" and not (self.settings.recognition.groq.api_key or \"\").strip():\r\n@@ -277,13 +296,13 @@\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n \r\n         post_cfg = self.settings.postprocess\r\n         if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n-            post_cfg.groq.api_key = rec.groq.api_key\r\n+            setattr(post_cfg.groq, \"api_key\", rec.groq.api_key)\r\n             if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n                 setattr(post_cfg.groq, \"model_process\", rec.groq.model_process)\r\n         if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n-            post_cfg.openai.api_key = rec.openai.api_key\r\n+            setattr(post_cfg.openai, \"api_key\", rec.openai.api_key)\r\n             if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n                 setattr(post_cfg.openai, \"model_process\", rec.openai.model_process)\r\n \r\n         self.postprocessor = TextPostprocessor(post_cfg)\r\n"
                },
                {
                    "date": 1764422294029,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -184,22 +184,24 @@\n         self.audio_recorder.cancel()\r\n         self.window.set_state(\"idle\")\r\n \r\n     # ----------------------------------------------------------- Processing\r\n-\r\n+    \r\n     def _process_audio(self, audio_data) -> None:\r\n         \"\"\"Synchronous processing for MVP; later can be moved to worker thread.\"\"\"\r\n         from loguru import logger\r\n-\r\n+        from pathlib import Path\r\n+        from datetime import datetime\r\n+    \r\n         try:\r\n             self.window.set_state(\"processing\")\r\n             # 1) сырой текст от Whisper\r\n             raw_text = self.recognizer.transcribe(audio_data)\r\n-\r\n+    \r\n             # 2) regex-очистка (базовый препроцессинг всегда)\r\n             from recognition.postprocessor import TextPostprocessor as TP  # локальный импорт для статик-метода\r\n             regex_text = TP._simple_cleanup(raw_text or \"\")\r\n-\r\n+    \r\n             # 3) LLM-постпроцессинг (если включён в конфиге)\r\n             processed_text = regex_text\r\n             try:\r\n                 processed_text = self.postprocessor.process(raw_text or \"\")\r\n@@ -209,30 +211,56 @@\n                 self.window.show_message(str(exc))\r\n             except Exception as exc:  # noqa: BLE001\r\n                 logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n                 self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n-\r\n+    \r\n             # 4) показать оба варианта в окне\r\n             try:\r\n                 # верхний блок — сырой текст от Whisper\r\n                 if hasattr(self.window, \"set_raw_text\"):\r\n                     self.window.set_raw_text(raw_text or \"\")\r\n                 else:\r\n                     # fallback в старый result_label\r\n                     self.window.result_label.setText(processed_text)\r\n-\r\n+    \r\n                 # нижний блок — обработанный текст (regex/LLM)\r\n                 if hasattr(self.window, \"set_processed_text\"):\r\n                     self.window.set_processed_text(processed_text)\r\n             except Exception:\r\n                 logger.debug(\"window text update failed\", exc_info=True)\r\n-\r\n+    \r\n             # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n             self.clipboard.copy(processed_text)\r\n-\r\n+    \r\n             # авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n             self.clipboard.paste()\r\n-\r\n+    \r\n+            # 6) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+            try:\r\n+                base_dir = Path(__file__).resolve().parents[2]\r\n+                log_dir = base_dir / \"logs\"\r\n+                log_dir.mkdir(parents=True, exist_ok=True)\r\n+                transcript_path = log_dir / \"transcripts.log\"\r\n+    \r\n+                # простая ротация: если файл больше 3 МБ — переименовать в transcripts_YYYYmmdd_HHMMSS.log\r\n+                max_size_bytes = 3 * 1024 * 1024\r\n+                if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n+                    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n+                    rotated = log_dir / f\"transcripts_{ts}.log\"\r\n+                    transcript_path.rename(rotated)\r\n+    \r\n+                # формат записи: время, сырой текст, обработанный текст\r\n+                with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n+                    f.write(\r\n+                        f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]\\\\n\"\r\n+                        f\"RAW: { (raw_text or '').strip() }\\\\n\"\r\n+                        f\"PROCESSED: { (processed_text or '').strip() }\\\\n\"\r\n+                        \"----------------------------------------\\\\n\"\r\n+                    )\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                # не ломаем основной флоу, если что-то пошло не так с логом\r\n+                logger.exception(\"Failed to append transcript log: {}\", exc)\r\n+    \r\n             self.window.set_state(\"ready\")\r\n         except RuntimeError as exc:\r\n             # Осмысленные ошибки от распознавания (например, Groq API)\r\n             logger.error(\"Processing error: {}\", exc)\r\n"
                },
                {
                    "date": 1764456211724,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -286,44 +286,44 @@\n         Читаем значения из UI, обновляем self.settings, сохраняем в config.yaml\r\n         и пересоздаём recognizer/postprocessor.\r\n         \"\"\"\r\n         from config.settings import AppSettings  # локальный импорт, чтобы избежать циклов\r\n-\r\n+    \r\n         rec = self.settings.recognition\r\n         post = self.settings.postprocess\r\n-\r\n+    \r\n         # 1) backend\r\n         backend_data = self.window.settings_backend_combo.currentData()\r\n         if backend_data in (\"groq\", \"openai\", \"local\"):\r\n             rec.backend = backend_data\r\n-\r\n+    \r\n         # 2) API keys / base URL\r\n         rec.groq.api_key = self.window.settings_groq_key.text().strip() or rec.groq.api_key\r\n         rec.openai.api_key = self.window.settings_openai_key.text().strip() or rec.openai.api_key\r\n         base_url = self.window.settings_openai_url.text().strip()\r\n         if base_url:\r\n             rec.openai.base_url = base_url\r\n-\r\n+    \r\n         # 3) postprocess\r\n         post.enabled = self.window.postprocess_enabled_checkbox.isChecked()\r\n-\r\n+    \r\n         # модели LLM: пишем в recognition.*.model_process и синхронизируем postprocess.*.model\r\n         groq_model_proc = self.window.postprocess_groq_model.text().strip()\r\n         if groq_model_proc:\r\n             rec.groq.model_process = groq_model_proc\r\n             post.groq.model = groq_model_proc\r\n-\r\n+    \r\n         openai_model_proc = self.window.postprocess_openai_model.text().strip()\r\n         if openai_model_proc:\r\n             rec.openai.model_process = openai_model_proc\r\n             post.openai.model = openai_model_proc\r\n-\r\n+    \r\n         # 4) сохранить всё в config.yaml\r\n         AppSettings.save_default(self.settings)\r\n-\r\n+    \r\n         # 5) пересоздать recognizer и postprocessor\r\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n-\r\n+    \r\n         post_cfg = self.settings.postprocess\r\n         if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n             setattr(post_cfg.groq, \"api_key\", rec.groq.api_key)\r\n             if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n@@ -331,12 +331,28 @@\n         if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n             setattr(post_cfg.openai, \"api_key\", rec.openai.api_key)\r\n             if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n                 setattr(post_cfg.openai, \"model_process\", rec.openai.model_process)\r\n-\r\n+    \r\n         self.postprocessor = TextPostprocessor(post_cfg)\r\n-\r\n-        # 6) показать уведомление\r\n+    \r\n+        # 6) если теперь ключи заданы — убрать предупреждающую надпись\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        has_key = False\r\n+        if backend == \"groq\" and (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            has_key = True\r\n+        elif backend == \"openai\" and (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            has_key = True\r\n+    \r\n+        if has_key:\r\n+            # очищаем все текстовые блоки, чтобы не висело старое предупреждение\r\n+            if hasattr(self.window, \"set_raw_text\"):\r\n+                self.window.set_raw_text(\"\")\r\n+            if hasattr(self.window, \"set_processed_text\"):\r\n+                self.window.set_processed_text(\"\")\r\n+            self.window.result_label.setText(\"\")\r\n+    \r\n+        # 7) показать уведомление\r\n         self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n \r\n     # -------------------------------------------------------------- Lifecycle\r\n \r\n"
                },
                {
                    "date": 1764458293169,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,9 +20,9 @@\n \r\n     MVP workflow:\r\n         global hotkey (record) down   -> start_recording()\r\n         global hotkey (record) up     -> stop_recording()\r\n-        audio -> recognizer (Groq) -> postprocess -> clipboard.copy + paste\r\n+        audio -> recognizer (Groq/GigaAM) -> postprocess -> clipboard.copy + paste\r\n     \"\"\"\r\n \r\n     def __init__(self) -> None:\r\n         self.qt_app = QApplication(sys.argv)\r\n@@ -73,8 +73,64 @@\n \r\n         # State\r\n         self._is_recording: bool = False\r\n \r\n+        # Worker thread for heavy audio processing (GigaAM / Groq / LLM)\r\n+        from PyQt6.QtCore import QObject, QThread, pyqtSignal\r\n+\r\n+        class _ProcessingWorker(QObject):\r\n+            finished = pyqtSignal()\r\n+            error = pyqtSignal(str)\r\n+            result_ready = pyqtSignal(str, str)  # raw_text, processed_text\r\n+\r\n+            def __init__(self, app_ref: \"App\", audio_data) -> None:\r\n+                super().__init__()\r\n+                self._app_ref = app_ref\r\n+                self._audio_data = audio_data\r\n+\r\n+            def run(self) -> None:\r\n+                \"\"\"\r\n+                Выполняется в отдельном потоке:\r\n+                - распознавание (Groq/GigaAM)\r\n+                - regex + LLM постобработка\r\n+                Никаких Qt-объектов/виджетов здесь не трогаем.\r\n+                \"\"\"\r\n+                from loguru import logger\r\n+                from recognition.postprocessor import TextPostprocessor as TP\r\n+\r\n+                try:\r\n+                    raw_text = self._app_ref.recognizer.transcribe(self._audio_data)\r\n+                    regex_text = TP._simple_cleanup(raw_text or \"\")\r\n+\r\n+                    processed_text = regex_text\r\n+                    try:\r\n+                        processed_text = self._app_ref.postprocessor.process(raw_text or \"\")\r\n+                    except RuntimeError as exc:\r\n+                        logger.error(\"LLM postprocess error: {}\", exc)\r\n+                        # Передаём текст ошибки наверх, чтобы UI показал его\r\n+                        self.error.emit(str(exc))\r\n+                    except Exception as exc:  # noqa: BLE001\r\n+                        logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                        self.error.emit(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n+\r\n+                    self.result_ready.emit(raw_text or \"\", processed_text or \"\")\r\n+                except RuntimeError as exc:\r\n+                    # Осмысленные ошибки от распознавания (например, Groq/GigaAM)\r\n+                    from loguru import logger as _logger\r\n+\r\n+                    _logger.error(\"Processing error: {}\", exc)\r\n+                    self.error.emit(str(exc))\r\n+                except Exception as exc:  # noqa: BLE001\r\n+                    from loguru import logger as _logger\r\n+\r\n+                    _logger.exception(\"Unexpected error during processing: {}\", exc)\r\n+                    self.error.emit(\"Неизвестная ошибка распознавания. См. логи.\")\r\n+                finally:\r\n+                    self.finished.emit()\r\n+\r\n+        self._ProcessingWorker = _ProcessingWorker  # type: ignore[attr-defined]\r\n+        self._processing_thread: Optional[QThread] = None\r\n+\r\n         # Hotkeys\r\n         self.hotkeys = HotKeyManager(\r\n             record_hotkey=self.settings.hotkeys.record,\r\n             cancel_hotkey=self.settings.hotkeys.cancel,\r\n@@ -165,10 +221,11 @@\n         self.window.set_state(\"recording\")\r\n \r\n         def on_finished(audio_data):\r\n             # Этот колбэк вызывается из потока рекордера.\r\n-            # Для MVP просто передаём данные в обработку синхронно.\r\n-            self._process_audio(audio_data)\r\n+            # Теперь только запускаем воркер в отдельном QThread,\r\n+            # а UI обновляем через сигналы.\r\n+            self._start_processing_worker(audio_data)\r\n \r\n         self.audio_recorder.start(on_finished=on_finished)\r\n \r\n     def stop_recording(self) -> None:\r\n@@ -184,95 +241,112 @@\n         self.audio_recorder.cancel()\r\n         self.window.set_state(\"idle\")\r\n \r\n     # ----------------------------------------------------------- Processing\r\n-    \r\n-    def _process_audio(self, audio_data) -> None:\r\n-        \"\"\"Synchronous processing for MVP; later can be moved to worker thread.\"\"\"\r\n+\r\n+    def _start_processing_worker(self, audio_data) -> None:\r\n+        \"\"\"\r\n+        Запуск тяжёлой обработки аудио (GigaAM/Groq + LLM) в отдельном QThread.\r\n+\r\n+        ВАЖНО: здесь мы только создаём поток и воркер, а все обновления UI\r\n+        делаем в слотах, которые вызываются уже в главном Qt-потоке.\r\n+        \"\"\"\r\n+        from PyQt6.QtCore import QThread\r\n         from loguru import logger\r\n         from pathlib import Path\r\n         from datetime import datetime\r\n-    \r\n-        try:\r\n-            self.window.set_state(\"processing\")\r\n-            # 1) сырой текст от Whisper\r\n-            raw_text = self.recognizer.transcribe(audio_data)\r\n-    \r\n-            # 2) regex-очистка (базовый препроцессинг всегда)\r\n-            from recognition.postprocessor import TextPostprocessor as TP  # локальный импорт для статик-метода\r\n-            regex_text = TP._simple_cleanup(raw_text or \"\")\r\n-    \r\n-            # 3) LLM-постпроцессинг (если включён в конфиге)\r\n-            processed_text = regex_text\r\n+\r\n+        # Если по какой-то причине предыдущий поток ещё жив — аккуратно его гасим.\r\n+        if self._processing_thread is not None:\r\n             try:\r\n-                processed_text = self.postprocessor.process(raw_text or \"\")\r\n-            except RuntimeError as exc:\r\n-                # осмысленные ошибки LLM\r\n-                logger.error(\"LLM postprocess error: {}\", exc)\r\n-                self.window.show_message(str(exc))\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n-                self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n-    \r\n-            # 4) показать оба варианта в окне\r\n+                self._processing_thread.quit()\r\n+                self._processing_thread.wait(100)\r\n+            except Exception:\r\n+                logger.debug(\"Previous processing thread cleanup failed\", exc_info=True)\r\n+\r\n+        self.window.set_state(\"processing\")\r\n+\r\n+        thread = QThread(self.qt_app)\r\n+        worker = self._ProcessingWorker(self, audio_data)\r\n+        worker.moveToThread(thread)\r\n+\r\n+        def on_result(raw_text: str, processed_text: str) -> None:\r\n+            \"\"\"\r\n+            Этот слот вызывается в главном потоке Qt.\r\n+            Здесь можно безопасно трогать UI, буфер обмена и т.п.\r\n+            \"\"\"\r\n+            # 1) показать оба варианта в окне\r\n             try:\r\n-                # верхний блок — сырой текст от Whisper\r\n                 if hasattr(self.window, \"set_raw_text\"):\r\n                     self.window.set_raw_text(raw_text or \"\")\r\n                 else:\r\n-                    # fallback в старый result_label\r\n-                    self.window.result_label.setText(processed_text)\r\n-    \r\n-                # нижний блок — обработанный текст (regex/LLM)\r\n+                    self.window.result_label.setText(processed_text or \"\")\r\n+\r\n                 if hasattr(self.window, \"set_processed_text\"):\r\n-                    self.window.set_processed_text(processed_text)\r\n+                    self.window.set_processed_text(processed_text or \"\")\r\n             except Exception:\r\n                 logger.debug(\"window text update failed\", exc_info=True)\r\n-    \r\n-            # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n-            self.clipboard.copy(processed_text)\r\n-    \r\n-            # авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n+\r\n+            # 2) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+            self.clipboard.copy(processed_text or \"\")\r\n+\r\n+            # 3) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n             self.clipboard.paste()\r\n-    \r\n-            # 6) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+\r\n+            # 4) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n             try:\r\n                 base_dir = Path(__file__).resolve().parents[2]\r\n                 log_dir = base_dir / \"logs\"\r\n                 log_dir.mkdir(parents=True, exist_ok=True)\r\n                 transcript_path = log_dir / \"transcripts.log\"\r\n-    \r\n-                # простая ротация: если файл больше 3 МБ — переименовать в transcripts_YYYYmmdd_HHMMSS.log\r\n+\r\n                 max_size_bytes = 3 * 1024 * 1024\r\n                 if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n                     ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n                     rotated = log_dir / f\"transcripts_{ts}.log\"\r\n                     transcript_path.rename(rotated)\r\n-    \r\n-                # формат записи: время, сырой текст, обработанный текст\r\n+\r\n                 with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n                     f.write(\r\n                         f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]\\\\n\"\r\n                         f\"RAW: { (raw_text or '').strip() }\\\\n\"\r\n                         f\"PROCESSED: { (processed_text or '').strip() }\\\\n\"\r\n                         \"----------------------------------------\\\\n\"\r\n                     )\r\n             except Exception as exc:  # noqa: BLE001\r\n-                # не ломаем основной флоу, если что-то пошло не так с логом\r\n                 logger.exception(\"Failed to append transcript log: {}\", exc)\r\n-    \r\n+\r\n             self.window.set_state(\"ready\")\r\n-        except RuntimeError as exc:\r\n-            # Осмысленные ошибки от распознавания (например, Groq API)\r\n-            logger.error(\"Processing error: {}\", exc)\r\n+\r\n+        def on_error(message: str) -> None:\r\n+            \"\"\"\r\n+            Слот для ошибок распознавания/LLM.\r\n+            \"\"\"\r\n+            logger = __import__(\"loguru\").logger  # избежать замыкания logger сверху\r\n+            logger.error(\"Processing error (worker): {}\", message)\r\n             self.window.set_state(\"error\")\r\n-            # Показываем пользователю человекочитаемое сообщение\r\n-            self.window.show_message(str(exc))\r\n-        except Exception as exc:  # noqa: BLE001\r\n-            logger.exception(\"Unexpected error during processing: {}\", exc)\r\n-            self.window.set_state(\"error\")\r\n-            self.window.show_message(\"Неизвестная ошибка распознавания. См. логи.\")\r\n+            self.window.show_message(message)\r\n \r\n+        def on_finished() -> None:\r\n+            \"\"\"\r\n+            Слот завершения работы воркера: чистим поток.\r\n+            \"\"\"\r\n+            thread.quit()\r\n+            thread.wait()\r\n+            self._processing_thread = None\r\n+            # Сбрасываем флаг записи, если ещё не сброшен\r\n+            self._is_recording = False\r\n+\r\n+        # wiring сигналов\r\n+        thread.started.connect(worker.run)          # type: ignore[arg-type]\r\n+        worker.result_ready.connect(on_result)      # type: ignore[arg-type]\r\n+        worker.error.connect(on_error)              # type: ignore[arg-type]\r\n+        worker.finished.connect(on_finished)        # type: ignore[arg-type]\r\n+        worker.finished.connect(worker.deleteLater) # type: ignore[arg-type]\r\n+\r\n+        self._processing_thread = thread\r\n+        thread.start()\r\n+\r\n     # -------------------------------------------------------------- Debug\r\n \r\n     def toggle_debug_mode(self) -> None:\r\n         # Placeholder: will reconfigure logging level later\r\n"
                },
                {
                    "date": 1764462394215,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -246,10 +246,13 @@\n     def _start_processing_worker(self, audio_data) -> None:\r\n         \"\"\"\r\n         Запуск тяжёлой обработки аудио (GigaAM/Groq + LLM) в отдельном QThread.\r\n \r\n-        ВАЖНО: здесь мы только создаём поток и воркер, а все обновления UI\r\n-        делаем в слотах, которые вызываются уже в главном Qt-потоке.\r\n+        ВАЖНО:\r\n+        - QThread создаём БЕЗ родителя (никаких QObject в чужом потоке),\r\n+        - воркер не трогает UI,\r\n+        - все обновления UI делаем только в слотах, которые Qt вызывает\r\n+          в главном потоке.\r\n         \"\"\"\r\n         from PyQt6.QtCore import QThread\r\n         from loguru import logger\r\n         from pathlib import Path\r\n@@ -262,11 +265,13 @@\n                 self._processing_thread.wait(100)\r\n             except Exception:\r\n                 logger.debug(\"Previous processing thread cleanup failed\", exc_info=True)\r\n \r\n+        # Состояние UI меняем в главном потоке\r\n         self.window.set_state(\"processing\")\r\n \r\n-        thread = QThread(self.qt_app)\r\n+        # ВАЖНО: QThread без родителя, чтобы не было \"parent is QApplication in different thread\"\r\n+        thread = QThread()\r\n         worker = self._ProcessingWorker(self, audio_data)\r\n         worker.moveToThread(thread)\r\n \r\n         def on_result(raw_text: str, processed_text: str) -> None:\r\n"
                },
                {
                    "date": 1764462623945,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,64 +73,8 @@\n \r\n         # State\r\n         self._is_recording: bool = False\r\n \r\n-        # Worker thread for heavy audio processing (GigaAM / Groq / LLM)\r\n-        from PyQt6.QtCore import QObject, QThread, pyqtSignal\r\n-\r\n-        class _ProcessingWorker(QObject):\r\n-            finished = pyqtSignal()\r\n-            error = pyqtSignal(str)\r\n-            result_ready = pyqtSignal(str, str)  # raw_text, processed_text\r\n-\r\n-            def __init__(self, app_ref: \"App\", audio_data) -> None:\r\n-                super().__init__()\r\n-                self._app_ref = app_ref\r\n-                self._audio_data = audio_data\r\n-\r\n-            def run(self) -> None:\r\n-                \"\"\"\r\n-                Выполняется в отдельном потоке:\r\n-                - распознавание (Groq/GigaAM)\r\n-                - regex + LLM постобработка\r\n-                Никаких Qt-объектов/виджетов здесь не трогаем.\r\n-                \"\"\"\r\n-                from loguru import logger\r\n-                from recognition.postprocessor import TextPostprocessor as TP\r\n-\r\n-                try:\r\n-                    raw_text = self._app_ref.recognizer.transcribe(self._audio_data)\r\n-                    regex_text = TP._simple_cleanup(raw_text or \"\")\r\n-\r\n-                    processed_text = regex_text\r\n-                    try:\r\n-                        processed_text = self._app_ref.postprocessor.process(raw_text or \"\")\r\n-                    except RuntimeError as exc:\r\n-                        logger.error(\"LLM postprocess error: {}\", exc)\r\n-                        # Передаём текст ошибки наверх, чтобы UI показал его\r\n-                        self.error.emit(str(exc))\r\n-                    except Exception as exc:  # noqa: BLE001\r\n-                        logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n-                        self.error.emit(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n-\r\n-                    self.result_ready.emit(raw_text or \"\", processed_text or \"\")\r\n-                except RuntimeError as exc:\r\n-                    # Осмысленные ошибки от распознавания (например, Groq/GigaAM)\r\n-                    from loguru import logger as _logger\r\n-\r\n-                    _logger.error(\"Processing error: {}\", exc)\r\n-                    self.error.emit(str(exc))\r\n-                except Exception as exc:  # noqa: BLE001\r\n-                    from loguru import logger as _logger\r\n-\r\n-                    _logger.exception(\"Unexpected error during processing: {}\", exc)\r\n-                    self.error.emit(\"Неизвестная ошибка распознавания. См. логи.\")\r\n-                finally:\r\n-                    self.finished.emit()\r\n-\r\n-        self._ProcessingWorker = _ProcessingWorker  # type: ignore[attr-defined]\r\n-        self._processing_thread: Optional[QThread] = None\r\n-\r\n         # Hotkeys\r\n         self.hotkeys = HotKeyManager(\r\n             record_hotkey=self.settings.hotkeys.record,\r\n             cancel_hotkey=self.settings.hotkeys.cancel,\r\n@@ -221,11 +165,10 @@\n         self.window.set_state(\"recording\")\r\n \r\n         def on_finished(audio_data):\r\n             # Этот колбэк вызывается из потока рекордера.\r\n-            # Теперь только запускаем воркер в отдельном QThread,\r\n-            # а UI обновляем через сигналы.\r\n-            self._start_processing_worker(audio_data)\r\n+            # Возвращаемся к синхронной обработке, как в рабочем варианте.\r\n+            self._process_audio(audio_data)\r\n \r\n         self.audio_recorder.start(on_finished=on_finished)\r\n \r\n     def stop_recording(self) -> None:\r\n@@ -242,45 +185,36 @@\n         self.window.set_state(\"idle\")\r\n \r\n     # ----------------------------------------------------------- Processing\r\n \r\n-    def _start_processing_worker(self, audio_data) -> None:\r\n-        \"\"\"\r\n-        Запуск тяжёлой обработки аудио (GigaAM/Groq + LLM) в отдельном QThread.\r\n-\r\n-        ВАЖНО:\r\n-        - QThread создаём БЕЗ родителя (никаких QObject в чужом потоке),\r\n-        - воркер не трогает UI,\r\n-        - все обновления UI делаем только в слотах, которые Qt вызывает\r\n-          в главном потоке.\r\n-        \"\"\"\r\n-        from PyQt6.QtCore import QThread\r\n+    def _process_audio(self, audio_data) -> None:\r\n+        \"\"\"Синхронная обработка аудио (как в рабочем MVP).\"\"\"\r\n         from loguru import logger\r\n         from pathlib import Path\r\n         from datetime import datetime\r\n+        from recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n \r\n-        # Если по какой-то причине предыдущий поток ещё жив — аккуратно его гасим.\r\n-        if self._processing_thread is not None:\r\n-            try:\r\n-                self._processing_thread.quit()\r\n-                self._processing_thread.wait(100)\r\n-            except Exception:\r\n-                logger.debug(\"Previous processing thread cleanup failed\", exc_info=True)\r\n+        try:\r\n+            self.window.set_state(\"processing\")\r\n+            # 1) сырой текст от распознавателя (Groq / GigaAM)\r\n+            raw_text = self.recognizer.transcribe(audio_data)\r\n \r\n-        # Состояние UI меняем в главном потоке\r\n-        self.window.set_state(\"processing\")\r\n+            # 2) regex-очистка (базовый препроцессинг всегда)\r\n+            regex_text = TP._simple_cleanup(raw_text or \"\")\r\n \r\n-        # ВАЖНО: QThread без родителя, чтобы не было \"parent is QApplication in different thread\"\r\n-        thread = QThread()\r\n-        worker = self._ProcessingWorker(self, audio_data)\r\n-        worker.moveToThread(thread)\r\n+            # 3) LLM-постпроцессинг (если включён в конфиге)\r\n+            processed_text = regex_text\r\n+            try:\r\n+                processed_text = self.postprocessor.process(raw_text or \"\")\r\n+            except RuntimeError as exc:\r\n+                # осмысленные ошибки LLM\r\n+                logger.error(\"LLM postprocess error: {}\", exc)\r\n+                self.window.show_message(str(exc))\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n \r\n-        def on_result(raw_text: str, processed_text: str) -> None:\r\n-            \"\"\"\r\n-            Этот слот вызывается в главном потоке Qt.\r\n-            Здесь можно безопасно трогать UI, буфер обмена и т.п.\r\n-            \"\"\"\r\n-            # 1) показать оба варианта в окне\r\n+            # 4) показать оба варианта в окне\r\n             try:\r\n                 if hasattr(self.window, \"set_raw_text\"):\r\n                     self.window.set_raw_text(raw_text or \"\")\r\n                 else:\r\n@@ -290,15 +224,15 @@\n                     self.window.set_processed_text(processed_text or \"\")\r\n             except Exception:\r\n                 logger.debug(\"window text update failed\", exc_info=True)\r\n \r\n-            # 2) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+            # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n             self.clipboard.copy(processed_text or \"\")\r\n \r\n-            # 3) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n+            # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n             self.clipboard.paste()\r\n \r\n-            # 4) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+            # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n             try:\r\n                 base_dir = Path(__file__).resolve().parents[2]\r\n                 log_dir = base_dir / \"logs\"\r\n                 log_dir.mkdir(parents=True, exist_ok=True)\r\n@@ -320,38 +254,18 @@\n             except Exception as exc:  # noqa: BLE001\r\n                 logger.exception(\"Failed to append transcript log: {}\", exc)\r\n \r\n             self.window.set_state(\"ready\")\r\n-\r\n-        def on_error(message: str) -> None:\r\n-            \"\"\"\r\n-            Слот для ошибок распознавания/LLM.\r\n-            \"\"\"\r\n-            logger = __import__(\"loguru\").logger  # избежать замыкания logger сверху\r\n-            logger.error(\"Processing error (worker): {}\", message)\r\n+        except RuntimeError as exc:\r\n+            # Осмысленные ошибки от распознавания (например, Groq API)\r\n+            logger.error(\"Processing error: {}\", exc)\r\n             self.window.set_state(\"error\")\r\n-            self.window.show_message(message)\r\n+            self.window.show_message(str(exc))\r\n+        except Exception as exc:  # noqa: BLE001\r\n+            logger.exception(\"Unexpected error during processing: {}\", exc)\r\n+            self.window.set_state(\"error\")\r\n+            self.window.show_message(\"Неизвестная ошибка распознавания. См. логи.\")\r\n \r\n-        def on_finished() -> None:\r\n-            \"\"\"\r\n-            Слот завершения работы воркера: чистим поток.\r\n-            \"\"\"\r\n-            thread.quit()\r\n-            thread.wait()\r\n-            self._processing_thread = None\r\n-            # Сбрасываем флаг записи, если ещё не сброшен\r\n-            self._is_recording = False\r\n-\r\n-        # wiring сигналов\r\n-        thread.started.connect(worker.run)          # type: ignore[arg-type]\r\n-        worker.result_ready.connect(on_result)      # type: ignore[arg-type]\r\n-        worker.error.connect(on_error)              # type: ignore[arg-type]\r\n-        worker.finished.connect(on_finished)        # type: ignore[arg-type]\r\n-        worker.finished.connect(worker.deleteLater) # type: ignore[arg-type]\r\n-\r\n-        self._processing_thread = thread\r\n-        thread.start()\r\n-\r\n     # -------------------------------------------------------------- Debug\r\n \r\n     def toggle_debug_mode(self) -> None:\r\n         # Placeholder: will reconfigure logging level later\r\n"
                },
                {
                    "date": 1764463456430,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -186,32 +186,82 @@\n \r\n     # ----------------------------------------------------------- Processing\r\n \r\n     def _process_audio(self, audio_data) -> None:\r\n-        \"\"\"Синхронная обработка аудио (как в рабочем MVP).\"\"\"\r\n+        \"\"\"\r\n+        Синхронная обработка аудио с каскадом backend'ов:\r\n+        1) основной backend из настроек (groq / openai / local),\r\n+        2) при ошибке — fallback на остальные по приоритету.\r\n+        \"\"\"\r\n         from loguru import logger\r\n         from pathlib import Path\r\n         from datetime import datetime\r\n         from recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n+        from recognition import create_recognizer  # каскадное создание по backend'у\r\n \r\n+        self.window.set_state(\"processing\")\r\n+\r\n+        # Собираем приоритетный список backend'ов:\r\n+        # сначала выбранный пользователем, затем остальные.\r\n+        primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+        all_backends = [\"groq\", \"openai\", \"local\"]\r\n+        cascade = [b for b in [primary] + all_backends if b in all_backends]\r\n+        # Убираем дубликаты, сохраняя порядок\r\n+        seen = set()\r\n+        ordered_backends = []\r\n+        for b in cascade:\r\n+            if b not in seen:\r\n+                seen.add(b)\r\n+                ordered_backends.append(b)\r\n+\r\n+        last_error: str | None = None\r\n+        raw_text: str | None = None\r\n+\r\n+        for backend in ordered_backends:\r\n+            try:\r\n+                logger.info(\"Trying recognition backend: {}\", backend)\r\n+                # Временно подменяем backend в настройках для фабрики\r\n+                original_backend = self.settings.recognition.backend\r\n+                self.settings.recognition.backend = backend\r\n+                recognizer = create_recognizer(self.settings.recognition)\r\n+                # ВАЖНО: возвращаем исходный backend в настройках\r\n+                self.settings.recognition.backend = original_backend\r\n+\r\n+                raw_text = recognizer.transcribe(audio_data)\r\n+                logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n+                break\r\n+            except RuntimeError as exc:\r\n+                # Осмысленная ошибка — логируем и пробуем следующий backend\r\n+                logger.error(\"Recognition error on backend {}: {}\", backend, exc)\r\n+                last_error = str(exc)\r\n+                continue\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                logger.exception(\"Unexpected recognition error on backend {}: {}\", backend, exc)\r\n+                last_error = f\"Неизвестная ошибка backend '{backend}'. См. логи.\"\r\n+                continue\r\n+\r\n+        if raw_text is None:\r\n+            # Все backend'ы упали — показываем последнюю ошибку\r\n+            msg = last_error or \"Не удалось распознать аудио ни одним backend'ом.\"\r\n+            self.window.set_state(\"error\")\r\n+            self.window.show_message(msg)\r\n+            return\r\n+\r\n+        from loguru import logger as _logger\r\n+\r\n         try:\r\n-            self.window.set_state(\"processing\")\r\n-            # 1) сырой текст от распознавателя (Groq / GigaAM)\r\n-            raw_text = self.recognizer.transcribe(audio_data)\r\n-\r\n             # 2) regex-очистка (базовый препроцессинг всегда)\r\n             regex_text = TP._simple_cleanup(raw_text or \"\")\r\n \r\n             # 3) LLM-постпроцессинг (если включён в конфиге)\r\n             processed_text = regex_text\r\n             try:\r\n                 processed_text = self.postprocessor.process(raw_text or \"\")\r\n             except RuntimeError as exc:\r\n-                # осмысленные ошибки LLM\r\n-                logger.error(\"LLM postprocess error: {}\", exc)\r\n+                _logger.error(\"LLM postprocess error: {}\", exc)\r\n                 self.window.show_message(str(exc))\r\n             except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n                 self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n \r\n             # 4) показать оба варианта в окне\r\n             try:\r\n@@ -222,9 +272,9 @@\n \r\n                 if hasattr(self.window, \"set_processed_text\"):\r\n                     self.window.set_processed_text(processed_text or \"\")\r\n             except Exception:\r\n-                logger.debug(\"window text update failed\", exc_info=True)\r\n+                _logger.debug(\"window text update failed\", exc_info=True)\r\n \r\n             # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n             self.clipboard.copy(processed_text or \"\")\r\n \r\n@@ -251,20 +301,15 @@\n                         f\"PROCESSED: { (processed_text or '').strip() }\\\\n\"\r\n                         \"----------------------------------------\\\\n\"\r\n                     )\r\n             except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"Failed to append transcript log: {}\", exc)\r\n+                _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n \r\n             self.window.set_state(\"ready\")\r\n-        except RuntimeError as exc:\r\n-            # Осмысленные ошибки от распознавания (например, Groq API)\r\n-            logger.error(\"Processing error: {}\", exc)\r\n-            self.window.set_state(\"error\")\r\n-            self.window.show_message(str(exc))\r\n         except Exception as exc:  # noqa: BLE001\r\n-            logger.exception(\"Unexpected error during processing: {}\", exc)\r\n+            _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n             self.window.set_state(\"error\")\r\n-            self.window.show_message(\"Неизвестная ошибка распознавания. См. логи.\")\r\n+            self.window.show_message(\"Неизвестная ошибка постобработки. См. логи.\")\r\n \r\n     # -------------------------------------------------------------- Debug\r\n \r\n     def toggle_debug_mode(self) -> None:\r\n"
                },
                {
                    "date": 1764468303756,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -88,9 +88,8 @@\n         )\r\n \r\n         # Wire UI signals\r\n         self.window.settings_requested.connect(self.open_settings_dialog)\r\n-        self.window.settings_save_requested.connect(self._on_settings_save_requested)\r\n         self.window.exit_requested.connect(self.quit)\r\n         self.tray.show_window_requested.connect(self.show_window)\r\n         self.tray.settings_requested.connect(self.open_settings_dialog)\r\n         self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n@@ -116,47 +115,64 @@\n         self.show_window()\r\n \r\n     def open_settings_dialog(self) -> None:\r\n         \"\"\"\r\n-        Открыть панель настроек внутри основного окна.\r\n+        Открыть диалог настроек (SettingsDialog) и применить изменения.\r\n+        \"\"\"\r\n+        from ui.settings_dialog import SettingsDialog  # локальный импорт, чтобы избежать циклов\r\n \r\n-        ВАЖНО: все значения берём/кладём только в config.yaml через AppSettings.\r\n-        \"\"\"\r\n-        # показать окно\r\n+        # показать основное окно, чтобы диалог был поверх\r\n         self.show_window()\r\n \r\n-        # заполнить UI текущими значениями из self.settings\r\n-        rec = self.settings.recognition\r\n-        post = self.settings.postprocess\r\n+        dlg = SettingsDialog(self.settings, parent=self.window)\r\n+        if dlg.exec() != dlg.DialogCode.Accepted:\r\n+            return\r\n \r\n-        # backend\r\n-        backend_value = (rec.backend or \"groq\").lower()\r\n-        idx = self.window.settings_backend_combo.findData(backend_value)\r\n-        if idx >= 0:\r\n-            self.window.settings_backend_combo.setCurrentIndex(idx)\r\n+        new_settings = dlg.get_result()\r\n+        if new_settings is None:\r\n+            return\r\n \r\n-        # API keys / base URL\r\n-        self.window.settings_groq_key.setText(rec.groq.api_key or \"\")\r\n-        self.window.settings_openai_key.setText(rec.openai.api_key or \"\")\r\n-        self.window.settings_openai_url.setText(rec.openai.base_url or \"\")\r\n+        # обновляем настройки в памяти\r\n+        self.settings = new_settings\r\n \r\n-        # postprocess\r\n-        self.window.postprocess_enabled_checkbox.setChecked(post.enabled)\r\n+        # сохраняем в config.yaml\r\n+        AppSettings.save_default(self.settings)\r\n \r\n-        # Если в конфиге пустые строки, подставляем дефолты,\r\n-        # чтобы поля в UI были уже заполнены при первом открытии.\r\n-        # По твоему запросу:\r\n-        #   - Groq postprocess model:   moonshotai/kimi-k2-instruct\r\n-        #   - OpenAI postprocess model: gpt-5.1\r\n-        groq_model = (post.groq.model or \"\").strip() or \"moonshotai/kimi-k2-instruct\"\r\n-        openai_model = (post.openai.model or \"\").strip() or \"gpt-5.1\"\r\n+        # пересоздаём recognizer и postprocessor с учётом новых настроек\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n \r\n-        self.window.postprocess_groq_model.setText(groq_model)\r\n-        self.window.postprocess_openai_model.setText(openai_model)\r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n \r\n-        # переключаем окно в режим настроек\r\n-        self.window._enter_settings_mode()\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n \r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n+        # если теперь ключи заданы — убрать предупреждающую надпись\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        has_key = False\r\n+        if backend == \"groq\" and (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            has_key = True\r\n+        elif backend == \"openai\" and (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            has_key = True\r\n+\r\n+        if has_key:\r\n+            if hasattr(self.window, \"set_raw_text\"):\r\n+                self.window.set_raw_text(\"\")\r\n+            if hasattr(self.window, \"set_processed_text\"):\r\n+                self.window.set_processed_text(\"\")\r\n+            self.window.result_label.setText(\"\")\r\n+\r\n+        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+\r\n     # ----------------------------------------------------------------- Hotkeys\r\n \r\n     def start_recording(self) -> None:\r\n         if self._is_recording:\r\n@@ -316,82 +332,12 @@\n         # Placeholder: will reconfigure logging level later\r\n         self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n \r\n     # ----------------------------------------------------------- Settings save\r\n-\r\n+    # Встроенный обработчик сохранения панели настроек больше не нужен:\r\n+    # всё делает open_settings_dialog() через SettingsDialog.\r\n     def _on_settings_save_requested(self) -> None:\r\n-        \"\"\"\r\n-        Пользователь нажал «Сохранить» в панели настроек.\r\n-        Читаем значения из UI, обновляем self.settings, сохраняем в config.yaml\r\n-        и пересоздаём recognizer/postprocessor.\r\n-        \"\"\"\r\n-        from config.settings import AppSettings  # локальный импорт, чтобы избежать циклов\r\n-    \r\n-        rec = self.settings.recognition\r\n-        post = self.settings.postprocess\r\n-    \r\n-        # 1) backend\r\n-        backend_data = self.window.settings_backend_combo.currentData()\r\n-        if backend_data in (\"groq\", \"openai\", \"local\"):\r\n-            rec.backend = backend_data\r\n-    \r\n-        # 2) API keys / base URL\r\n-        rec.groq.api_key = self.window.settings_groq_key.text().strip() or rec.groq.api_key\r\n-        rec.openai.api_key = self.window.settings_openai_key.text().strip() or rec.openai.api_key\r\n-        base_url = self.window.settings_openai_url.text().strip()\r\n-        if base_url:\r\n-            rec.openai.base_url = base_url\r\n-    \r\n-        # 3) postprocess\r\n-        post.enabled = self.window.postprocess_enabled_checkbox.isChecked()\r\n-    \r\n-        # модели LLM: пишем в recognition.*.model_process и синхронизируем postprocess.*.model\r\n-        groq_model_proc = self.window.postprocess_groq_model.text().strip()\r\n-        if groq_model_proc:\r\n-            rec.groq.model_process = groq_model_proc\r\n-            post.groq.model = groq_model_proc\r\n-    \r\n-        openai_model_proc = self.window.postprocess_openai_model.text().strip()\r\n-        if openai_model_proc:\r\n-            rec.openai.model_process = openai_model_proc\r\n-            post.openai.model = openai_model_proc\r\n-    \r\n-        # 4) сохранить всё в config.yaml\r\n-        AppSettings.save_default(self.settings)\r\n-    \r\n-        # 5) пересоздать recognizer и postprocessor\r\n-        self.recognizer = create_recognizer(self.settings.recognition)\r\n-    \r\n-        post_cfg = self.settings.postprocess\r\n-        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n-            setattr(post_cfg.groq, \"api_key\", rec.groq.api_key)\r\n-            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n-                setattr(post_cfg.groq, \"model_process\", rec.groq.model_process)\r\n-        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n-            setattr(post_cfg.openai, \"api_key\", rec.openai.api_key)\r\n-            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n-                setattr(post_cfg.openai, \"model_process\", rec.openai.model_process)\r\n-    \r\n-        self.postprocessor = TextPostprocessor(post_cfg)\r\n-    \r\n-        # 6) если теперь ключи заданы — убрать предупреждающую надпись\r\n-        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n-        has_key = False\r\n-        if backend == \"groq\" and (self.settings.recognition.groq.api_key or \"\").strip():\r\n-            has_key = True\r\n-        elif backend == \"openai\" and (self.settings.recognition.openai.api_key or \"\").strip():\r\n-            has_key = True\r\n-    \r\n-        if has_key:\r\n-            # очищаем все текстовые блоки, чтобы не висело старое предупреждение\r\n-            if hasattr(self.window, \"set_raw_text\"):\r\n-                self.window.set_raw_text(\"\")\r\n-            if hasattr(self.window, \"set_processed_text\"):\r\n-                self.window.set_processed_text(\"\")\r\n-            self.window.result_label.setText(\"\")\r\n-    \r\n-        # 7) показать уведомление\r\n-        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+        return\r\n \r\n     # -------------------------------------------------------------- Lifecycle\r\n \r\n     def quit(self) -> None:\r\n"
                },
                {
                    "date": 1764469329776,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,8 +51,9 @@\n             if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n                 setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n \r\n         if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            # ключ для LLM всегда берём из поля OpenAI API key (recognition.openai.api_key)\r\n             setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n             if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n                 setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n \r\n"
                },
                {
                    "date": 1764492233578,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,6 @@\n import sys\r\n+from pathlib import Path\r\n from typing import Optional\r\n \r\n from PyQt6.QtWidgets import QApplication\r\n \r\n@@ -26,10 +27,20 @@\n \r\n     def __init__(self) -> None:\r\n         self.qt_app = QApplication(sys.argv)\r\n \r\n-        # Load settings and logging\r\n-        self.settings = AppSettings.load_default()\r\n+        # Определяем базовую директорию приложения:\r\n+        # - в dev-режиме: корень проекта (родитель src)\r\n+        # - в собранном .exe: папка, где лежит exe\r\n+        if getattr(sys, \"frozen\", False):\r\n+            # PyInstaller / frozen\r\n+            self.base_dir = Path(sys.executable).resolve().parent\r\n+        else:\r\n+            # Обычный запуск из исходников\r\n+            self.base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+        # Load settings and logging (с учётом base_dir и config.local.yaml)\r\n+        self.settings = self._load_or_init_settings()\r\n         setup_logging(self.settings.logging)\r\n \r\n         # Core components\r\n         self.window = FloatingWindow(self.settings.ui)\r\n@@ -332,14 +343,107 @@\n     def toggle_debug_mode(self) -> None:\r\n         # Placeholder: will reconfigure logging level later\r\n         self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n \r\n-    # ----------------------------------------------------------- Settings save\r\n-    # Встроенный обработчик сохранения панели настроек больше не нужен:\r\n-    # всё делает open_settings_dialog() через SettingsDialog.\r\n-    def _on_settings_save_requested(self) -> None:\r\n-        return\r\n+    # ----------------------------------------------------------- Settings / config helpers\r\n \r\n+    def _load_or_init_settings(self) -> AppSettings:\r\n+        \"\"\"\r\n+        Загрузка настроек с учётом портативного режима.\r\n+\r\n+        Логика:\r\n+        - Ищем config.yaml в self.base_dir (рядом с exe или в корне проекта).\r\n+        - Если файла нет — создаём минимальный config.yaml с backend=local.\r\n+        - Затем вызываем AppSettings.load_default(), который уже умеет\r\n+          подмешивать config.local.yaml поверх config.yaml.\r\n+        \"\"\"\r\n+        config_path = self.base_dir / \"config.yaml\"\r\n+\r\n+        if not config_path.exists():\r\n+            # Минимальный конфиг по умолчанию: локальный backend, безопасные значения.\r\n+            default_config = {\r\n+                \"app\": {\r\n+                    \"name\": \"VoiceCapture\",\r\n+                    \"version\": \"0.1.0\",\r\n+                },\r\n+                \"hotkeys\": {\r\n+                    \"record\": \"ctrl+win\",\r\n+                    \"cancel\": \"esc\",\r\n+                    \"toggle_window\": \"ctrl+alt+s\",\r\n+                    \"toggle_debug\": \"ctrl+alt+d\",\r\n+                },\r\n+                \"audio\": {\r\n+                    \"sample_rate\": 16000,\r\n+                    \"channels\": 1,\r\n+                    \"max_duration\": 120,\r\n+                },\r\n+                \"recognition\": {\r\n+                    \"backend\": \"local\",\r\n+                    \"local\": {\r\n+                        \"model\": \"large-v3\",\r\n+                        \"device\": \"cuda\",\r\n+                        \"compute_type\": \"float16\",\r\n+                        \"language\": \"ru\",\r\n+                        \"beam_size\": 5,\r\n+                        \"temperature\": 0.0,\r\n+                    },\r\n+                    \"openai\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-1\",\r\n+                        \"model_process\": \"gpt-4o-mini\",\r\n+                        \"language\": \"ru\",\r\n+                        \"base_url\": \"https://api.openai.com/v1\",\r\n+                    },\r\n+                    \"groq\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-large-v3\",\r\n+                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n+                        \"language\": \"ru\",\r\n+                    },\r\n+                },\r\n+                \"postprocess\": {\r\n+                    \"llm_backend\": \"groq\",\r\n+                    \"openai\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model_process\": \"gpt-4o-mini\",\r\n+                        \"base_url\": \"https://api.openai.com/v1\",\r\n+                    },\r\n+                    \"groq\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n+                    },\r\n+                },\r\n+                \"ui\": {\r\n+                    \"width\": 320,\r\n+                    \"height\": 200,\r\n+                    \"opacity\": 0.9,\r\n+                    \"compact_mode\": False,\r\n+                },\r\n+                \"logging\": {\r\n+                    \"level\": \"INFO\",\r\n+                    \"log_dir\": \"logs\",\r\n+                },\r\n+            }\r\n+\r\n+            try:\r\n+                import yaml\r\n+\r\n+                with config_path.open(\"w\", encoding=\"utf-8\") as f:\r\n+                    yaml.safe_dump(default_config, f, allow_unicode=True, sort_keys=False)\r\n+            except Exception:\r\n+                # Если по какой-то причине не удалось записать файл — продолжаем\r\n+                # с дефолтами из dataclass'ов AppSettings.\r\n+                pass\r\n+\r\n+        # Теперь загружаем настройки стандартным способом:\r\n+        settings = AppSettings.load_default()\r\n+\r\n+        # Гарантируем, что backend задан\r\n+        if not getattr(settings.recognition, \"backend\", None):\r\n+            settings.recognition.backend = \"local\"\r\n+\r\n+        return settings\r\n+\r\n     # -------------------------------------------------------------- Lifecycle\r\n \r\n     def quit(self) -> None:\r\n         self.hotkeys.stop()\r\n"
                },
                {
                    "date": 1764494264918,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -395,9 +395,9 @@\n                     },\r\n                     \"groq\": {\r\n                         \"api_key\": \"\",\r\n                         \"model\": \"whisper-large-v3\",\r\n-                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n+                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n                         \"language\": \"ru\",\r\n                     },\r\n                 },\r\n                 \"postprocess\": {\r\n@@ -408,9 +408,9 @@\n                         \"base_url\": \"https://api.openai.com/v1\",\r\n                     },\r\n                     \"groq\": {\r\n                         \"api_key\": \"\",\r\n-                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n+                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n                     },\r\n                 },\r\n                 \"ui\": {\r\n                     \"width\": 320,\r\n"
                },
                {
                    "date": 1764499985591,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -390,30 +390,35 @@\n                         \"api_key\": \"\",\r\n                         \"model\": \"whisper-1\",\r\n                         \"model_process\": \"gpt-4o-mini\",\r\n                         \"language\": \"ru\",\r\n-                        \"base_url\": \"https://api.openai.com/v1\",\r\n+                        # base_url намеренно оставляем пустым, чтобы пользователь\r\n+                        # задал его в настройках (OpenAI Base URL).\r\n+                        \"base_url\": \"\",\r\n                     },\r\n                     \"groq\": {\r\n                         \"api_key\": \"\",\r\n                         \"model\": \"whisper-large-v3\",\r\n                         \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n                         \"language\": \"ru\",\r\n                     },\r\n                 },\r\n+                # Блок postprocess больше не хранит ключи / base_url.\r\n+                # Здесь только включение, режим и \"отображательные\" модели.\r\n                 \"postprocess\": {\r\n+                    \"enabled\": True,\r\n+                    \"mode\": \"llm\",\r\n                     \"llm_backend\": \"groq\",\r\n+                    \"groq\": {\r\n+                        \"model\": \"moonshotai/kimi-k2-instruct\",\r\n+                    },\r\n                     \"openai\": {\r\n-                        \"api_key\": \"\",\r\n-                        \"model_process\": \"gpt-4o-mini\",\r\n-                        \"base_url\": \"https://api.openai.com/v1\",\r\n+                        \"model\": \"gpt-5.1\",\r\n                     },\r\n-                    \"groq\": {\r\n-                        \"api_key\": \"\",\r\n-                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n-                    },\r\n                 },\r\n                 \"ui\": {\r\n+                    # Старые поля width/height/compact_mode больше не используются,\r\n+                    # но при первой генерации конфига запишем их для обратной совместимости.\r\n                     \"width\": 320,\r\n                     \"height\": 200,\r\n                     \"opacity\": 0.9,\r\n                     \"compact_mode\": False,\r\n"
                },
                {
                    "date": 1764500312963,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,9 +49,9 @@\n         self.audio_recorder = AudioRecorder(self.settings.audio)\r\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n \r\n         # Постпроцессинг текста.\r\n-        # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ и model_process,\r\n+        # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ, model_process и base_url,\r\n         # что и в recognition.*, чтобы LLM работал уже при первом запуске.\r\n         post_cfg = self.settings.postprocess\r\n         rec_cfg = self.settings.recognition\r\n \r\n@@ -64,10 +64,13 @@\n \r\n         if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n             # ключ для LLM всегда берём из поля OpenAI API key (recognition.openai.api_key)\r\n             setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            # модель LLM\r\n             if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n                 setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n \r\n         self.postprocessor = TextPostprocessor(post_cfg)\r\n \r\n         # Первое сообщение: если нет ключа для текущего backend'а — подсказка пользователю\r\n@@ -163,8 +166,10 @@\n         if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n             setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n             if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n                 setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n \r\n         self.postprocessor = TextPostprocessor(post_cfg)\r\n \r\n         # если теперь ключи заданы — убрать предупреждающую надпись\r\n"
                },
                {
                    "date": 1764591217908,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,17 +3,17 @@\n from typing import Optional\r\n \r\n from PyQt6.QtWidgets import QApplication\r\n \r\n-from config.settings import AppSettings\r\n-from ui.floating_window import FloatingWindow\r\n-from ui.system_tray import SystemTrayIcon\r\n-from hotkey.hotkey_manager import HotKeyManager\r\n-from audio.recorder import AudioRecorder\r\n-from clipboard.clipboard_manager import ClipboardManager\r\n-from recognition import create_recognizer\r\n-from recognition.postprocessor import TextPostprocessor\r\n-from utils.logger import setup_logging\r\n+from src.config.settings import AppSettings\r\n+from src.ui.floating_window import FloatingWindow\r\n+from src.ui.system_tray import SystemTrayIcon\r\n+from src.hotkey.hotkey_manager import HotKeyManager\r\n+from src.audio.recorder import AudioRecorder\r\n+from src.clipboard.clipboard_manager import ClipboardManager\r\n+from src.recognition import create_recognizer\r\n+from src.recognition.postprocessor import TextPostprocessor\r\n+from src.utils.logger import setup_logging\r\n \r\n \r\n class App:\r\n     \"\"\"\r\n@@ -132,9 +132,9 @@\n     def open_settings_dialog(self) -> None:\r\n         \"\"\"\r\n         Открыть диалог настроек (SettingsDialog) и применить изменения.\r\n         \"\"\"\r\n-        from ui.settings_dialog import SettingsDialog  # локальный импорт, чтобы избежать циклов\r\n+        from src.ui.settings_dialog import SettingsDialog  # локальный импорт, чтобы избежать циклов\r\n \r\n         # показать основное окно, чтобы диалог был поверх\r\n         self.show_window()\r\n \r\n@@ -227,10 +227,10 @@\n         \"\"\"\r\n         from loguru import logger\r\n         from pathlib import Path\r\n         from datetime import datetime\r\n-        from recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n-        from recognition import create_recognizer  # каскадное создание по backend'у\r\n+        from src.recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n+        from src.recognition import create_recognizer  # каскадное создание по backend'у\r\n \r\n         self.window.set_state(\"processing\")\r\n \r\n         # Собираем приоритетный список backend'ов:\r\n"
                },
                {
                    "date": 1764659905356,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -40,15 +40,20 @@\n \r\n         # Load settings and logging (с учётом base_dir и config.local.yaml)\r\n         self.settings = self._load_or_init_settings()\r\n         setup_logging(self.settings.logging)\r\n-\r\n+        \r\n         # Core components\r\n         self.window = FloatingWindow(self.settings.ui)\r\n         self.tray = SystemTrayIcon(self.window, self.settings.app)\r\n         self.clipboard = ClipboardManager()\r\n         self.audio_recorder = AudioRecorder(self.settings.audio)\r\n+        # Основной распознаватель для текущего backend'а\r\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n+        # Кэш распознавателей по backend'ам, чтобы не пересоздавать GigaAM на каждое распознавание\r\n+        self._recognizers = {}\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n \r\n         # Постпроцессинг текста.\r\n         # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ, model_process и base_url,\r\n         # что и в recognition.*, чтобы LLM работал уже при первом запуске.\r\n@@ -147,15 +152,19 @@\n             return\r\n \r\n         # обновляем настройки в памяти\r\n         self.settings = new_settings\r\n-\r\n+        \r\n         # сохраняем в config.yaml\r\n         AppSettings.save_default(self.settings)\r\n-\r\n+        \r\n         # пересоздаём recognizer и postprocessor с учётом новых настроек\r\n+        # и сбрасываем кэш распознавателей по backend'ам.\r\n+        self._recognizers = {}\r\n         self.recognizer = create_recognizer(self.settings.recognition)\r\n-\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n+        \r\n         post_cfg = self.settings.postprocess\r\n         rec_cfg = self.settings.recognition\r\n \r\n         if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n@@ -218,8 +227,30 @@\n         self.window.set_state(\"idle\")\r\n \r\n     # ----------------------------------------------------------- Processing\r\n \r\n+    def _get_or_create_recognizer(self, backend: str):\r\n+        from dataclasses import replace  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        backend = (backend or \"groq\").lower()\r\n+        cache = getattr(self, \"_recognizers\", None)\r\n+        if cache is None:\r\n+            cache = {}\r\n+            self._recognizers = cache\r\n+            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+            cache[primary] = self.recognizer\r\n+\r\n+        if backend in cache:\r\n+            return cache[backend]\r\n+\r\n+        rec_cfg = self.settings.recognition\r\n+        tmp_cfg = replace(rec_cfg, backend=backend)\r\n+        recognizer = create_recognizer(tmp_cfg)\r\n+        cache[backend] = recognizer\r\n+        return recognizer\r\n+    \r\n+    # ----------------------------------------------------------- Processing\r\n+    \r\n     def _process_audio(self, audio_data) -> None:\r\n         \"\"\"\r\n         Синхронная обработка аудио с каскадом backend'ов:\r\n         1) основной backend из настроек (groq / openai / local),\r\n@@ -251,15 +282,11 @@\n \r\n         for backend in ordered_backends:\r\n             try:\r\n                 logger.info(\"Trying recognition backend: {}\", backend)\r\n-                # Временно подменяем backend в настройках для фабрики\r\n-                original_backend = self.settings.recognition.backend\r\n-                self.settings.recognition.backend = backend\r\n-                recognizer = create_recognizer(self.settings.recognition)\r\n-                # ВАЖНО: возвращаем исходный backend в настройках\r\n-                self.settings.recognition.backend = original_backend\r\n-\r\n+                # Используем кэш распознавателей, чтобы не пересоздавать GigaAM-v3\r\n+                recognizer = self._get_or_create_recognizer(backend)\r\n+        \r\n                 raw_text = recognizer.transcribe(audio_data)\r\n                 logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n                 break\r\n             except RuntimeError as exc:\r\n"
                },
                {
                    "date": 1764661505071,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,535 @@\n+import sys\r\n+from pathlib import Path\r\n+from typing import Optional\r\n+\r\n+from PyQt6.QtWidgets import QApplication\r\n+\r\n+from config.settings import AppSettings\r\n+from ui.floating_window import FloatingWindow\r\n+from ui.system_tray import SystemTrayIcon\r\n+from hotkey.hotkey_manager import HotKeyManager\r\n+from audio.recorder import AudioRecorder\r\n+from clipboard.clipboard_manager import ClipboardManager\r\n+from recognition import create_recognizer\r\n+from recognition.postprocessor import TextPostprocessor\r\n+from utils.logger import setup_logging\r\n+\r\n+\r\n+class App:\r\n+    \"\"\"\r\n+    Main application class: wires UI, hotkeys, audio recorder, recognizer and clipboard.\r\n+\r\n+    MVP workflow:\r\n+        global hotkey (record) down   -> start_recording()\r\n+        global hotkey (record) up     -> stop_recording()\r\n+        audio -> recognizer (Groq/GigaAM) -> postprocess -> clipboard.copy + paste\r\n+    \"\"\"\r\n+\r\n+    def __init__(self) -> None:\r\n+        self.qt_app = QApplication(sys.argv)\r\n+\r\n+        # Определяем базовую директорию приложения:\r\n+        # - в dev-режиме: корень проекта (родитель src)\r\n+        # - в собранном .exe: папка, где лежит exe\r\n+        if getattr(sys, \"frozen\", False):\r\n+            # PyInstaller / frozen\r\n+            self.base_dir = Path(sys.executable).resolve().parent\r\n+        else:\r\n+            # Обычный запуск из исходников\r\n+            self.base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+        # Load settings and logging (с учётом base_dir и config.local.yaml)\r\n+        self.settings = self._load_or_init_settings()\r\n+        setup_logging(self.settings.logging)\r\n+        \r\n+        # Core components\r\n+        self.window = FloatingWindow(self.settings.ui)\r\n+        self.tray = SystemTrayIcon(self.window, self.settings.app)\r\n+        self.clipboard = ClipboardManager()\r\n+        self.audio_recorder = AudioRecorder(self.settings.audio)\r\n+        # Основной распознаватель для текущего backend'а\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        # Кэш распознавателей по backend'ам, чтобы не пересоздавать GigaAM на каждое распознавание\r\n+        self._recognizers = {}\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n+\r\n+        # Постпроцессинг текста.\r\n+        # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ, model_process и base_url,\r\n+        # что и в recognition.*, чтобы LLM работал уже при первом запуске.\r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            # один ключ Groq: берём из recognition.groq.api_key\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            # модель LLM: из recognition.groq.model_process\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            # ключ для LLM всегда берём из поля OpenAI API key (recognition.openai.api_key)\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            # модель LLM\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n+        # Первое сообщение: если нет ключа для текущего backend'а — подсказка пользователю\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        missing_key = False\r\n+        if backend == \"groq\" and not (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            missing_key = True\r\n+        elif backend == \"openai\" and not (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            missing_key = True\r\n+\r\n+        if missing_key:\r\n+            self.window.result_label.setText(\r\n+                \"Добавьте API‑ключ в настройках (⚙️) перед использованием распознавания.\"\r\n+            )\r\n+\r\n+        # State\r\n+        self._is_recording: bool = False\r\n+\r\n+        # Hotkeys\r\n+        self.hotkeys = HotKeyManager(\r\n+            record_hotkey=self.settings.hotkeys.record,\r\n+            cancel_hotkey=self.settings.hotkeys.cancel,\r\n+            toggle_window_hotkey=self.settings.hotkeys.toggle_window,\r\n+            toggle_debug_hotkey=self.settings.hotkeys.toggle_debug,\r\n+            on_record_press=self.start_recording,\r\n+            on_record_release=self.stop_recording,\r\n+            on_cancel=self.cancel_recording,\r\n+            on_toggle_window=self.toggle_window_visibility,\r\n+            on_toggle_debug=self.toggle_debug_mode,\r\n+        )\r\n+\r\n+        # Wire UI signals\r\n+        self.window.settings_requested.connect(self.open_settings_dialog)\r\n+        self.window.exit_requested.connect(self.quit)\r\n+        self.tray.show_window_requested.connect(self.show_window)\r\n+        self.tray.settings_requested.connect(self.open_settings_dialog)\r\n+        self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n+        self.tray.exit_requested.connect(self.quit)\r\n+\r\n+    # --------------------------------------------------------------------- UI\r\n+\r\n+    def show_window(self) -> None:\r\n+        self.window.show()\r\n+        self.window.raise_()\r\n+        self.window.activateWindow()\r\n+\r\n+    def toggle_window_visibility(self) -> None:\r\n+        \"\"\"\r\n+        Горячая клавиша \"Показать/скрыть окно\".\r\n+\r\n+        Для твоего сценария окно должно быть ВСЕГДА видно, поэтому\r\n+        мы больше не будем его прятать, а только:\r\n+        - если оно свернуто в компактный режим — разворачивать,\r\n+        - если оно где-то \"потерялось\" — показывать и поднимать наверх.\r\n+        \"\"\"\r\n+        # просто гарантируем, что окно показано и на переднем плане\r\n+        self.show_window()\r\n+\r\n+    def open_settings_dialog(self) -> None:\r\n+        \"\"\"\r\n+        Открыть диалог настроек (SettingsDialog) и применить изменения.\r\n+        \"\"\"\r\n+        from ui.settings_dialog import SettingsDialog  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        # показать основное окно, чтобы диалог был поверх\r\n+        self.show_window()\r\n+\r\n+        dlg = SettingsDialog(self.settings, parent=self.window)\r\n+        if dlg.exec() != dlg.DialogCode.Accepted:\r\n+            return\r\n+\r\n+        new_settings = dlg.get_result()\r\n+        if new_settings is None:\r\n+            return\r\n+\r\n+        # обновляем настройки в памяти\r\n+        self.settings = new_settings\r\n+        \r\n+        # сохраняем в config.yaml\r\n+        AppSettings.save_default(self.settings)\r\n+        \r\n+        # пересоздаём recognizer и postprocessor с учётом новых настроек\r\n+        # и сбрасываем кэш распознавателей по backend'ам.\r\n+        self._recognizers = {}\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n+        \r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n+        # если теперь ключи заданы — убрать предупреждающую надпись\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        has_key = False\r\n+        if backend == \"groq\" and (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            has_key = True\r\n+        elif backend == \"openai\" and (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            has_key = True\r\n+\r\n+        if has_key:\r\n+            if hasattr(self.window, \"set_raw_text\"):\r\n+                self.window.set_raw_text(\"\")\r\n+            if hasattr(self.window, \"set_processed_text\"):\r\n+                self.window.set_processed_text(\"\")\r\n+            self.window.result_label.setText(\"\")\r\n+\r\n+        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+\r\n+    # ----------------------------------------------------------------- Hotkeys\r\n+\r\n+    def start_recording(self) -> None:\r\n+        if self._is_recording:\r\n+            return\r\n+        self._is_recording = True\r\n+        self.window.set_state(\"recording\")\r\n+\r\n+        def on_finished(audio_data):\r\n+            # Этот колбэк вызывается из потока рекордера.\r\n+            # Возвращаемся к синхронной обработке, как в рабочем варианте.\r\n+            self._process_audio(audio_data)\r\n+\r\n+        self.audio_recorder.start(on_finished=on_finished)\r\n+\r\n+    def stop_recording(self) -> None:\r\n+        if not self._is_recording:\r\n+            return\r\n+        self._is_recording = False\r\n+        self.audio_recorder.stop()\r\n+\r\n+    def cancel_recording(self) -> None:\r\n+        if not self._is_recording:\r\n+            return\r\n+        self._is_recording = False\r\n+        self.audio_recorder.cancel()\r\n+        self.window.set_state(\"idle\")\r\n+\r\n+    # ----------------------------------------------------------- Processing\r\n+\r\n+    def _get_or_create_recognizer(self, backend: str):\r\n+        from dataclasses import replace  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        backend = (backend or \"groq\").lower()\r\n+        cache = getattr(self, \"_recognizers\", None)\r\n+        if cache is None:\r\n+            cache = {}\r\n+            self._recognizers = cache\r\n+            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+            cache[primary] = self.recognizer\r\n+\r\n+        if backend in cache:\r\n+            return cache[backend]\r\n+\r\n+        rec_cfg = self.settings.recognition\r\n+        tmp_cfg = replace(rec_cfg, backend=backend)\r\n+        recognizer = create_recognizer(tmp_cfg)\r\n+        cache[backend] = recognizer\r\n+        return recognizer\r\n+    \r\n+    # ----------------------------------------------------------- Processing\r\n+    \r\n+    def _process_audio(self, audio_data) -> None:\r\n+        \"\"\"\r\n+        Синхронная обработка аудио с каскадом backend'ов:\r\n+        1) основной backend из настроек (groq / openai / local),\r\n+        2) при ошибке — fallback на остальные по приоритету.\r\n+\r\n+        Дополнительно:\r\n+        - логируем все распознавания в отдельный logfile с указанием:\r\n+          * времени;\r\n+          * backend'а;\r\n+          * длительности аудио;\r\n+          * исходного и обработанного текста.\r\n+        \"\"\"\r\n+        from loguru import logger\r\n+        from pathlib import Path\r\n+        from datetime import datetime\r\n+        from recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n+\r\n+        self.window.set_state(\"processing\")\r\n+\r\n+        # ------------------------ вычисляем длительность аудио -----------------\r\n+        try:\r\n+            import numpy as _np  # локальный импорт, чтобы не тянуть при импорте модуля\r\n+\r\n+            samples = audio_data.samples\r\n+            sample_rate = getattr(audio_data, \"sample_rate\", None) or getattr(\r\n+                audio_data, \"rate\", None\r\n+            ) or 16000\r\n+\r\n+            if isinstance(samples, _np.ndarray):\r\n+                total_samples = samples.shape[0]\r\n+            else:\r\n+                samples = _np.asarray(samples)\r\n+                total_samples = samples.shape[0]\r\n+\r\n+            audio_duration_sec = float(total_samples) / float(sample_rate or 1)\r\n+        except Exception as exc:  # noqa: BLE001\r\n+            logger.exception(\"Failed to compute audio duration: {}\", exc)\r\n+            audio_duration_sec = -1.0\r\n+\r\n+        # ------------------------ каскад backend'ов ----------------------------\r\n+        primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+        all_backends = [\"groq\", \"openai\", \"local\"]\r\n+        cascade = [b for b in [primary] + all_backends if b in all_backends]\r\n+\r\n+        seen = set()\r\n+        ordered_backends = []\r\n+        for b in cascade:\r\n+            if b not in seen:\r\n+                seen.add(b)\r\n+                ordered_backends.append(b)\r\n+\r\n+        last_error: str | None = None\r\n+        raw_text: str | None = None\r\n+        used_backend: str | None = None\r\n+\r\n+        for backend in ordered_backends:\r\n+            try:\r\n+                logger.info(\"Trying recognition backend: {}\", backend)\r\n+                recognizer = self._get_or_create_recognizer(backend)\r\n+\r\n+                raw_text = recognizer.transcribe(audio_data)\r\n+                used_backend = backend\r\n+                logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n+                break\r\n+            except RuntimeError as exc:\r\n+                logger.error(\"Recognition error on backend {}: {}\", backend, exc)\r\n+                last_error = str(exc)\r\n+                continue\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                logger.exception(\"Unexpected recognition error on backend {}: {}\", backend, exc)\r\n+                last_error = f\"Неизвестная ошибка backend '{backend}'. См. логи.\"\r\n+                continue\r\n+\r\n+        if raw_text is None:\r\n+            msg = last_error or \"Не удалось распознать аудио ни одним backend'ом.\"\r\n+            self.window.set_state(\"error\")\r\n+            self.window.show_message(msg)\r\n+            return\r\n+\r\n+        from loguru import logger as _logger\r\n+\r\n+        try:\r\n+            # 2) regex-очистка (базовый препроцессинг всегда)\r\n+            regex_text = TP._simple_cleanup(raw_text or \"\")\r\n+\r\n+            # 3) LLM-постпроцессинг (если включён в конфиге)\r\n+            processed_text = regex_text\r\n+            try:\r\n+                processed_text = self.postprocessor.process(raw_text or \"\")\r\n+            except RuntimeError as exc:\r\n+                _logger.error(\"LLM postprocess error: {}\", exc)\r\n+                self.window.show_message(str(exc))\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n+\r\n+            # 4) показать оба варианта в окне\r\n+            try:\r\n+                if hasattr(self.window, \"set_raw_text\"):\r\n+                    self.window.set_raw_text(raw_text or \"\")\r\n+                else:\r\n+                    self.window.result_label.setText(processed_text or \"\")\r\n+\r\n+                if hasattr(self.window, \"set_processed_text\"):\r\n+                    self.window.set_processed_text(processed_text or \"\")\r\n+            except Exception:\r\n+                _logger.debug(\"window text update failed\", exc_info=True)\r\n+\r\n+            # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+            self.clipboard.copy(processed_text or \"\")\r\n+\r\n+            # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n+            self.clipboard.paste()\r\n+\r\n+            # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+            try:\r\n+                # Базовая директория приложения (та же логика, что и в App._load_or_init_settings)\r\n+                if getattr(sys, \"frozen\", False):\r\n+                    base_dir = Path(sys.executable).resolve().parent\r\n+                else:\r\n+                    base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+                log_dir = base_dir / \"logs\"\r\n+                log_dir.mkdir(parents=True, exist_ok=True)\r\n+                transcript_path = log_dir / \"transcripts.log\"\r\n+\r\n+                max_size_bytes = 3 * 1024 * 1024\r\n+                if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n+                    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n+                    rotated = log_dir / f\"transcripts_{ts}.log\"\r\n+                    transcript_path.rename(rotated)\r\n+\r\n+                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\r\n+                backend_str = used_backend or (self.settings.recognition.backend or \"unknown\")\r\n+\r\n+                with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n+                    f.write(\r\n+                        f\"[{timestamp}] backend={backend_str} \"\r\n+                        f\"duration={audio_duration_sec:.3f}s\\n\"\r\n+                        f\"RAW: {(raw_text or '').strip()}\\n\"\r\n+                        f\"PROCESSED: {(processed_text or '').strip()}\\n\"\r\n+                        \"----------------------------------------\\n\"\r\n+                    )\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n+\r\n+            self.window.set_state(\"ready\")\r\n+        except Exception as exc:  # noqa: BLE001\r\n+            _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n+            self.window.set_state(\"error\")\r\n+            self.window.show_message(\"Неизвестная ошибка постобработки. См. логи.\")\r\n+\r\n+    # -------------------------------------------------------------- Debug\r\n+\r\n+    def toggle_debug_mode(self) -> None:\r\n+        # Placeholder: will reconfigure logging level later\r\n+        self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n+\r\n+    # ----------------------------------------------------------- Settings / config helpers\r\n+\r\n+    def _load_or_init_settings(self) -> AppSettings:\r\n+        \"\"\"\r\n+        Загрузка настроек с учётом портативного режима.\r\n+\r\n+        Логика:\r\n+        - Ищем config.yaml в self.base_dir (рядом с exe или в корне проекта).\r\n+        - Если файла нет — создаём минимальный config.yaml с backend=local.\r\n+        - Затем вызываем AppSettings.load_default(), который уже умеет\r\n+          подмешивать config.local.yaml поверх config.yaml.\r\n+        \"\"\"\r\n+        config_path = self.base_dir / \"config.yaml\"\r\n+\r\n+        if not config_path.exists():\r\n+            # Минимальный конфиг по умолчанию: локальный backend, безопасные значения.\r\n+            default_config = {\r\n+                \"app\": {\r\n+                    \"name\": \"VoiceCapture\",\r\n+                    \"version\": \"0.1.0\",\r\n+                },\r\n+                \"hotkeys\": {\r\n+                    \"record\": \"ctrl+win\",\r\n+                    \"cancel\": \"esc\",\r\n+                    \"toggle_window\": \"ctrl+alt+s\",\r\n+                    \"toggle_debug\": \"ctrl+alt+d\",\r\n+                },\r\n+                \"audio\": {\r\n+                    \"sample_rate\": 16000,\r\n+                    \"channels\": 1,\r\n+                    \"max_duration\": 120,\r\n+                },\r\n+                \"recognition\": {\r\n+                    \"backend\": \"local\",\r\n+                    \"local\": {\r\n+                        \"model\": \"large-v3\",\r\n+                        \"device\": \"cuda\",\r\n+                        \"compute_type\": \"float16\",\r\n+                        \"language\": \"ru\",\r\n+                        \"beam_size\": 5,\r\n+                        \"temperature\": 0.0,\r\n+                        \"hf_token\": \"\",\r\n+                    },\r\n+                    \"openai\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-1\",\r\n+                        \"model_process\": \"gpt-4o-mini\",\r\n+                        \"language\": \"ru\",\r\n+                        # base_url намеренно оставляем пустым, чтобы пользователь\r\n+                        # задал его в настройках (OpenAI Base URL).\r\n+                        \"base_url\": \"\",\r\n+                    },\r\n+                    \"groq\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-large-v3\",\r\n+                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n+                        \"language\": \"ru\",\r\n+                    },\r\n+                },\r\n+                # Блок postprocess больше не хранит ключи / base_url.\r\n+                # Здесь только включение, режим и \"отображательные\" модели.\r\n+                \"postprocess\": {\r\n+                    \"enabled\": True,\r\n+                    \"mode\": \"llm\",\r\n+                    \"llm_backend\": \"groq\",\r\n+                    \"groq\": {\r\n+                        \"model\": \"moonshotai/kimi-k2-instruct\",\r\n+                    },\r\n+                    \"openai\": {\r\n+                        \"model\": \"gpt-5.1\",\r\n+                    },\r\n+                },\r\n+                \"ui\": {\r\n+                    # Старые поля width/height/compact_mode больше не используются,\r\n+                    # но при первой генерации конфига запишем их для обратной совместимости.\r\n+                    \"width\": 320,\r\n+                    \"height\": 200,\r\n+                    \"opacity\": 0.9,\r\n+                    \"compact_mode\": False,\r\n+                },\r\n+                \"logging\": {\r\n+                    \"level\": \"INFO\",\r\n+                    \"log_dir\": \"logs\",\r\n+                },\r\n+            }\r\n+\r\n+            try:\r\n+                import yaml\r\n+\r\n+                with config_path.open(\"w\", encoding=\"utf-8\") as f:\r\n+                    yaml.safe_dump(default_config, f, allow_unicode=True, sort_keys=False)\r\n+            except Exception:\r\n+                # Если по какой-то причине не удалось записать файл — продолжаем\r\n+                # с дефолтами из dataclass'ов AppSettings.\r\n+                pass\r\n+\r\n+        # Теперь загружаем настройки стандартным способом:\r\n+        settings = AppSettings.load_default()\r\n+\r\n+        # Гарантируем, что backend задан\r\n+        if not getattr(settings.recognition, \"backend\", None):\r\n+            settings.recognition.backend = \"local\"\r\n+\r\n+        return settings\r\n+\r\n+    # -------------------------------------------------------------- Lifecycle\r\n+\r\n+    def quit(self) -> None:\r\n+        self.hotkeys.stop()\r\n+        self.qt_app.quit()\r\n+\r\n+    def run(self) -> None:\r\n+        self.hotkeys.start()\r\n+        self.show_window()\r\n+        sys.exit(self.qt_app.exec())\r\n+\r\n+\r\n+def main() -> None:\r\n+    app = App()\r\n+    app.run()\r\n+\r\n+\r\n+if __name__ == \"__main__\":\r\n+    main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764671742334,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -531,506 +531,5 @@\n     app.run()\r\n \r\n \r\n if __name__ == \"__main__\":\r\n-    main()\n-import sys\r\n-from pathlib import Path\r\n-from typing import Optional\r\n-\r\n-from PyQt6.QtWidgets import QApplication\r\n-\r\n-from src.config.settings import AppSettings\r\n-from src.ui.floating_window import FloatingWindow\r\n-from src.ui.system_tray import SystemTrayIcon\r\n-from src.hotkey.hotkey_manager import HotKeyManager\r\n-from src.audio.recorder import AudioRecorder\r\n-from src.clipboard.clipboard_manager import ClipboardManager\r\n-from src.recognition import create_recognizer\r\n-from src.recognition.postprocessor import TextPostprocessor\r\n-from src.utils.logger import setup_logging\r\n-\r\n-\r\n-class App:\r\n-    \"\"\"\r\n-    Main application class: wires UI, hotkeys, audio recorder, recognizer and clipboard.\r\n-\r\n-    MVP workflow:\r\n-        global hotkey (record) down   -> start_recording()\r\n-        global hotkey (record) up     -> stop_recording()\r\n-        audio -> recognizer (Groq/GigaAM) -> postprocess -> clipboard.copy + paste\r\n-    \"\"\"\r\n-\r\n-    def __init__(self) -> None:\r\n-        self.qt_app = QApplication(sys.argv)\r\n-\r\n-        # Определяем базовую директорию приложения:\r\n-        # - в dev-режиме: корень проекта (родитель src)\r\n-        # - в собранном .exe: папка, где лежит exe\r\n-        if getattr(sys, \"frozen\", False):\r\n-            # PyInstaller / frozen\r\n-            self.base_dir = Path(sys.executable).resolve().parent\r\n-        else:\r\n-            # Обычный запуск из исходников\r\n-            self.base_dir = Path(__file__).resolve().parents[1]\r\n-\r\n-        # Load settings and logging (с учётом base_dir и config.local.yaml)\r\n-        self.settings = self._load_or_init_settings()\r\n-        setup_logging(self.settings.logging)\r\n-        \r\n-        # Core components\r\n-        self.window = FloatingWindow(self.settings.ui)\r\n-        self.tray = SystemTrayIcon(self.window, self.settings.app)\r\n-        self.clipboard = ClipboardManager()\r\n-        self.audio_recorder = AudioRecorder(self.settings.audio)\r\n-        # Основной распознаватель для текущего backend'а\r\n-        self.recognizer = create_recognizer(self.settings.recognition)\r\n-        # Кэш распознавателей по backend'ам, чтобы не пересоздавать GigaAM на каждое распознавание\r\n-        self._recognizers = {}\r\n-        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n-        self._recognizers[primary_backend] = self.recognizer\r\n-\r\n-        # Постпроцессинг текста.\r\n-        # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ, model_process и base_url,\r\n-        # что и в recognition.*, чтобы LLM работал уже при первом запуске.\r\n-        post_cfg = self.settings.postprocess\r\n-        rec_cfg = self.settings.recognition\r\n-\r\n-        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n-            # один ключ Groq: берём из recognition.groq.api_key\r\n-            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n-            # модель LLM: из recognition.groq.model_process\r\n-            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n-                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n-\r\n-        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n-            # ключ для LLM всегда берём из поля OpenAI API key (recognition.openai.api_key)\r\n-            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n-            # модель LLM\r\n-            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n-                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n-            # базовый URL LLM = тот же, что и у ASR\r\n-            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n-\r\n-        self.postprocessor = TextPostprocessor(post_cfg)\r\n-\r\n-        # Первое сообщение: если нет ключа для текущего backend'а — подсказка пользователю\r\n-        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n-        missing_key = False\r\n-        if backend == \"groq\" and not (self.settings.recognition.groq.api_key or \"\").strip():\r\n-            missing_key = True\r\n-        elif backend == \"openai\" and not (self.settings.recognition.openai.api_key or \"\").strip():\r\n-            missing_key = True\r\n-\r\n-        if missing_key:\r\n-            self.window.result_label.setText(\r\n-                \"Добавьте API‑ключ в настройках (⚙️) перед использованием распознавания.\"\r\n-            )\r\n-\r\n-        # State\r\n-        self._is_recording: bool = False\r\n-\r\n-        # Hotkeys\r\n-        self.hotkeys = HotKeyManager(\r\n-            record_hotkey=self.settings.hotkeys.record,\r\n-            cancel_hotkey=self.settings.hotkeys.cancel,\r\n-            toggle_window_hotkey=self.settings.hotkeys.toggle_window,\r\n-            toggle_debug_hotkey=self.settings.hotkeys.toggle_debug,\r\n-            on_record_press=self.start_recording,\r\n-            on_record_release=self.stop_recording,\r\n-            on_cancel=self.cancel_recording,\r\n-            on_toggle_window=self.toggle_window_visibility,\r\n-            on_toggle_debug=self.toggle_debug_mode,\r\n-        )\r\n-\r\n-        # Wire UI signals\r\n-        self.window.settings_requested.connect(self.open_settings_dialog)\r\n-        self.window.exit_requested.connect(self.quit)\r\n-        self.tray.show_window_requested.connect(self.show_window)\r\n-        self.tray.settings_requested.connect(self.open_settings_dialog)\r\n-        self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n-        self.tray.exit_requested.connect(self.quit)\r\n-\r\n-    # --------------------------------------------------------------------- UI\r\n-\r\n-    def show_window(self) -> None:\r\n-        self.window.show()\r\n-        self.window.raise_()\r\n-        self.window.activateWindow()\r\n-\r\n-    def toggle_window_visibility(self) -> None:\r\n-        \"\"\"\r\n-        Горячая клавиша \"Показать/скрыть окно\".\r\n-\r\n-        Для твоего сценария окно должно быть ВСЕГДА видно, поэтому\r\n-        мы больше не будем его прятать, а только:\r\n-        - если оно свернуто в компактный режим — разворачивать,\r\n-        - если оно где-то \"потерялось\" — показывать и поднимать наверх.\r\n-        \"\"\"\r\n-        # просто гарантируем, что окно показано и на переднем плане\r\n-        self.show_window()\r\n-\r\n-    def open_settings_dialog(self) -> None:\r\n-        \"\"\"\r\n-        Открыть диалог настроек (SettingsDialog) и применить изменения.\r\n-        \"\"\"\r\n-        from src.ui.settings_dialog import SettingsDialog  # локальный импорт, чтобы избежать циклов\r\n-\r\n-        # показать основное окно, чтобы диалог был поверх\r\n-        self.show_window()\r\n-\r\n-        dlg = SettingsDialog(self.settings, parent=self.window)\r\n-        if dlg.exec() != dlg.DialogCode.Accepted:\r\n-            return\r\n-\r\n-        new_settings = dlg.get_result()\r\n-        if new_settings is None:\r\n-            return\r\n-\r\n-        # обновляем настройки в памяти\r\n-        self.settings = new_settings\r\n-        \r\n-        # сохраняем в config.yaml\r\n-        AppSettings.save_default(self.settings)\r\n-        \r\n-        # пересоздаём recognizer и postprocessor с учётом новых настроек\r\n-        # и сбрасываем кэш распознавателей по backend'ам.\r\n-        self._recognizers = {}\r\n-        self.recognizer = create_recognizer(self.settings.recognition)\r\n-        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n-        self._recognizers[primary_backend] = self.recognizer\r\n-        \r\n-        post_cfg = self.settings.postprocess\r\n-        rec_cfg = self.settings.recognition\r\n-\r\n-        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n-            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n-            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n-                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n-\r\n-        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n-            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n-            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n-                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n-            # базовый URL LLM = тот же, что и у ASR\r\n-            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n-\r\n-        self.postprocessor = TextPostprocessor(post_cfg)\r\n-\r\n-        # если теперь ключи заданы — убрать предупреждающую надпись\r\n-        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n-        has_key = False\r\n-        if backend == \"groq\" and (self.settings.recognition.groq.api_key or \"\").strip():\r\n-            has_key = True\r\n-        elif backend == \"openai\" and (self.settings.recognition.openai.api_key or \"\").strip():\r\n-            has_key = True\r\n-\r\n-        if has_key:\r\n-            if hasattr(self.window, \"set_raw_text\"):\r\n-                self.window.set_raw_text(\"\")\r\n-            if hasattr(self.window, \"set_processed_text\"):\r\n-                self.window.set_processed_text(\"\")\r\n-            self.window.result_label.setText(\"\")\r\n-\r\n-        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n-\r\n-    # ----------------------------------------------------------------- Hotkeys\r\n-\r\n-    def start_recording(self) -> None:\r\n-        if self._is_recording:\r\n-            return\r\n-        self._is_recording = True\r\n-        self.window.set_state(\"recording\")\r\n-\r\n-        def on_finished(audio_data):\r\n-            # Этот колбэк вызывается из потока рекордера.\r\n-            # Возвращаемся к синхронной обработке, как в рабочем варианте.\r\n-            self._process_audio(audio_data)\r\n-\r\n-        self.audio_recorder.start(on_finished=on_finished)\r\n-\r\n-    def stop_recording(self) -> None:\r\n-        if not self._is_recording:\r\n-            return\r\n-        self._is_recording = False\r\n-        self.audio_recorder.stop()\r\n-\r\n-    def cancel_recording(self) -> None:\r\n-        if not self._is_recording:\r\n-            return\r\n-        self._is_recording = False\r\n-        self.audio_recorder.cancel()\r\n-        self.window.set_state(\"idle\")\r\n-\r\n-    # ----------------------------------------------------------- Processing\r\n-\r\n-    def _get_or_create_recognizer(self, backend: str):\r\n-        from dataclasses import replace  # локальный импорт, чтобы избежать циклов\r\n-\r\n-        backend = (backend or \"groq\").lower()\r\n-        cache = getattr(self, \"_recognizers\", None)\r\n-        if cache is None:\r\n-            cache = {}\r\n-            self._recognizers = cache\r\n-            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n-            cache[primary] = self.recognizer\r\n-\r\n-        if backend in cache:\r\n-            return cache[backend]\r\n-\r\n-        rec_cfg = self.settings.recognition\r\n-        tmp_cfg = replace(rec_cfg, backend=backend)\r\n-        recognizer = create_recognizer(tmp_cfg)\r\n-        cache[backend] = recognizer\r\n-        return recognizer\r\n-    \r\n-    # ----------------------------------------------------------- Processing\r\n-    \r\n-    def _process_audio(self, audio_data) -> None:\r\n-        \"\"\"\r\n-        Синхронная обработка аудио с каскадом backend'ов:\r\n-        1) основной backend из настроек (groq / openai / local),\r\n-        2) при ошибке — fallback на остальные по приоритету.\r\n-        \"\"\"\r\n-        from loguru import logger\r\n-        from pathlib import Path\r\n-        from datetime import datetime\r\n-        from src.recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n-        from src.recognition import create_recognizer  # каскадное создание по backend'у\r\n-\r\n-        self.window.set_state(\"processing\")\r\n-\r\n-        # Собираем приоритетный список backend'ов:\r\n-        # сначала выбранный пользователем, затем остальные.\r\n-        primary = (self.settings.recognition.backend or \"groq\").lower()\r\n-        all_backends = [\"groq\", \"openai\", \"local\"]\r\n-        cascade = [b for b in [primary] + all_backends if b in all_backends]\r\n-        # Убираем дубликаты, сохраняя порядок\r\n-        seen = set()\r\n-        ordered_backends = []\r\n-        for b in cascade:\r\n-            if b not in seen:\r\n-                seen.add(b)\r\n-                ordered_backends.append(b)\r\n-\r\n-        last_error: str | None = None\r\n-        raw_text: str | None = None\r\n-\r\n-        for backend in ordered_backends:\r\n-            try:\r\n-                logger.info(\"Trying recognition backend: {}\", backend)\r\n-                # Используем кэш распознавателей, чтобы не пересоздавать GigaAM-v3\r\n-                recognizer = self._get_or_create_recognizer(backend)\r\n-        \r\n-                raw_text = recognizer.transcribe(audio_data)\r\n-                logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n-                break\r\n-            except RuntimeError as exc:\r\n-                # Осмысленная ошибка — логируем и пробуем следующий backend\r\n-                logger.error(\"Recognition error on backend {}: {}\", backend, exc)\r\n-                last_error = str(exc)\r\n-                continue\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"Unexpected recognition error on backend {}: {}\", backend, exc)\r\n-                last_error = f\"Неизвестная ошибка backend '{backend}'. См. логи.\"\r\n-                continue\r\n-\r\n-        if raw_text is None:\r\n-            # Все backend'ы упали — показываем последнюю ошибку\r\n-            msg = last_error or \"Не удалось распознать аудио ни одним backend'ом.\"\r\n-            self.window.set_state(\"error\")\r\n-            self.window.show_message(msg)\r\n-            return\r\n-\r\n-        from loguru import logger as _logger\r\n-\r\n-        try:\r\n-            # 2) regex-очистка (базовый препроцессинг всегда)\r\n-            regex_text = TP._simple_cleanup(raw_text or \"\")\r\n-\r\n-            # 3) LLM-постпроцессинг (если включён в конфиге)\r\n-            processed_text = regex_text\r\n-            try:\r\n-                processed_text = self.postprocessor.process(raw_text or \"\")\r\n-            except RuntimeError as exc:\r\n-                _logger.error(\"LLM postprocess error: {}\", exc)\r\n-                self.window.show_message(str(exc))\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n-                self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n-\r\n-            # 4) показать оба варианта в окне\r\n-            try:\r\n-                if hasattr(self.window, \"set_raw_text\"):\r\n-                    self.window.set_raw_text(raw_text or \"\")\r\n-                else:\r\n-                    self.window.result_label.setText(processed_text or \"\")\r\n-\r\n-                if hasattr(self.window, \"set_processed_text\"):\r\n-                    self.window.set_processed_text(processed_text or \"\")\r\n-            except Exception:\r\n-                _logger.debug(\"window text update failed\", exc_info=True)\r\n-\r\n-            # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n-            self.clipboard.copy(processed_text or \"\")\r\n-\r\n-            # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n-            self.clipboard.paste()\r\n-\r\n-            # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n-            try:\r\n-                base_dir = Path(__file__).resolve().parents[2]\r\n-                log_dir = base_dir / \"logs\"\r\n-                log_dir.mkdir(parents=True, exist_ok=True)\r\n-                transcript_path = log_dir / \"transcripts.log\"\r\n-\r\n-                max_size_bytes = 3 * 1024 * 1024\r\n-                if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n-                    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n-                    rotated = log_dir / f\"transcripts_{ts}.log\"\r\n-                    transcript_path.rename(rotated)\r\n-\r\n-                with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n-                    f.write(\r\n-                        f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]\\\\n\"\r\n-                        f\"RAW: { (raw_text or '').strip() }\\\\n\"\r\n-                        f\"PROCESSED: { (processed_text or '').strip() }\\\\n\"\r\n-                        \"----------------------------------------\\\\n\"\r\n-                    )\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n-\r\n-            self.window.set_state(\"ready\")\r\n-        except Exception as exc:  # noqa: BLE001\r\n-            _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n-            self.window.set_state(\"error\")\r\n-            self.window.show_message(\"Неизвестная ошибка постобработки. См. логи.\")\r\n-\r\n-    # -------------------------------------------------------------- Debug\r\n-\r\n-    def toggle_debug_mode(self) -> None:\r\n-        # Placeholder: will reconfigure logging level later\r\n-        self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n-\r\n-    # ----------------------------------------------------------- Settings / config helpers\r\n-\r\n-    def _load_or_init_settings(self) -> AppSettings:\r\n-        \"\"\"\r\n-        Загрузка настроек с учётом портативного режима.\r\n-\r\n-        Логика:\r\n-        - Ищем config.yaml в self.base_dir (рядом с exe или в корне проекта).\r\n-        - Если файла нет — создаём минимальный config.yaml с backend=local.\r\n-        - Затем вызываем AppSettings.load_default(), который уже умеет\r\n-          подмешивать config.local.yaml поверх config.yaml.\r\n-        \"\"\"\r\n-        config_path = self.base_dir / \"config.yaml\"\r\n-\r\n-        if not config_path.exists():\r\n-            # Минимальный конфиг по умолчанию: локальный backend, безопасные значения.\r\n-            default_config = {\r\n-                \"app\": {\r\n-                    \"name\": \"VoiceCapture\",\r\n-                    \"version\": \"0.1.0\",\r\n-                },\r\n-                \"hotkeys\": {\r\n-                    \"record\": \"ctrl+win\",\r\n-                    \"cancel\": \"esc\",\r\n-                    \"toggle_window\": \"ctrl+alt+s\",\r\n-                    \"toggle_debug\": \"ctrl+alt+d\",\r\n-                },\r\n-                \"audio\": {\r\n-                    \"sample_rate\": 16000,\r\n-                    \"channels\": 1,\r\n-                    \"max_duration\": 120,\r\n-                },\r\n-                \"recognition\": {\r\n-                    \"backend\": \"local\",\r\n-                    \"local\": {\r\n-                        \"model\": \"large-v3\",\r\n-                        \"device\": \"cuda\",\r\n-                        \"compute_type\": \"float16\",\r\n-                        \"language\": \"ru\",\r\n-                        \"beam_size\": 5,\r\n-                        \"temperature\": 0.0,\r\n-                    },\r\n-                    \"openai\": {\r\n-                        \"api_key\": \"\",\r\n-                        \"model\": \"whisper-1\",\r\n-                        \"model_process\": \"gpt-4o-mini\",\r\n-                        \"language\": \"ru\",\r\n-                        # base_url намеренно оставляем пустым, чтобы пользователь\r\n-                        # задал его в настройках (OpenAI Base URL).\r\n-                        \"base_url\": \"\",\r\n-                    },\r\n-                    \"groq\": {\r\n-                        \"api_key\": \"\",\r\n-                        \"model\": \"whisper-large-v3\",\r\n-                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n-                        \"language\": \"ru\",\r\n-                    },\r\n-                },\r\n-                # Блок postprocess больше не хранит ключи / base_url.\r\n-                # Здесь только включение, режим и \"отображательные\" модели.\r\n-                \"postprocess\": {\r\n-                    \"enabled\": True,\r\n-                    \"mode\": \"llm\",\r\n-                    \"llm_backend\": \"groq\",\r\n-                    \"groq\": {\r\n-                        \"model\": \"moonshotai/kimi-k2-instruct\",\r\n-                    },\r\n-                    \"openai\": {\r\n-                        \"model\": \"gpt-5.1\",\r\n-                    },\r\n-                },\r\n-                \"ui\": {\r\n-                    # Старые поля width/height/compact_mode больше не используются,\r\n-                    # но при первой генерации конфига запишем их для обратной совместимости.\r\n-                    \"width\": 320,\r\n-                    \"height\": 200,\r\n-                    \"opacity\": 0.9,\r\n-                    \"compact_mode\": False,\r\n-                },\r\n-                \"logging\": {\r\n-                    \"level\": \"INFO\",\r\n-                    \"log_dir\": \"logs\",\r\n-                },\r\n-            }\r\n-\r\n-            try:\r\n-                import yaml\r\n-\r\n-                with config_path.open(\"w\", encoding=\"utf-8\") as f:\r\n-                    yaml.safe_dump(default_config, f, allow_unicode=True, sort_keys=False)\r\n-            except Exception:\r\n-                # Если по какой-то причине не удалось записать файл — продолжаем\r\n-                # с дефолтами из dataclass'ов AppSettings.\r\n-                pass\r\n-\r\n-        # Теперь загружаем настройки стандартным способом:\r\n-        settings = AppSettings.load_default()\r\n-\r\n-        # Гарантируем, что backend задан\r\n-        if not getattr(settings.recognition, \"backend\", None):\r\n-            settings.recognition.backend = \"local\"\r\n-\r\n-        return settings\r\n-\r\n-    # -------------------------------------------------------------- Lifecycle\r\n-\r\n-    def quit(self) -> None:\r\n-        self.hotkeys.stop()\r\n-        self.qt_app.quit()\r\n-\r\n-    def run(self) -> None:\r\n-        self.hotkeys.start()\r\n-        self.show_window()\r\n-        sys.exit(self.qt_app.exec())\r\n-\r\n-\r\n-def main() -> None:\r\n-    app = App()\r\n-    app.run()\r\n-\r\n-\r\n-if __name__ == \"__main__\":\r\n     main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764731664664,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,9 @@\n import sys\r\n from pathlib import Path\r\n from typing import Optional\r\n \r\n+from PyQt6.QtCore import QObject, pyqtSignal\r\n from PyQt6.QtWidgets import QApplication\r\n \r\n from config.settings import AppSettings\r\n from ui.floating_window import FloatingWindow\r\n@@ -14,9 +15,14 @@\n from recognition.postprocessor import TextPostprocessor\r\n from utils.logger import setup_logging\r\n \r\n \r\n-class App:\r\n+class App(QObject):\r\n+    # Сигналы для безопасного обновления UI из других потоков\r\n+    state_changed = pyqtSignal(str)\r\n+    message_shown = pyqtSignal(str, int)\r\n+    text_updated = pyqtSignal(str, str)\r\n+\r\n     \"\"\"\r\n     Main application class: wires UI, hotkeys, audio recorder, recognizer and clipboard.\r\n \r\n     MVP workflow:\r\n@@ -25,8 +31,9 @@\n         audio -> recognizer (Groq/GigaAM) -> postprocess -> clipboard.copy + paste\r\n     \"\"\"\r\n \r\n     def __init__(self) -> None:\r\n+        super().__init__()\r\n         self.qt_app = QApplication(sys.argv)\r\n \r\n         # Определяем базовую директорию приложения:\r\n         # - в dev-режиме: корень проекта (родитель src)\r\n@@ -114,10 +121,26 @@\n         self.tray.settings_requested.connect(self.open_settings_dialog)\r\n         self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n         self.tray.exit_requested.connect(self.quit)\r\n \r\n+        # Подключаем сигналы к слотам окна\r\n+        self.state_changed.connect(self.window.set_state)\r\n+        self.message_shown.connect(self.window.show_message)\r\n+        self.text_updated.connect(self._on_text_updated)\r\n+\r\n     # --------------------------------------------------------------------- UI\r\n \r\n+    def _on_text_updated(self, raw_text: str, processed_text: str) -> None:\r\n+        \"\"\"Слот для обновления текстовых полей в окне.\"\"\"\r\n+        if hasattr(self.window, \"set_raw_text\"):\r\n+            self.window.set_raw_text(raw_text or \"\")\r\n+        else:\r\n+            # fallback для старых версий окна\r\n+            self.window.result_label.setText(processed_text or \"\")\r\n+\r\n+        if hasattr(self.window, \"set_processed_text\"):\r\n+            self.window.set_processed_text(processed_text or \"\")\r\n+\r\n     def show_window(self) -> None:\r\n         self.window.show()\r\n         self.window.raise_()\r\n         self.window.activateWindow()\r\n@@ -267,9 +290,9 @@\n         from pathlib import Path\r\n         from datetime import datetime\r\n         from recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n \r\n-        self.window.set_state(\"processing\")\r\n+        self.state_changed.emit(\"processing\")\r\n \r\n         # ------------------------ вычисляем длительность аудио -----------------\r\n         try:\r\n             import numpy as _np  # локальный импорт, чтобы не тянуть при импорте модуля\r\n@@ -325,10 +348,10 @@\n                 continue\r\n \r\n         if raw_text is None:\r\n             msg = last_error or \"Не удалось распознать аудио ни одним backend'ом.\"\r\n-            self.window.set_state(\"error\")\r\n-            self.window.show_message(msg)\r\n+            self.state_changed.emit(\"error\")\r\n+            self.message_shown.emit(msg, 3000)\r\n             return\r\n \r\n         from loguru import logger as _logger\r\n \r\n@@ -341,25 +364,16 @@\n             try:\r\n                 processed_text = self.postprocessor.process(raw_text or \"\")\r\n             except RuntimeError as exc:\r\n                 _logger.error(\"LLM postprocess error: {}\", exc)\r\n-                self.window.show_message(str(exc))\r\n+                self.message_shown.emit(str(exc), 3000)\r\n             except Exception as exc:  # noqa: BLE001\r\n                 _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n-                self.window.show_message(\"Ошибка LLM-постпроцессинга. См. логи.\")\r\n+                self.message_shown.emit(\"Ошибка LLM-постпроцессинга. См. логи.\", 3000)\r\n \r\n-            # 4) показать оба варианта в окне\r\n-            try:\r\n-                if hasattr(self.window, \"set_raw_text\"):\r\n-                    self.window.set_raw_text(raw_text or \"\")\r\n-                else:\r\n-                    self.window.result_label.setText(processed_text or \"\")\r\n+            # 4) показать оба варианта в окне (через сигнал)\r\n+            self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n \r\n-                if hasattr(self.window, \"set_processed_text\"):\r\n-                    self.window.set_processed_text(processed_text or \"\")\r\n-            except Exception:\r\n-                _logger.debug(\"window text update failed\", exc_info=True)\r\n-\r\n             # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n             self.clipboard.copy(processed_text or \"\")\r\n \r\n             # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n@@ -396,13 +410,13 @@\n                     )\r\n             except Exception as exc:  # noqa: BLE001\r\n                 _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n \r\n-            self.window.set_state(\"ready\")\r\n+            self.state_changed.emit(\"ready\")\r\n         except Exception as exc:  # noqa: BLE001\r\n             _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n-            self.window.set_state(\"error\")\r\n-            self.window.show_message(\"Неизвестная ошибка постобработки. См. логи.\")\r\n+            self.state_changed.emit(\"error\")\r\n+            self.message_shown.emit(\"Неизвестная ошибка постобработки. См. логи.\", 3000)\r\n \r\n     # -------------------------------------------------------------- Debug\r\n \r\n     def toggle_debug_mode(self) -> None:\r\n"
                },
                {
                    "date": 1764794842213,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,7 @@\n import sys\r\n+import time\r\n+import threading\r\n from pathlib import Path\r\n from typing import Optional\r\n \r\n from PyQt6.QtCore import QObject, pyqtSignal\r\n@@ -99,8 +101,10 @@\n             )\r\n \r\n         # State\r\n         self._is_recording: bool = False\r\n+        self._last_audio_data: Optional[any] = None\r\n+        self._processing_lock = threading.Lock()\r\n \r\n         # Hotkeys\r\n         self.hotkeys = HotKeyManager(\r\n             record_hotkey=self.settings.hotkeys.record,\r\n@@ -116,8 +120,9 @@\n \r\n         # Wire UI signals\r\n         self.window.settings_requested.connect(self.open_settings_dialog)\r\n         self.window.exit_requested.connect(self.quit)\r\n+        self.window.retry_requested.connect(self._retry_processing)\r\n         self.tray.show_window_requested.connect(self.show_window)\r\n         self.tray.settings_requested.connect(self.open_settings_dialog)\r\n         self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n         self.tray.exit_requested.connect(self.quit)\r\n@@ -222,18 +227,36 @@\n         self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n \r\n     # ----------------------------------------------------------------- Hotkeys\r\n \r\n+    def _retry_processing(self) -> None:\r\n+        \"\"\"Запускает повторную обработку последнего записанного аудио.\"\"\"\r\n+        from loguru import logger\r\n+\r\n+        if self._last_audio_data:\r\n+            logger.info(\"Retrying processing for the last audio data.\")\r\n+            # Запускаем в новом потоке, чтобы не блокировать UI\r\n+            thread = threading.Thread(target=self._process_audio, args=(self._last_audio_data,))\r\n+            thread.start()\r\n+        else:\r\n+            logger.warning(\"Retry requested, but no audio data is available.\")\r\n+            self.state_changed.emit(\"idle\")\r\n+\r\n     def start_recording(self) -> None:\r\n         if self._is_recording:\r\n             return\r\n         self._is_recording = True\r\n+        # При начале новой записи сбрасываем старые данные и убираем кнопку \"повторить\"\r\n+        self._last_audio_data = None\r\n+        self.window.hide_retry_button()\r\n         self.window.set_state(\"recording\")\r\n \r\n         def on_finished(audio_data):\r\n             # Этот колбэк вызывается из потока рекордера.\r\n-            # Возвращаемся к синхронной обработке, как в рабочем варианте.\r\n-            self._process_audio(audio_data)\r\n+            # Запускаем обработку в новом потоке, чтобы не блокировать поток рекордера\r\n+            # и чтобы основной цикл событий Qt продолжал работать.\r\n+            thread = threading.Thread(target=self._process_audio, args=(audio_data,))\r\n+            thread.start()\r\n \r\n         self.audio_recorder.start(on_finished=on_finished)\r\n \r\n     def stop_recording(self) -> None:\r\n@@ -274,150 +297,144 @@\n     # ----------------------------------------------------------- Processing\r\n     \r\n     def _process_audio(self, audio_data) -> None:\r\n         \"\"\"\r\n-        Синхронная обработка аудио с каскадом backend'ов:\r\n-        1) основной backend из настроек (groq / openai / local),\r\n-        2) при ошибке — fallback на остальные по приоритету.\r\n-\r\n-        Дополнительно:\r\n-        - логируем все распознавания в отдельный logfile с указанием:\r\n-          * времени;\r\n-          * backend'а;\r\n-          * длительности аудио;\r\n-          * исходного и обработанного текста.\r\n+        Синхронная обработка аудио с каскадом backend'ов и ретраями.\r\n         \"\"\"\r\n         from loguru import logger\r\n         from pathlib import Path\r\n         from datetime import datetime\r\n-        from recognition.postprocessor import TextPostprocessor as TP  # для _simple_cleanup\r\n+        from recognition.postprocessor import TextPostprocessor as TP\r\n \r\n-        self.state_changed.emit(\"processing\")\r\n+        if not self._processing_lock.acquire(blocking=False):\r\n+            logger.warning(\"Processing is already in progress. Skipping new request.\")\r\n+            return\r\n \r\n-        # ------------------------ вычисляем длительность аудио -----------------\r\n         try:\r\n-            import numpy as _np  # локальный импорт, чтобы не тянуть при импорте модуля\r\n+            self._last_audio_data = audio_data\r\n+            self.state_changed.emit(\"processing\")\r\n \r\n-            samples = audio_data.samples\r\n-            sample_rate = getattr(audio_data, \"sample_rate\", None) or getattr(\r\n-                audio_data, \"rate\", None\r\n-            ) or 16000\r\n-\r\n-            if isinstance(samples, _np.ndarray):\r\n+            # ------------------------ вычисляем длительность аудио -----------------\r\n+            try:\r\n+                import numpy as _np\r\n+                samples = audio_data.samples\r\n+                sample_rate = getattr(audio_data, \"sample_rate\", 16000)\r\n                 total_samples = samples.shape[0]\r\n-            else:\r\n-                samples = _np.asarray(samples)\r\n-                total_samples = samples.shape[0]\r\n+                audio_duration_sec = float(total_samples) / float(sample_rate)\r\n+            except Exception as exc:\r\n+                logger.exception(\"Failed to compute audio duration: {}\", exc)\r\n+                audio_duration_sec = -1.0\r\n \r\n-            audio_duration_sec = float(total_samples) / float(sample_rate or 1)\r\n-        except Exception as exc:  # noqa: BLE001\r\n-            logger.exception(\"Failed to compute audio duration: {}\", exc)\r\n-            audio_duration_sec = -1.0\r\n+            # ------------------------ каскад backend'ов с ретраями ----------------\r\n+            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+            all_backends = [\"groq\", \"openai\", \"local\"]\r\n+            cascade = [b for b in [primary] + all_backends if b in all_backends]\r\n+            seen = set()\r\n+            ordered_backends = [b for b in cascade if not (b in seen or seen.add(b))]\r\n \r\n-        # ------------------------ каскад backend'ов ----------------------------\r\n-        primary = (self.settings.recognition.backend or \"groq\").lower()\r\n-        all_backends = [\"groq\", \"openai\", \"local\"]\r\n-        cascade = [b for b in [primary] + all_backends if b in all_backends]\r\n+            MAX_ATTEMPTS = 5\r\n+            RETRY_DELAY_SEC = 2\r\n+            BACKEND_SWITCH_DELAY_SEC = 1\r\n \r\n-        seen = set()\r\n-        ordered_backends = []\r\n-        for b in cascade:\r\n-            if b not in seen:\r\n-                seen.add(b)\r\n-                ordered_backends.append(b)\r\n+            last_error: str | None = None\r\n+            raw_text: str | None = None\r\n+            used_backend: str | None = None\r\n \r\n-        last_error: str | None = None\r\n-        raw_text: str | None = None\r\n-        used_backend: str | None = None\r\n+            for attempt in range(MAX_ATTEMPTS):\r\n+                logger.info(f\"Recognition attempt #{attempt + 1}/{MAX_ATTEMPTS}\")\r\n+                for backend in ordered_backends:\r\n+                    try:\r\n+                        logger.info(\"Trying recognition backend: {}\", backend)\r\n+                        recognizer = self._get_or_create_recognizer(backend)\r\n+                        raw_text = recognizer.transcribe(audio_data)\r\n+                        used_backend = backend\r\n+                        logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n+                        break  # Exit inner loop (backends)\r\n+                    except Exception as exc:\r\n+                        logger.error(\"Recognition error on backend {}: {}\", backend, exc)\r\n+                        last_error = str(exc)\r\n+                        time.sleep(BACKEND_SWITCH_DELAY_SEC)\r\n+                        continue\r\n+                \r\n+                if raw_text is not None:\r\n+                    break  # Exit outer loop (attempts)\r\n \r\n-        for backend in ordered_backends:\r\n-            try:\r\n-                logger.info(\"Trying recognition backend: {}\", backend)\r\n-                recognizer = self._get_or_create_recognizer(backend)\r\n+                if attempt < MAX_ATTEMPTS - 1:\r\n+                    logger.info(f\"Attempt #{attempt + 1} failed. Retrying in {RETRY_DELAY_SEC} seconds...\")\r\n+                    time.sleep(RETRY_DELAY_SEC)\r\n \r\n-                raw_text = recognizer.transcribe(audio_data)\r\n-                used_backend = backend\r\n-                logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n-                break\r\n-            except RuntimeError as exc:\r\n-                logger.error(\"Recognition error on backend {}: {}\", backend, exc)\r\n-                last_error = str(exc)\r\n-                continue\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                logger.exception(\"Unexpected recognition error on backend {}: {}\", backend, exc)\r\n-                last_error = f\"Неизвестная ошибка backend '{backend}'. См. логи.\"\r\n-                continue\r\n+            if raw_text is None:\r\n+                msg = \"Ошибка соединения. Настройте соединение и попробуйте еще раз.\"\r\n+                self.state_changed.emit(\"error\")\r\n+                self.message_shown.emit(msg, 0)  # 0 timeout to keep it visible\r\n+                self.window.show_retry_button()\r\n+                return\r\n \r\n-        if raw_text is None:\r\n-            msg = last_error or \"Не удалось распознать аудио ни одним backend'ом.\"\r\n-            self.state_changed.emit(\"error\")\r\n-            self.message_shown.emit(msg, 3000)\r\n-            return\r\n+            from loguru import logger as _logger\r\n \r\n-        from loguru import logger as _logger\r\n+            try:\r\n+                # 2) regex-очистка (базовый препроцессинг всегда)\r\n+                regex_text = TP._simple_cleanup(raw_text or \"\")\r\n \r\n-        try:\r\n-            # 2) regex-очистка (базовый препроцессинг всегда)\r\n-            regex_text = TP._simple_cleanup(raw_text or \"\")\r\n+                # 3) LLM-постпроцессинг (если включён в конфиге)\r\n+                processed_text = regex_text\r\n+                try:\r\n+                    processed_text = self.postprocessor.process(raw_text or \"\")\r\n+                except RuntimeError as exc:\r\n+                    _logger.error(\"LLM postprocess error: {}\", exc)\r\n+                    self.message_shown.emit(str(exc), 3000)\r\n+                except Exception as exc:  # noqa: BLE001\r\n+                    _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                    self.message_shown.emit(\"Ошибка LLM-постпроцессинга. См. логи.\", 3000)\r\n \r\n-            # 3) LLM-постпроцессинг (если включён в конфиге)\r\n-            processed_text = regex_text\r\n-            try:\r\n-                processed_text = self.postprocessor.process(raw_text or \"\")\r\n-            except RuntimeError as exc:\r\n-                _logger.error(\"LLM postprocess error: {}\", exc)\r\n-                self.message_shown.emit(str(exc), 3000)\r\n-            except Exception as exc:  # noqa: BLE001\r\n-                _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n-                self.message_shown.emit(\"Ошибка LLM-постпроцессинга. См. логи.\", 3000)\r\n+                # 4) показать оба варианта в окне (через сигнал)\r\n+                self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n \r\n-            # 4) показать оба варианта в окне (через сигнал)\r\n-            self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n+                # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+                self.clipboard.copy(processed_text or \"\")\r\n \r\n-            # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n-            self.clipboard.copy(processed_text or \"\")\r\n+                # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n+                self.clipboard.paste()\r\n \r\n-            # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n-            self.clipboard.paste()\r\n+                # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+                try:\r\n+                    if getattr(sys, \"frozen\", False):\r\n+                        base_dir = Path(sys.executable).resolve().parent\r\n+                    else:\r\n+                        base_dir = Path(__file__).resolve().parents[1]\r\n \r\n-            # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n-            try:\r\n-                # Базовая директория приложения (та же логика, что и в App._load_or_init_settings)\r\n-                if getattr(sys, \"frozen\", False):\r\n-                    base_dir = Path(sys.executable).resolve().parent\r\n-                else:\r\n-                    base_dir = Path(__file__).resolve().parents[1]\r\n+                    log_dir = base_dir / \"logs\"\r\n+                    log_dir.mkdir(parents=True, exist_ok=True)\r\n+                    transcript_path = log_dir / \"transcripts.log\"\r\n \r\n-                log_dir = base_dir / \"logs\"\r\n-                log_dir.mkdir(parents=True, exist_ok=True)\r\n-                transcript_path = log_dir / \"transcripts.log\"\r\n+                    max_size_bytes = 3 * 1024 * 1024\r\n+                    if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n+                        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n+                        rotated = log_dir / f\"transcripts_{ts}.log\"\r\n+                        transcript_path.rename(rotated)\r\n \r\n-                max_size_bytes = 3 * 1024 * 1024\r\n-                if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n-                    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n-                    rotated = log_dir / f\"transcripts_{ts}.log\"\r\n-                    transcript_path.rename(rotated)\r\n+                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\r\n+                    backend_str = used_backend or (self.settings.recognition.backend or \"unknown\")\r\n \r\n-                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\r\n-                backend_str = used_backend or (self.settings.recognition.backend or \"unknown\")\r\n+                    with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n+                        f.write(\r\n+                            f\"[{timestamp}] backend={backend_str} \"\r\n+                            f\"duration={audio_duration_sec:.3f}s\\n\"\r\n+                            f\"RAW: {(raw_text or '').strip()}\\n\"\r\n+                            f\"PROCESSED: {(processed_text or '').strip()}\\n\"\r\n+                            \"----------------------------------------\\n\"\r\n+                        )\r\n+                except Exception as exc:  # noqa: BLE001\r\n+                    _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n \r\n-                with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n-                    f.write(\r\n-                        f\"[{timestamp}] backend={backend_str} \"\r\n-                        f\"duration={audio_duration_sec:.3f}s\\n\"\r\n-                        f\"RAW: {(raw_text or '').strip()}\\n\"\r\n-                        f\"PROCESSED: {(processed_text or '').strip()}\\n\"\r\n-                        \"----------------------------------------\\n\"\r\n-                    )\r\n+                self.state_changed.emit(\"ready\")\r\n             except Exception as exc:  # noqa: BLE001\r\n-                _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n+                _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n+                self.state_changed.emit(\"error\")\r\n+                self.message_shown.emit(\"Неизвестная ошибка постобработки. См. логи.\", 3000)\r\n+        finally:\r\n+            self._processing_lock.release()\r\n \r\n-            self.state_changed.emit(\"ready\")\r\n-        except Exception as exc:  # noqa: BLE001\r\n-            _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n-            self.state_changed.emit(\"error\")\r\n-            self.message_shown.emit(\"Неизвестная ошибка постобработки. См. логи.\", 3000)\r\n-\r\n     # -------------------------------------------------------------- Debug\r\n \r\n     def toggle_debug_mode(self) -> None:\r\n         # Placeholder: will reconfigure logging level later\r\n"
                },
                {
                    "date": 1764806766574,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,567 @@\n+import sys\r\n+import time\r\n+import threading\r\n+from pathlib import Path\r\n+from typing import Optional\r\n+\r\n+from PyQt6.QtCore import QObject, pyqtSignal\r\n+from PyQt6.QtWidgets import QApplication\r\n+\r\n+from config.settings import AppSettings\r\n+from ui.floating_window import FloatingWindow\r\n+from ui.system_tray import SystemTrayIcon\r\n+from hotkey.hotkey_manager import HotKeyManager\r\n+from audio.recorder import AudioRecorder\r\n+from clipboard.clipboard_manager import ClipboardManager\r\n+from recognition import create_recognizer\r\n+from recognition.postprocessor import TextPostprocessor\r\n+from utils.logger import setup_logging\r\n+\r\n+\r\n+class App(QObject):\r\n+    # Сигналы для безопасного обновления UI из других потоков\r\n+    state_changed = pyqtSignal(str)\r\n+    message_shown = pyqtSignal(str, int)\r\n+    text_updated = pyqtSignal(str, str)\r\n+\r\n+    \"\"\"\r\n+    Main application class: wires UI, hotkeys, audio recorder, recognizer and clipboard.\r\n+\r\n+    MVP workflow:\r\n+        global hotkey (record) down   -> start_recording()\r\n+        global hotkey (record) up     -> stop_recording()\r\n+        audio -> recognizer (Groq/GigaAM) -> postprocess -> clipboard.copy + paste\r\n+    \"\"\"\r\n+\r\n+    def __init__(self) -> None:\r\n+        super().__init__()\r\n+        self.qt_app = QApplication(sys.argv)\r\n+\r\n+        # Определяем базовую директорию приложения:\r\n+        # - в dev-режиме: корень проекта (родитель src)\r\n+        # - в собранном .exe: папка, где лежит exe\r\n+        if getattr(sys, \"frozen\", False):\r\n+            # PyInstaller / frozen\r\n+            self.base_dir = Path(sys.executable).resolve().parent\r\n+        else:\r\n+            # Обычный запуск из исходников\r\n+            self.base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+        # Load settings and logging (с учётом base_dir и config.local.yaml)\r\n+        self.settings = self._load_or_init_settings()\r\n+        setup_logging(self.settings.logging)\r\n+        \r\n+        # Core components\r\n+        self.window = FloatingWindow(self.settings.ui)\r\n+        self.tray = SystemTrayIcon(self.window, self.settings.app)\r\n+        self.clipboard = ClipboardManager()\r\n+        self.audio_recorder = AudioRecorder(self.settings.audio)\r\n+        # Основной распознаватель для текущего backend'а\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        # Кэш распознавателей по backend'ам, чтобы не пересоздавать GigaAM на каждое распознавание\r\n+        self._recognizers = {}\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n+\r\n+        # Постпроцессинг текста.\r\n+        # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ, model_process и base_url,\r\n+        # что и в recognition.*, чтобы LLM работал уже при первом запуске.\r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            # один ключ Groq: берём из recognition.groq.api_key\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            # модель LLM: из recognition.groq.model_process\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            # ключ для LLM всегда берём из поля OpenAI API key (recognition.openai.api_key)\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            # модель LLM\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n+        # Первое сообщение: если нет ключа для текущего backend'а — подсказка пользователю\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        missing_key = False\r\n+        if backend == \"groq\" and not (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            missing_key = True\r\n+        elif backend == \"openai\" and not (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            missing_key = True\r\n+\r\n+        if missing_key:\r\n+            self.window.result_label.setText(\r\n+                \"Добавьте API‑ключ в настройках (⚙️) перед использованием распознавания.\"\r\n+            )\r\n+\r\n+        # State\r\n+        self._is_recording: bool = False\r\n+        self._last_audio_data: Optional[any] = None\r\n+        self._processing_lock = threading.Lock()\r\n+\r\n+        # Hotkeys\r\n+        self.hotkeys = HotKeyManager(\r\n+            record_hotkey=self.settings.hotkeys.record,\r\n+            cancel_hotkey=self.settings.hotkeys.cancel,\r\n+            toggle_window_hotkey=self.settings.hotkeys.toggle_window,\r\n+            toggle_debug_hotkey=self.settings.hotkeys.toggle_debug,\r\n+            on_record_press=self.start_recording,\r\n+            on_record_release=self.stop_recording,\r\n+            on_cancel=self.cancel_recording,\r\n+            on_toggle_window=self.toggle_window_visibility,\r\n+            on_toggle_debug=self.toggle_debug_mode,\r\n+        )\r\n+\r\n+        # Wire UI signals\r\n+        self.window.settings_requested.connect(self.open_settings_dialog)\r\n+        self.window.exit_requested.connect(self.quit)\r\n+        self.window.retry_requested.connect(self._retry_processing)\r\n+        self.tray.show_window_requested.connect(self.show_window)\r\n+        self.tray.settings_requested.connect(self.open_settings_dialog)\r\n+        self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n+        self.tray.exit_requested.connect(self.quit)\r\n+\r\n+        # Подключаем сигналы к слотам окна\r\n+        self.state_changed.connect(self.window.set_state)\r\n+        self.message_shown.connect(self.window.show_message)\r\n+        self.text_updated.connect(self._on_text_updated)\r\n+\r\n+    # --------------------------------------------------------------------- UI\r\n+\r\n+    def _on_text_updated(self, raw_text: str, processed_text: str) -> None:\r\n+        \"\"\"Слот для обновления текстовых полей в окне.\"\"\"\r\n+        if hasattr(self.window, \"set_raw_text\"):\r\n+            self.window.set_raw_text(raw_text or \"\")\r\n+        else:\r\n+            # fallback для старых версий окна\r\n+            self.window.result_label.setText(processed_text or \"\")\r\n+\r\n+        if hasattr(self.window, \"set_processed_text\"):\r\n+            self.window.set_processed_text(processed_text or \"\")\r\n+\r\n+    def show_window(self) -> None:\r\n+        self.window.show()\r\n+        self.window.raise_()\r\n+        self.window.activateWindow()\r\n+\r\n+    def toggle_window_visibility(self) -> None:\r\n+        \"\"\"\r\n+        Горячая клавиша \"Показать/скрыть окно\".\r\n+\r\n+        Для твоего сценария окно должно быть ВСЕГДА видно, поэтому\r\n+        мы больше не будем его прятать, а только:\r\n+        - если оно свернуто в компактный режим — разворачивать,\r\n+        - если оно где-то \"потерялось\" — показывать и поднимать наверх.\r\n+        \"\"\"\r\n+        # просто гарантируем, что окно показано и на переднем плане\r\n+        self.show_window()\r\n+\r\n+    def open_settings_dialog(self) -> None:\r\n+        \"\"\"\r\n+        Открыть диалог настроек (SettingsDialog) и применить изменения.\r\n+        \"\"\"\r\n+        from ui.settings_dialog import SettingsDialog  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        # показать основное окно, чтобы диалог был поверх\r\n+        self.show_window()\r\n+\r\n+        dlg = SettingsDialog(self.settings, parent=self.window)\r\n+        if dlg.exec() != dlg.DialogCode.Accepted:\r\n+            return\r\n+\r\n+        new_settings = dlg.get_result()\r\n+        if new_settings is None:\r\n+            return\r\n+\r\n+        # обновляем настройки в памяти\r\n+        self.settings = new_settings\r\n+        \r\n+        # сохраняем в config.yaml\r\n+        AppSettings.save_default(self.settings)\r\n+        \r\n+        # пересоздаём recognizer и postprocessor с учётом новых настроек\r\n+        # и сбрасываем кэш распознавателей по backend'ам.\r\n+        self._recognizers = {}\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n+        \r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n+        # если теперь ключи заданы — убрать предупреждающую надпись\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        has_key = False\r\n+        if backend == \"groq\" and (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            has_key = True\r\n+        elif backend == \"openai\" and (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            has_key = True\r\n+\r\n+        if has_key:\r\n+            if hasattr(self.window, \"set_raw_text\"):\r\n+                self.window.set_raw_text(\"\")\r\n+            if hasattr(self.window, \"set_processed_text\"):\r\n+                self.window.set_processed_text(\"\")\r\n+            self.window.result_label.setText(\"\")\r\n+\r\n+        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+\r\n+    # ----------------------------------------------------------------- Hotkeys\r\n+\r\n+    def _retry_processing(self) -> None:\r\n+        \"\"\"Запускает повторную обработку последнего записанного аудио.\"\"\"\r\n+        from loguru import logger\r\n+\r\n+        if self._last_audio_data:\r\n+            logger.info(\"Retrying processing for the last audio data.\")\r\n+            # Запускаем в новом потоке, чтобы не блокировать UI\r\n+            thread = threading.Thread(target=self._process_audio, args=(self._last_audio_data,))\r\n+            thread.start()\r\n+        else:\r\n+            logger.warning(\"Retry requested, but no audio data is available.\")\r\n+            self.state_changed.emit(\"idle\")\r\n+\r\n+    def start_recording(self) -> None:\r\n+        if self._is_recording:\r\n+            return\r\n+        self._is_recording = True\r\n+        # При начале новой записи сбрасываем старые данные и убираем кнопку \"повторить\"\r\n+        self._last_audio_data = None\r\n+        self.window.hide_retry_button()\r\n+        self.window.set_state(\"recording\")\r\n+\r\n+        def on_finished(audio_data):\r\n+            # Этот колбэк вызывается из потока рекордера.\r\n+            # Запускаем обработку в новом потоке, чтобы не блокировать поток рекордера\r\n+            # и чтобы основной цикл событий Qt продолжал работать.\r\n+            thread = threading.Thread(target=self._process_audio, args=(audio_data,))\r\n+            thread.start()\r\n+\r\n+        self.audio_recorder.start(on_finished=on_finished)\r\n+\r\n+    def stop_recording(self) -> None:\r\n+        if not self._is_recording:\r\n+            return\r\n+        self._is_recording = False\r\n+        self.audio_recorder.stop()\r\n+\r\n+    def cancel_recording(self) -> None:\r\n+        if not self._is_recording:\r\n+            return\r\n+        self._is_recording = False\r\n+        self.audio_recorder.cancel()\r\n+        self.window.set_state(\"idle\")\r\n+\r\n+    # ----------------------------------------------------------- Processing\r\n+\r\n+    def _get_or_create_recognizer(self, backend: str):\r\n+        from dataclasses import replace  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        backend = (backend or \"groq\").lower()\r\n+        cache = getattr(self, \"_recognizers\", None)\r\n+        if cache is None:\r\n+            cache = {}\r\n+            self._recognizers = cache\r\n+            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+            cache[primary] = self.recognizer\r\n+\r\n+        if backend in cache:\r\n+            return cache[backend]\r\n+\r\n+        rec_cfg = self.settings.recognition\r\n+        tmp_cfg = replace(rec_cfg, backend=backend)\r\n+        recognizer = create_recognizer(tmp_cfg)\r\n+        cache[backend] = recognizer\r\n+        return recognizer\r\n+    \r\n+    # ----------------------------------------------------------- Processing\r\n+    \r\n+    def _process_audio(self, audio_data) -> None:\r\n+        \"\"\"\r\n+        Синхронная обработка аудио с каскадом backend'ов и ретраями.\r\n+        \"\"\"\r\n+        from loguru import logger\r\n+        from pathlib import Path\r\n+        from datetime import datetime\r\n+        from recognition.postprocessor import TextPostprocessor as TP\r\n+\r\n+        if not self._processing_lock.acquire(blocking=False):\r\n+            logger.warning(\"Processing is already in progress. Skipping new request.\")\r\n+            return\r\n+\r\n+        try:\r\n+            self._last_audio_data = audio_data\r\n+            self.state_changed.emit(\"processing\")\r\n+\r\n+            # ------------------------ вычисляем длительность аудио -----------------\r\n+            try:\r\n+                import numpy as _np\r\n+                samples = audio_data.samples\r\n+                sample_rate = getattr(audio_data, \"sample_rate\", 16000)\r\n+                total_samples = samples.shape[0]\r\n+                audio_duration_sec = float(total_samples) / float(sample_rate)\r\n+            except Exception as exc:\r\n+                logger.exception(\"Failed to compute audio duration: {}\", exc)\r\n+                audio_duration_sec = -1.0\r\n+\r\n+            # ------------------------ каскад backend'ов с ретраями ----------------\r\n+            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+            all_backends = [\"groq\", \"openai\", \"local\"]\r\n+            cascade = [b for b in [primary] + all_backends if b in all_backends]\r\n+            seen = set()\r\n+            ordered_backends = [b for b in cascade if not (b in seen or seen.add(b))]\r\n+\r\n+            MAX_ATTEMPTS = 5\r\n+            RETRY_DELAY_SEC = 2\r\n+            BACKEND_SWITCH_DELAY_SEC = 1\r\n+\r\n+            last_error: str | None = None\r\n+            raw_text: str | None = None\r\n+            used_backend: str | None = None\r\n+\r\n+            for attempt in range(MAX_ATTEMPTS):\r\n+                logger.info(f\"Recognition attempt #{attempt + 1}/{MAX_ATTEMPTS}\")\r\n+                for backend in ordered_backends:\r\n+                    try:\r\n+                        logger.info(\"Trying recognition backend: {}\", backend)\r\n+                        recognizer = self._get_or_create_recognizer(backend)\r\n+                        raw_text = recognizer.transcribe(audio_data)\r\n+                        used_backend = backend\r\n+                        logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n+                        break  # Exit inner loop (backends)\r\n+                    except Exception as exc:\r\n+                        logger.error(\"Recognition error on backend {}: {}\", backend, exc)\r\n+                        last_error = str(exc)\r\n+                        time.sleep(BACKEND_SWITCH_DELAY_SEC)\r\n+                        continue\r\n+                \r\n+                if raw_text is not None:\r\n+                    break  # Exit outer loop (attempts)\r\n+\r\n+                if attempt < MAX_ATTEMPTS - 1:\r\n+                    logger.info(f\"Attempt #{attempt + 1} failed. Retrying in {RETRY_DELAY_SEC} seconds...\")\r\n+                    time.sleep(RETRY_DELAY_SEC)\r\n+\r\n+            if raw_text is None:\r\n+                msg = \"Ошибка соединения. Настройте соединение и попробуйте еще раз.\"\r\n+                self.state_changed.emit(\"error\")\r\n+                self.message_shown.emit(msg, 0)  # 0 timeout to keep it visible\r\n+                self.window.show_retry_button()\r\n+                return\r\n+\r\n+            from loguru import logger as _logger\r\n+\r\n+            try:\r\n+                # 2) regex-очистка (базовый препроцессинг всегда)\r\n+                regex_text = TP._simple_cleanup(raw_text or \"\")\r\n+\r\n+                # 3) LLM-постпроцессинг (если включён в конфиге)\r\n+                processed_text = regex_text\r\n+                try:\r\n+                    processed_text = self.postprocessor.process(raw_text or \"\")\r\n+                except RuntimeError as exc:\r\n+                    _logger.error(\"LLM postprocess error: {}\", exc)\r\n+                    self.message_shown.emit(str(exc), 3000)\r\n+                except Exception as exc:  # noqa: BLE001\r\n+                    _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                    self.message_shown.emit(\"Ошибка LLM-постпроцессинга. См. логи.\", 3000)\r\n+\r\n+                # 4) показать оба варианта в окне (через сигнал)\r\n+                self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n+\r\n+                # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+                self.clipboard.copy(processed_text or \"\")\r\n+\r\n+                # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n+                self.clipboard.paste()\r\n+\r\n+                # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+                try:\r\n+                    if getattr(sys, \"frozen\", False):\r\n+                        base_dir = Path(sys.executable).resolve().parent\r\n+                    else:\r\n+                        base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+                    log_dir = base_dir / \"logs\"\r\n+                    log_dir.mkdir(parents=True, exist_ok=True)\r\n+                    transcript_path = log_dir / \"transcripts.log\"\r\n+\r\n+                    max_size_bytes = 3 * 1024 * 1024\r\n+                    if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n+                        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n+                        rotated = log_dir / f\"transcripts_{ts}.log\"\r\n+                        transcript_path.rename(rotated)\r\n+\r\n+                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\r\n+                    backend_str = used_backend or (self.settings.recognition.backend or \"unknown\")\r\n+\r\n+                    with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n+                        f.write(\r\n+                            f\"[{timestamp}] backend={backend_str} \"\r\n+                            f\"duration={audio_duration_sec:.3f}s\\n\"\r\n+                            f\"RAW: {(raw_text or '').strip()}\\n\"\r\n+                            f\"PROCESSED: {(processed_text or '').strip()}\\n\"\r\n+                            \"----------------------------------------\\n\"\r\n+                        )\r\n+                except Exception as exc:  # noqa: BLE001\r\n+                    _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n+\r\n+                self.state_changed.emit(\"ready\")\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n+                self.state_changed.emit(\"error\")\r\n+                self.message_shown.emit(\"Неизвестная ошибка постобработки. См. логи.\", 3000)\r\n+        finally:\r\n+            self._processing_lock.release()\r\n+\r\n+    # -------------------------------------------------------------- Debug\r\n+\r\n+    def toggle_debug_mode(self) -> None:\r\n+        # Placeholder: will reconfigure logging level later\r\n+        self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n+\r\n+    # ----------------------------------------------------------- Settings / config helpers\r\n+\r\n+    def _load_or_init_settings(self) -> AppSettings:\r\n+        \"\"\"\r\n+        Загрузка настроек с учётом портативного режима.\r\n+\r\n+        Логика:\r\n+        - Ищем config.yaml в self.base_dir (рядом с exe или в корне проекта).\r\n+        - Если файла нет — создаём минимальный config.yaml с backend=local.\r\n+        - Затем вызываем AppSettings.load_default(), который уже умеет\r\n+          подмешивать config.local.yaml поверх config.yaml.\r\n+        \"\"\"\r\n+        config_path = self.base_dir / \"config.yaml\"\r\n+\r\n+        if not config_path.exists():\r\n+            # Минимальный конфиг по умолчанию: локальный backend, безопасные значения.\r\n+            default_config = {\r\n+                \"app\": {\r\n+                    \"name\": \"VoiceCapture\",\r\n+                    \"version\": \"0.1.0\",\r\n+                },\r\n+                \"hotkeys\": {\r\n+                    \"record\": \"ctrl+win\",\r\n+                    \"record_idea\": \"ctrl+win+alt\",\r\n+                    \"cancel\": \"esc\",\r\n+                    \"toggle_window\": \"ctrl+alt+s\",\r\n+                    \"toggle_debug\": \"ctrl+alt+d\",\r\n+                },\r\n+                \"audio\": {\r\n+                    \"sample_rate\": 16000,\r\n+                    \"channels\": 1,\r\n+                    \"max_duration\": 120,\r\n+                },\r\n+                \"recognition\": {\r\n+                    \"backend\": \"local\",\r\n+                    \"local\": {\r\n+                        \"model\": \"large-v3\",\r\n+                        \"device\": \"cuda\",\r\n+                        \"compute_type\": \"float16\",\r\n+                        \"language\": \"ru\",\r\n+                        \"beam_size\": 5,\r\n+                        \"temperature\": 0.0,\r\n+                        \"hf_token\": \"\",\r\n+                    },\r\n+                    \"openai\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-1\",\r\n+                        \"model_process\": \"gpt-4o-mini\",\r\n+                        \"language\": \"ru\",\r\n+                        # base_url намеренно оставляем пустым, чтобы пользователь\r\n+                        # задал его в настройках (OpenAI Base URL).\r\n+                        \"base_url\": \"\",\r\n+                    },\r\n+                    \"groq\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-large-v3\",\r\n+                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n+                        \"language\": \"ru\",\r\n+                    },\r\n+                },\r\n+                # Блок postprocess больше не хранит ключи / base_url.\r\n+                # Здесь только включение, режим и \"отображательные\" модели.\r\n+                \"postprocess\": {\r\n+                    \"enabled\": True,\r\n+                    \"mode\": \"llm\",\r\n+                    \"llm_backend\": \"groq\",\r\n+                    \"groq\": {\r\n+                        \"model\": \"moonshotai/kimi-k2-instruct\",\r\n+                    },\r\n+                    \"openai\": {\r\n+                        \"model\": \"gpt-5.1\",\r\n+                    },\r\n+                },\r\n+                \"ui\": {\r\n+                    # Старые поля width/height/compact_mode больше не используются,\r\n+                    # но при первой генерации конфига запишем их для обратной совместимости.\r\n+                    \"width\": 320,\r\n+                    \"height\": 200,\r\n+                    \"opacity\": 0.9,\r\n+                    \"compact_mode\": False,\r\n+                },\r\n+                \"logging\": {\r\n+                    \"level\": \"INFO\",\r\n+                    \"log_dir\": \"logs\",\r\n+                },\r\n+            }\r\n+\r\n+            try:\r\n+                import yaml\r\n+\r\n+                with config_path.open(\"w\", encoding=\"utf-8\") as f:\r\n+                    yaml.safe_dump(default_config, f, allow_unicode=True, sort_keys=False)\r\n+            except Exception:\r\n+                # Если по какой-то причине не удалось записать файл — продолжаем\r\n+                # с дефолтами из dataclass'ов AppSettings.\r\n+                pass\r\n+\r\n+        # Теперь загружаем настройки стандартным способом:\r\n+        settings = AppSettings.load_default()\r\n+\r\n+        # Гарантируем, что backend задан\r\n+        if not getattr(settings.recognition, \"backend\", None):\r\n+            settings.recognition.backend = \"local\"\r\n+\r\n+        return settings\r\n+\r\n+    # -------------------------------------------------------------- Lifecycle\r\n+\r\n+    def quit(self) -> None:\r\n+        self.hotkeys.stop()\r\n+        self.qt_app.quit()\r\n+\r\n+    def run(self) -> None:\r\n+        self.hotkeys.start()\r\n+        self.show_window()\r\n+        sys.exit(self.qt_app.exec())\r\n+\r\n+\r\n+def main() -> None:\r\n+    app = App()\r\n+    app.run()\r\n+\r\n+\r\n+if __name__ == \"__main__\":\r\n+    main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764806849563,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,8 +22,9 @@\n     # Сигналы для безопасного обновления UI из других потоков\r\n     state_changed = pyqtSignal(str)\r\n     message_shown = pyqtSignal(str, int)\r\n     text_updated = pyqtSignal(str, str)\r\n+    idea_added = pyqtSignal(str)\r\n \r\n     \"\"\"\r\n     Main application class: wires UI, hotkeys, audio recorder, recognizer and clipboard.\r\n \r\n@@ -101,19 +102,23 @@\n             )\r\n \r\n         # State\r\n         self._is_recording: bool = False\r\n+        self._is_idea_recording: bool = False  # New flag for idea mode\r\n         self._last_audio_data: Optional[any] = None\r\n         self._processing_lock = threading.Lock()\r\n \r\n         # Hotkeys\r\n         self.hotkeys = HotKeyManager(\r\n             record_hotkey=self.settings.hotkeys.record,\r\n+            record_idea_hotkey=self.settings.hotkeys.record_idea,\r\n             cancel_hotkey=self.settings.hotkeys.cancel,\r\n             toggle_window_hotkey=self.settings.hotkeys.toggle_window,\r\n             toggle_debug_hotkey=self.settings.hotkeys.toggle_debug,\r\n             on_record_press=self.start_recording,\r\n             on_record_release=self.stop_recording,\r\n+            on_record_idea_press=self.start_idea_recording,\r\n+            on_record_idea_release=self.stop_idea_recording,\r\n             on_cancel=self.cancel_recording,\r\n             on_toggle_window=self.toggle_window_visibility,\r\n             on_toggle_debug=self.toggle_debug_mode,\r\n         )\r\n@@ -130,8 +135,9 @@\n         # Подключаем сигналы к слотам окна\r\n         self.state_changed.connect(self.window.set_state)\r\n         self.message_shown.connect(self.window.show_message)\r\n         self.text_updated.connect(self._on_text_updated)\r\n+        self.idea_added.connect(self.window.add_idea)\r\n \r\n     # --------------------------------------------------------------------- UI\r\n \r\n     def _on_text_updated(self, raw_text: str, processed_text: str) -> None:\r\n@@ -241,9 +247,9 @@\n             logger.warning(\"Retry requested, but no audio data is available.\")\r\n             self.state_changed.emit(\"idle\")\r\n \r\n     def start_recording(self) -> None:\r\n-        if self._is_recording:\r\n+        if self._is_recording or self._is_idea_recording:\r\n             return\r\n         self._is_recording = True\r\n         # При начале новой записи сбрасываем старые данные и убираем кнопку \"повторить\"\r\n         self._last_audio_data = None\r\n@@ -264,15 +270,41 @@\n             return\r\n         self._is_recording = False\r\n         self.audio_recorder.stop()\r\n \r\n-    def cancel_recording(self) -> None:\r\n-        if not self._is_recording:\r\n+    def start_idea_recording(self) -> None:\r\n+        \"\"\"Start recording for the Idea List.\"\"\"\r\n+        if self._is_recording or self._is_idea_recording:\r\n             return\r\n-        self._is_recording = False\r\n-        self.audio_recorder.cancel()\r\n-        self.window.set_state(\"idle\")\r\n+        self._is_idea_recording = True\r\n+        self._last_audio_data = None\r\n+        self.window.hide_retry_button()\r\n+        self.window.set_state(\"recording\") # Reuse recording state for UI feedback\r\n \r\n+        def on_finished(audio_data):\r\n+            # Pass is_idea=True to process_audio\r\n+            thread = threading.Thread(target=self._process_audio, args=(audio_data, True))\r\n+            thread.start()\r\n+\r\n+        self.audio_recorder.start(on_finished=on_finished)\r\n+\r\n+    def stop_idea_recording(self) -> None:\r\n+        \"\"\"Stop recording for the Idea List.\"\"\"\r\n+        if not self._is_idea_recording:\r\n+            return\r\n+        self._is_idea_recording = False\r\n+        self.audio_recorder.stop()\r\n+\r\n+    def cancel_recording(self) -> None:\r\n+        if self._is_recording:\r\n+            self._is_recording = False\r\n+            self.audio_recorder.cancel()\r\n+            self.window.set_state(\"idle\")\r\n+        elif self._is_idea_recording:\r\n+            self._is_idea_recording = False\r\n+            self.audio_recorder.cancel()\r\n+            self.window.set_state(\"idle\")\r\n+\r\n     # ----------------------------------------------------------- Processing\r\n \r\n     def _get_or_create_recognizer(self, backend: str):\r\n         from dataclasses import replace  # локальный импорт, чтобы избежать циклов\r\n@@ -295,11 +327,12 @@\n         return recognizer\r\n     \r\n     # ----------------------------------------------------------- Processing\r\n     \r\n-    def _process_audio(self, audio_data) -> None:\r\n+    def _process_audio(self, audio_data, is_idea: bool = False) -> None:\r\n         \"\"\"\r\n         Синхронная обработка аудио с каскадом backend'ов и ретраями.\r\n+        :param is_idea: Если True, результат добавляется в список идей, а не в буфер обмена.\r\n         \"\"\"\r\n         from loguru import logger\r\n         from pathlib import Path\r\n         from datetime import datetime\r\n@@ -386,16 +419,24 @@\n                     _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n                     self.message_shown.emit(\"Ошибка LLM-постпроцессинга. См. логи.\", 3000)\r\n \r\n                 # 4) показать оба варианта в окне (через сигнал)\r\n-                self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n+                if not is_idea:\r\n+                    self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n+                    \r\n+                    # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+                    self.clipboard.copy(processed_text or \"\")\r\n \r\n-                # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n-                self.clipboard.copy(processed_text or \"\")\r\n+                    # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n+                    self.clipboard.paste()\r\n+                else:\r\n+                    # Если это идея - добавляем в список идей\r\n+                    # Нам нужен новый сигнал для добавления идеи\r\n+                    # Пока используем text_updated как заглушку, но лучше добавить сигнал idea_added\r\n+                    # Но так как мы в потоке, нам нужно эмитить сигнал.\r\n+                    # Добавим сигнал idea_added в класс App.\r\n+                    self.idea_added.emit(processed_text or \"\")\r\n \r\n-                # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n-                self.clipboard.paste()\r\n-\r\n                 # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n                 try:\r\n                     if getattr(sys, \"frozen\", False):\r\n                         base_dir = Path(sys.executable).resolve().parent\r\n"
                },
                {
                    "date": 1764807042753,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,632 @@\n+import sys\r\n+import time\r\n+import threading\r\n+from pathlib import Path\r\n+from typing import Optional\r\n+\r\n+from PyQt6.QtCore import QObject, pyqtSignal\r\n+from PyQt6.QtWidgets import QApplication\r\n+\r\n+from config.settings import AppSettings\r\n+from ui.floating_window import FloatingWindow\r\n+from ui.system_tray import SystemTrayIcon\r\n+from hotkey.hotkey_manager import HotKeyManager\r\n+from audio.recorder import AudioRecorder\r\n+from clipboard.clipboard_manager import ClipboardManager\r\n+from recognition import create_recognizer\r\n+from recognition.postprocessor import TextPostprocessor\r\n+from utils.logger import setup_logging\r\n+\r\n+\r\n+class App(QObject):\r\n+    # Сигналы для безопасного обновления UI из других потоков\r\n+    state_changed = pyqtSignal(str)\r\n+    message_shown = pyqtSignal(str, int)\r\n+    text_updated = pyqtSignal(str, str)\r\n+    idea_added = pyqtSignal(str)\r\n+\r\n+    \"\"\"\r\n+    Main application class: wires UI, hotkeys, audio recorder, recognizer and clipboard.\r\n+\r\n+    MVP workflow:\r\n+        global hotkey (record) down   -> start_recording()\r\n+        global hotkey (record) up     -> stop_recording()\r\n+        audio -> recognizer (Groq/GigaAM) -> postprocess -> clipboard.copy + paste\r\n+    \"\"\"\r\n+\r\n+    def __init__(self) -> None:\r\n+        super().__init__()\r\n+        self.qt_app = QApplication(sys.argv)\r\n+\r\n+        # Определяем базовую директорию приложения:\r\n+        # - в dev-режиме: корень проекта (родитель src)\r\n+        # - в собранном .exe: папка, где лежит exe\r\n+        if getattr(sys, \"frozen\", False):\r\n+            # PyInstaller / frozen\r\n+            self.base_dir = Path(sys.executable).resolve().parent\r\n+        else:\r\n+            # Обычный запуск из исходников\r\n+            self.base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+        # Load settings and logging (с учётом base_dir и config.local.yaml)\r\n+        self.settings = self._load_or_init_settings()\r\n+        setup_logging(self.settings.logging)\r\n+        \r\n+        # Core components\r\n+        self.window = FloatingWindow(self.settings.ui)\r\n+        self.tray = SystemTrayIcon(self.window, self.settings.app)\r\n+        self.clipboard = ClipboardManager()\r\n+        self.audio_recorder = AudioRecorder(self.settings.audio)\r\n+        # Основной распознаватель для текущего backend'а\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        # Кэш распознавателей по backend'ам, чтобы не пересоздавать GigaAM на каждое распознавание\r\n+        self._recognizers = {}\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n+\r\n+        # Постпроцессинг текста.\r\n+        # ВАЖНО: сразу прокидываем в postprocess.* тот же ключ, model_process и base_url,\r\n+        # что и в recognition.*, чтобы LLM работал уже при первом запуске.\r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            # один ключ Groq: берём из recognition.groq.api_key\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            # модель LLM: из recognition.groq.model_process\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            # ключ для LLM всегда берём из поля OpenAI API key (recognition.openai.api_key)\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            # модель LLM\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n+        # Первое сообщение: если нет ключа для текущего backend'а — подсказка пользователю\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        missing_key = False\r\n+        if backend == \"groq\" and not (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            missing_key = True\r\n+        elif backend == \"openai\" and not (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            missing_key = True\r\n+\r\n+        if missing_key:\r\n+            self.window.result_label.setText(\r\n+                \"Добавьте API‑ключ в настройках (⚙️) перед использованием распознавания.\"\r\n+            )\r\n+\r\n+        # State\r\n+        self._is_recording: bool = False\r\n+        self._is_idea_recording: bool = False  # New flag for idea mode\r\n+        self._last_audio_data: Optional[any] = None\r\n+        self._processing_lock = threading.Lock()\r\n+\r\n+        # Hotkeys\r\n+        self.hotkeys = HotKeyManager(\r\n+            record_hotkey=self.settings.hotkeys.record,\r\n+            record_idea_hotkey=self.settings.hotkeys.record_idea,\r\n+            cancel_hotkey=self.settings.hotkeys.cancel,\r\n+            toggle_window_hotkey=self.settings.hotkeys.toggle_window,\r\n+            toggle_debug_hotkey=self.settings.hotkeys.toggle_debug,\r\n+            on_record_press=self.start_recording,\r\n+            on_record_release=self.stop_recording,\r\n+            on_record_idea_press=self.start_idea_recording,\r\n+            on_record_idea_release=self.stop_idea_recording,\r\n+            on_cancel=self.cancel_recording,\r\n+            on_toggle_window=self.toggle_window_visibility,\r\n+            on_toggle_debug=self.toggle_debug_mode,\r\n+        )\r\n+\r\n+        # Wire UI signals\r\n+        self.window.settings_requested.connect(self.open_settings_dialog)\r\n+        self.window.exit_requested.connect(self.quit)\r\n+        self.window.retry_requested.connect(self._retry_processing)\r\n+        self.tray.show_window_requested.connect(self.show_window)\r\n+        self.tray.settings_requested.connect(self.open_settings_dialog)\r\n+        self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n+        self.tray.exit_requested.connect(self.quit)\r\n+\r\n+        # Подключаем сигналы к слотам окна\r\n+        self.state_changed.connect(self.window.set_state)\r\n+        self.message_shown.connect(self.window.show_message)\r\n+        self.text_updated.connect(self._on_text_updated)\r\n+        self.idea_added.connect(self.window.add_idea)\r\n+\r\n+    # --------------------------------------------------------------------- UI\r\n+\r\n+    def _on_text_updated(self, raw_text: str, processed_text: str) -> None:\r\n+        \"\"\"Слот для обновления текстовых полей в окне.\"\"\"\r\n+        if hasattr(self.window, \"set_raw_text\"):\r\n+            self.window.set_raw_text(raw_text or \"\")\r\n+        else:\r\n+            # fallback для старых версий окна\r\n+            self.window.result_label.setText(processed_text or \"\")\r\n+\r\n+        if hasattr(self.window, \"set_processed_text\"):\r\n+            self.window.set_processed_text(processed_text or \"\")\r\n+\r\n+    def show_window(self) -> None:\r\n+        self.window.show()\r\n+        self.window.raise_()\r\n+        self.window.activateWindow()\r\n+\r\n+    def toggle_window_visibility(self) -> None:\r\n+        \"\"\"\r\n+        Горячая клавиша \"Показать/скрыть окно\".\r\n+\r\n+        Для твоего сценария окно должно быть ВСЕГДА видно, поэтому\r\n+        мы больше не будем его прятать, а только:\r\n+        - если оно свернуто в компактный режим — разворачивать,\r\n+        - если оно где-то \"потерялось\" — показывать и поднимать наверх.\r\n+        \"\"\"\r\n+        # просто гарантируем, что окно показано и на переднем плане\r\n+        self.show_window()\r\n+\r\n+    def open_settings_dialog(self) -> None:\r\n+        \"\"\"\r\n+        Открыть диалог настроек (SettingsDialog) и применить изменения.\r\n+        \"\"\"\r\n+        from ui.settings_dialog import SettingsDialog  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        # показать основное окно, чтобы диалог был поверх\r\n+        self.show_window()\r\n+\r\n+        dlg = SettingsDialog(self.settings, parent=self.window)\r\n+        if dlg.exec() != dlg.DialogCode.Accepted:\r\n+            return\r\n+\r\n+        new_settings = dlg.get_result()\r\n+        if new_settings is None:\r\n+            return\r\n+\r\n+        # обновляем настройки в памяти\r\n+        self.settings = new_settings\r\n+        \r\n+        # сохраняем в config.yaml\r\n+        AppSettings.save_default(self.settings)\r\n+        \r\n+        # пересоздаём recognizer и postprocessor с учётом новых настроек\r\n+        # и сбрасываем кэш распознавателей по backend'ам.\r\n+        self._recognizers = {}\r\n+        self.recognizer = create_recognizer(self.settings.recognition)\r\n+        primary_backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        self._recognizers[primary_backend] = self.recognizer\r\n+        \r\n+        post_cfg = self.settings.postprocess\r\n+        rec_cfg = self.settings.recognition\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"groq\":\r\n+            setattr(post_cfg.groq, \"api_key\", rec_cfg.groq.api_key)\r\n+            if not getattr(post_cfg.groq, \"model_process\", \"\"):\r\n+                setattr(post_cfg.groq, \"model_process\", rec_cfg.groq.model_process)\r\n+\r\n+        if (post_cfg.llm_backend or \"\").lower() == \"openai\":\r\n+            setattr(post_cfg.openai, \"api_key\", rec_cfg.openai.api_key)\r\n+            if not getattr(post_cfg.openai, \"model_process\", \"\"):\r\n+                setattr(post_cfg.openai, \"model_process\", rec_cfg.openai.model_process)\r\n+            # базовый URL LLM = тот же, что и у ASR\r\n+            setattr(post_cfg.openai, \"base_url\", rec_cfg.openai.base_url)\r\n+\r\n+        self.postprocessor = TextPostprocessor(post_cfg)\r\n+\r\n+        # если теперь ключи заданы — убрать предупреждающую надпись\r\n+        backend = (self.settings.recognition.backend or \"groq\").lower()\r\n+        has_key = False\r\n+        if backend == \"groq\" and (self.settings.recognition.groq.api_key or \"\").strip():\r\n+            has_key = True\r\n+        elif backend == \"openai\" and (self.settings.recognition.openai.api_key or \"\").strip():\r\n+            has_key = True\r\n+\r\n+        if has_key:\r\n+            if hasattr(self.window, \"set_raw_text\"):\r\n+                self.window.set_raw_text(\"\")\r\n+            if hasattr(self.window, \"set_processed_text\"):\r\n+                self.window.set_processed_text(\"\")\r\n+            self.window.result_label.setText(\"\")\r\n+\r\n+        self.window.show_message(\"Настройки сохранены.\", timeout_ms=1500)\r\n+\r\n+    # ----------------------------------------------------------------- Hotkeys\r\n+\r\n+    def _retry_processing(self) -> None:\r\n+        \"\"\"Запускает повторную обработку последнего записанного аудио.\"\"\"\r\n+        from loguru import logger\r\n+\r\n+        if self._last_audio_data:\r\n+            logger.info(\"Retrying processing for the last audio data.\")\r\n+            # Запускаем в новом потоке, чтобы не блокировать UI\r\n+            thread = threading.Thread(target=self._process_audio, args=(self._last_audio_data,))\r\n+            thread.start()\r\n+        else:\r\n+            logger.warning(\"Retry requested, but no audio data is available.\")\r\n+            self.state_changed.emit(\"idle\")\r\n+\r\n+    def start_recording(self) -> None:\r\n+        if self._is_recording or self._is_idea_recording:\r\n+            return\r\n+        self._is_recording = True\r\n+        # При начале новой записи сбрасываем старые данные и убираем кнопку \"повторить\"\r\n+        self._last_audio_data = None\r\n+        self.window.hide_retry_button()\r\n+        self.window.set_state(\"recording\")\r\n+\r\n+        def on_finished(audio_data):\r\n+            # Этот колбэк вызывается из потока рекордера.\r\n+            # Запускаем обработку в новом потоке, чтобы не блокировать поток рекордера\r\n+            # и чтобы основной цикл событий Qt продолжал работать.\r\n+            thread = threading.Thread(target=self._process_audio, args=(audio_data,))\r\n+            thread.start()\r\n+\r\n+        self.audio_recorder.start(on_finished=on_finished)\r\n+\r\n+    def stop_recording(self) -> None:\r\n+        if not self._is_recording:\r\n+            return\r\n+        self._is_recording = False\r\n+        self.audio_recorder.stop()\r\n+\r\n+    def start_idea_recording(self) -> None:\r\n+        \"\"\"Start recording for the Idea List.\"\"\"\r\n+        if self._is_recording or self._is_idea_recording:\r\n+            return\r\n+        self._is_idea_recording = True\r\n+        self._last_audio_data = None\r\n+        self.window.hide_retry_button()\r\n+        self.window.set_state(\"recording\") # Reuse recording state for UI feedback\r\n+\r\n+        def on_finished(audio_data):\r\n+            # Pass is_idea=True to process_audio\r\n+            thread = threading.Thread(target=self._process_audio, args=(audio_data, True))\r\n+            thread.start()\r\n+\r\n+        self.audio_recorder.start(on_finished=on_finished)\r\n+\r\n+    def stop_idea_recording(self) -> None:\r\n+        \"\"\"Stop recording for the Idea List.\"\"\"\r\n+        if not self._is_idea_recording:\r\n+            return\r\n+        self._is_idea_recording = False\r\n+        self.audio_recorder.stop()\r\n+\r\n+    def cancel_recording(self) -> None:\r\n+        if self._is_recording:\r\n+            self._is_recording = False\r\n+            self.audio_recorder.cancel()\r\n+            self.window.set_state(\"idle\")\r\n+        elif self._is_idea_recording:\r\n+            self._is_idea_recording = False\r\n+            self.audio_recorder.cancel()\r\n+            self.window.set_state(\"idle\")\r\n+\r\n+    # ----------------------------------------------------------- Processing\r\n+\r\n+    def _get_or_create_recognizer(self, backend: str):\r\n+        from dataclasses import replace  # локальный импорт, чтобы избежать циклов\r\n+\r\n+        backend = (backend or \"groq\").lower()\r\n+        cache = getattr(self, \"_recognizers\", None)\r\n+        if cache is None:\r\n+            cache = {}\r\n+            self._recognizers = cache\r\n+            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+            cache[primary] = self.recognizer\r\n+\r\n+        if backend in cache:\r\n+            return cache[backend]\r\n+\r\n+        rec_cfg = self.settings.recognition\r\n+        tmp_cfg = replace(rec_cfg, backend=backend)\r\n+        recognizer = create_recognizer(tmp_cfg)\r\n+        cache[backend] = recognizer\r\n+        return recognizer\r\n+    \r\n+    # ----------------------------------------------------------- Processing\r\n+    \r\n+    def _process_audio(self, audio_data, is_idea: bool = False) -> None:\r\n+        \"\"\"\r\n+        Синхронная обработка аудио с каскадом backend'ов и ретраями.\r\n+        :param is_idea: Если True, результат добавляется в список идей, а не в буфер обмена.\r\n+        \"\"\"\r\n+        from loguru import logger\r\n+        from pathlib import Path\r\n+        from datetime import datetime\r\n+        from recognition.postprocessor import TextPostprocessor as TP\r\n+\r\n+        if not self._processing_lock.acquire(blocking=False):\r\n+            logger.warning(\"Processing is already in progress. Skipping new request.\")\r\n+            return\r\n+\r\n+        try:\r\n+            self._last_audio_data = audio_data\r\n+            self.state_changed.emit(\"processing\")\r\n+\r\n+            # ------------------------ вычисляем длительность аудио -----------------\r\n+            try:\r\n+                import numpy as _np\r\n+                samples = audio_data.samples\r\n+                sample_rate = getattr(audio_data, \"sample_rate\", 16000)\r\n+                total_samples = samples.shape[0]\r\n+                audio_duration_sec = float(total_samples) / float(sample_rate)\r\n+            except Exception as exc:\r\n+                logger.exception(\"Failed to compute audio duration: {}\", exc)\r\n+                audio_duration_sec = -1.0\r\n+\r\n+            # ------------------------ каскад backend'ов с ретраями ----------------\r\n+            primary = (self.settings.recognition.backend or \"groq\").lower()\r\n+            all_backends = [\"groq\", \"openai\", \"local\"]\r\n+            cascade = [b for b in [primary] + all_backends if b in all_backends]\r\n+            seen = set()\r\n+            ordered_backends = [b for b in cascade if not (b in seen or seen.add(b))]\r\n+\r\n+            MAX_ATTEMPTS = 5\r\n+            RETRY_DELAY_SEC = 2\r\n+            BACKEND_SWITCH_DELAY_SEC = 1\r\n+\r\n+            last_error: str | None = None\r\n+            raw_text: str | None = None\r\n+            used_backend: str | None = None\r\n+\r\n+            for attempt in range(MAX_ATTEMPTS):\r\n+                logger.info(f\"Recognition attempt #{attempt + 1}/{MAX_ATTEMPTS}\")\r\n+                for backend in ordered_backends:\r\n+                    try:\r\n+                        logger.info(\"Trying recognition backend: {}\", backend)\r\n+                        recognizer = self._get_or_create_recognizer(backend)\r\n+                        raw_text = recognizer.transcribe(audio_data)\r\n+                        used_backend = backend\r\n+                        logger.info(\"Recognition succeeded with backend: {}\", backend)\r\n+                        break  # Exit inner loop (backends)\r\n+                    except Exception as exc:\r\n+                        logger.error(\"Recognition error on backend {}: {}\", backend, exc)\r\n+                        last_error = str(exc)\r\n+                        time.sleep(BACKEND_SWITCH_DELAY_SEC)\r\n+                        continue\r\n+                \r\n+                if raw_text is not None:\r\n+                    break  # Exit outer loop (attempts)\r\n+\r\n+                if attempt < MAX_ATTEMPTS - 1:\r\n+                    logger.info(f\"Attempt #{attempt + 1} failed. Retrying in {RETRY_DELAY_SEC} seconds...\")\r\n+                    time.sleep(RETRY_DELAY_SEC)\r\n+\r\n+            if raw_text is None:\r\n+                msg = \"Ошибка соединения. Настройте соединение и попробуйте еще раз.\"\r\n+                self.state_changed.emit(\"error\")\r\n+                self.message_shown.emit(msg, 0)  # 0 timeout to keep it visible\r\n+                self.window.show_retry_button()\r\n+                return\r\n+\r\n+            from loguru import logger as _logger\r\n+\r\n+            try:\r\n+                # 2) regex-очистка (базовый препроцессинг всегда)\r\n+                regex_text = TP._simple_cleanup(raw_text or \"\")\r\n+\r\n+                # 3) LLM-постпроцессинг (если включён в конфиге)\r\n+                processed_text = regex_text\r\n+                try:\r\n+                    processed_text = self.postprocessor.process(raw_text or \"\")\r\n+                except RuntimeError as exc:\r\n+                    _logger.error(\"LLM postprocess error: {}\", exc)\r\n+                    self.message_shown.emit(str(exc), 3000)\r\n+                except Exception as exc:  # noqa: BLE001\r\n+                    _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n+                    self.message_shown.emit(\"Ошибка LLM-постпроцессинга. См. логи.\", 3000)\r\n+\r\n+                # 4) показать оба варианта в окне (через сигнал)\r\n+                if not is_idea:\r\n+                    self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n+                    \r\n+                    # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n+                    self.clipboard.copy(processed_text or \"\")\r\n+\r\n+                    # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n+                    self.clipboard.paste()\r\n+                else:\r\n+                    # Если это идея - добавляем в список идей и логируем\r\n+                    self.idea_added.emit(processed_text or \"\")\r\n+                    self._log_idea(processed_text or \"\")\r\n+\r\n+                # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+                try:\r\n+                    if getattr(sys, \"frozen\", False):\r\n+                        base_dir = Path(sys.executable).resolve().parent\r\n+                    else:\r\n+                        base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+                    log_dir = base_dir / \"logs\"\r\n+                    log_dir.mkdir(parents=True, exist_ok=True)\r\n+                    transcript_path = log_dir / \"transcripts.log\"\r\n+\r\n+                    max_size_bytes = 3 * 1024 * 1024\r\n+                    if transcript_path.exists() and transcript_path.stat().st_size >= max_size_bytes:\r\n+                        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n+                        rotated = log_dir / f\"transcripts_{ts}.log\"\r\n+                        transcript_path.rename(rotated)\r\n+\r\n+                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\r\n+                    backend_str = used_backend or (self.settings.recognition.backend or \"unknown\")\r\n+\r\n+                    with transcript_path.open(\"a\", encoding=\"utf-8\") as f:\r\n+                        f.write(\r\n+                            f\"[{timestamp}] backend={backend_str} \"\r\n+                            f\"duration={audio_duration_sec:.3f}s\\n\"\r\n+                            f\"RAW: {(raw_text or '').strip()}\\n\"\r\n+                            f\"PROCESSED: {(processed_text or '').strip()}\\n\"\r\n+                            \"----------------------------------------\\n\"\r\n+                        )\r\n+                except Exception as exc:  # noqa: BLE001\r\n+                    _logger.exception(\"Failed to append transcript log: {}\", exc)\r\n+\r\n+                self.state_changed.emit(\"ready\")\r\n+            except Exception as exc:  # noqa: BLE001\r\n+                _logger.exception(\"Unexpected error during post-processing: {}\", exc)\r\n+                self.state_changed.emit(\"error\")\r\n+                self.message_shown.emit(\"Неизвестная ошибка постобработки. См. логи.\", 3000)\r\n+        finally:\r\n+            self._processing_lock.release()\r\n+\r\n+    def _log_idea(self, text: str):\r\n+        \"\"\"Appends an idea to the ideas.log file.\"\"\"\r\n+        from loguru import logger\r\n+        from datetime import datetime\r\n+        \r\n+        if not text.strip():\r\n+            return\r\n+            \r\n+        try:\r\n+            # Use the same base_dir logic as in _process_audio\r\n+            if getattr(sys, \"frozen\", False):\r\n+                base_dir = Path(sys.executable).resolve().parent\r\n+            else:\r\n+                base_dir = Path(__file__).resolve().parents[1]\r\n+\r\n+            log_dir = base_dir / \"logs\"\r\n+            log_dir.mkdir(parents=True, exist_ok=True)\r\n+            idea_log_path = log_dir / \"ideas.log\"\r\n+            \r\n+            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\r\n+            \r\n+            with idea_log_path.open(\"a\", encoding=\"utf-8\") as f:\r\n+                f.write(f\"[{timestamp}] {text.strip()}\\n\")\r\n+                \r\n+        except Exception as exc:\r\n+            logger.exception(\"Failed to append idea to log: {}\", exc)\r\n+\r\n+    # -------------------------------------------------------------- Debug\r\n+\r\n+    def toggle_debug_mode(self) -> None:\r\n+        # Placeholder: will reconfigure logging level later\r\n+        self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n+\r\n+    # ----------------------------------------------------------- Settings / config helpers\r\n+\r\n+    def _load_or_init_settings(self) -> AppSettings:\r\n+        \"\"\"\r\n+        Загрузка настроек с учётом портативного режима.\r\n+\r\n+        Логика:\r\n+        - Ищем config.yaml в self.base_dir (рядом с exe или в корне проекта).\r\n+        - Если файла нет — создаём минимальный config.yaml с backend=local.\r\n+        - Затем вызываем AppSettings.load_default(), который уже умеет\r\n+          подмешивать config.local.yaml поверх config.yaml.\r\n+        \"\"\"\r\n+        config_path = self.base_dir / \"config.yaml\"\r\n+\r\n+        if not config_path.exists():\r\n+            # Минимальный конфиг по умолчанию: локальный backend, безопасные значения.\r\n+            default_config = {\r\n+                \"app\": {\r\n+                    \"name\": \"VoiceCapture\",\r\n+                    \"version\": \"0.1.0\",\r\n+                },\r\n+                \"hotkeys\": {\r\n+                    \"record\": \"ctrl+win\",\r\n+                    \"record_idea\": \"ctrl+win+alt\",\r\n+                    \"cancel\": \"esc\",\r\n+                    \"toggle_window\": \"ctrl+alt+s\",\r\n+                    \"toggle_debug\": \"ctrl+alt+d\",\r\n+                },\r\n+                \"audio\": {\r\n+                    \"sample_rate\": 16000,\r\n+                    \"channels\": 1,\r\n+                    \"max_duration\": 120,\r\n+                },\r\n+                \"recognition\": {\r\n+                    \"backend\": \"local\",\r\n+                    \"local\": {\r\n+                        \"model\": \"large-v3\",\r\n+                        \"device\": \"cuda\",\r\n+                        \"compute_type\": \"float16\",\r\n+                        \"language\": \"ru\",\r\n+                        \"beam_size\": 5,\r\n+                        \"temperature\": 0.0,\r\n+                        \"hf_token\": \"\",\r\n+                    },\r\n+                    \"openai\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-1\",\r\n+                        \"model_process\": \"gpt-4o-mini\",\r\n+                        \"language\": \"ru\",\r\n+                        # base_url намеренно оставляем пустым, чтобы пользователь\r\n+                        # задал его в настройках (OpenAI Base URL).\r\n+                        \"base_url\": \"\",\r\n+                    },\r\n+                    \"groq\": {\r\n+                        \"api_key\": \"\",\r\n+                        \"model\": \"whisper-large-v3\",\r\n+                        \"model_process\": \"moonshotai/kimi-k2-instruct\",\r\n+                        \"language\": \"ru\",\r\n+                    },\r\n+                },\r\n+                # Блок postprocess больше не хранит ключи / base_url.\r\n+                # Здесь только включение, режим и \"отображательные\" модели.\r\n+                \"postprocess\": {\r\n+                    \"enabled\": True,\r\n+                    \"mode\": \"llm\",\r\n+                    \"llm_backend\": \"groq\",\r\n+                    \"groq\": {\r\n+                        \"model\": \"moonshotai/kimi-k2-instruct\",\r\n+                    },\r\n+                    \"openai\": {\r\n+                        \"model\": \"gpt-5.1\",\r\n+                    },\r\n+                },\r\n+                \"ui\": {\r\n+                    # Старые поля width/height/compact_mode больше не используются,\r\n+                    # но при первой генерации конфига запишем их для обратной совместимости.\r\n+                    \"width\": 320,\r\n+                    \"height\": 200,\r\n+                    \"opacity\": 0.9,\r\n+                    \"compact_mode\": False,\r\n+                },\r\n+                \"logging\": {\r\n+                    \"level\": \"INFO\",\r\n+                    \"log_dir\": \"logs\",\r\n+                },\r\n+            }\r\n+\r\n+            try:\r\n+                import yaml\r\n+\r\n+                with config_path.open(\"w\", encoding=\"utf-8\") as f:\r\n+                    yaml.safe_dump(default_config, f, allow_unicode=True, sort_keys=False)\r\n+            except Exception:\r\n+                # Если по какой-то причине не удалось записать файл — продолжаем\r\n+                # с дефолтами из dataclass'ов AppSettings.\r\n+                pass\r\n+\r\n+        # Теперь загружаем настройки стандартным способом:\r\n+        settings = AppSettings.load_default()\r\n+\r\n+        # Гарантируем, что backend задан\r\n+        if not getattr(settings.recognition, \"backend\", None):\r\n+            settings.recognition.backend = \"local\"\r\n+\r\n+        return settings\r\n+\r\n+    # -------------------------------------------------------------- Lifecycle\r\n+\r\n+    def quit(self) -> None:\r\n+        self.hotkeys.stop()\r\n+        self.qt_app.quit()\r\n+\r\n+    def run(self) -> None:\r\n+        self.hotkeys.start()\r\n+        self.show_window()\r\n+        sys.exit(self.qt_app.exec())\r\n+\r\n+\r\n+def main() -> None:\r\n+    app = App()\r\n+    app.run()\r\n+\r\n+\r\n+if __name__ == \"__main__\":\r\n+    main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1764807441042,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,9 +102,9 @@\n             )\r\n \r\n         # State\r\n         self._is_recording: bool = False\r\n-        self._is_idea_recording: bool = False  # New flag for idea mode\r\n+        self._is_idea: bool = False # True, if the current recording is an idea\r\n         self._last_audio_data: Optional[any] = None\r\n         self._processing_lock = threading.Lock()\r\n \r\n         # Hotkeys\r\n@@ -116,9 +116,10 @@\n             toggle_debug_hotkey=self.settings.hotkeys.toggle_debug,\r\n             on_record_press=self.start_recording,\r\n             on_record_release=self.stop_recording,\r\n             on_record_idea_press=self.start_idea_recording,\r\n-            on_record_idea_release=self.stop_idea_recording,\r\n+            on_record_idea_release=self.stop_recording, # Stop is the same for both\r\n+            on_convert_to_idea=self.convert_to_idea,\r\n             on_cancel=self.cancel_recording,\r\n             on_toggle_window=self.toggle_window_visibility,\r\n             on_toggle_debug=self.toggle_debug_mode,\r\n         )\r\n@@ -246,64 +247,48 @@\n         else:\r\n             logger.warning(\"Retry requested, but no audio data is available.\")\r\n             self.state_changed.emit(\"idle\")\r\n \r\n-    def start_recording(self) -> None:\r\n-        if self._is_recording or self._is_idea_recording:\r\n+    def start_recording(self, is_idea: bool = False) -> None:\r\n+        if self._is_recording:\r\n             return\r\n         self._is_recording = True\r\n-        # При начале новой записи сбрасываем старые данные и убираем кнопку \"повторить\"\r\n+        self._is_idea = is_idea\r\n+        \r\n         self._last_audio_data = None\r\n         self.window.hide_retry_button()\r\n         self.window.set_state(\"recording\")\r\n \r\n         def on_finished(audio_data):\r\n-            # Этот колбэк вызывается из потока рекордера.\r\n-            # Запускаем обработку в новом потоке, чтобы не блокировать поток рекордера\r\n-            # и чтобы основной цикл событий Qt продолжал работать.\r\n+            # The final `is_idea` flag is checked inside _process_audio\r\n             thread = threading.Thread(target=self._process_audio, args=(audio_data,))\r\n             thread.start()\r\n \r\n         self.audio_recorder.start(on_finished=on_finished)\r\n \r\n     def stop_recording(self) -> None:\r\n         if not self._is_recording:\r\n             return\r\n-        self._is_recording = False\r\n+        # We don't reset flags here, _process_audio will do it\r\n         self.audio_recorder.stop()\r\n \r\n     def start_idea_recording(self) -> None:\r\n-        \"\"\"Start recording for the Idea List.\"\"\"\r\n-        if self._is_recording or self._is_idea_recording:\r\n-            return\r\n-        self._is_idea_recording = True\r\n-        self._last_audio_data = None\r\n-        self.window.hide_retry_button()\r\n-        self.window.set_state(\"recording\") # Reuse recording state for UI feedback\r\n+        \"\"\"Starts a recording that is immediately flagged as an idea.\"\"\"\r\n+        self.start_recording(is_idea=True)\r\n \r\n-        def on_finished(audio_data):\r\n-            # Pass is_idea=True to process_audio\r\n-            thread = threading.Thread(target=self._process_audio, args=(audio_data, True))\r\n-            thread.start()\r\n+    def convert_to_idea(self) -> None:\r\n+        \"\"\"If a recording is in progress, flag it as an idea.\"\"\"\r\n+        if self._is_recording:\r\n+            self._is_idea = True\r\n+            # Optionally, provide some visual feedback\r\n+            self.message_shown.emit(\"Запись будет добавлена в идеи\", 1000)\r\n \r\n-        self.audio_recorder.start(on_finished=on_finished)\r\n-\r\n-    def stop_idea_recording(self) -> None:\r\n-        \"\"\"Stop recording for the Idea List.\"\"\"\r\n-        if not self._is_idea_recording:\r\n-            return\r\n-        self._is_idea_recording = False\r\n-        self.audio_recorder.stop()\r\n-\r\n     def cancel_recording(self) -> None:\r\n         if self._is_recording:\r\n             self._is_recording = False\r\n+            self._is_idea = False\r\n             self.audio_recorder.cancel()\r\n             self.window.set_state(\"idle\")\r\n-        elif self._is_idea_recording:\r\n-            self._is_idea_recording = False\r\n-            self.audio_recorder.cancel()\r\n-            self.window.set_state(\"idle\")\r\n \r\n     # ----------------------------------------------------------- Processing\r\n \r\n     def _get_or_create_recognizer(self, backend: str):\r\n@@ -327,12 +312,12 @@\n         return recognizer\r\n     \r\n     # ----------------------------------------------------------- Processing\r\n     \r\n-    def _process_audio(self, audio_data, is_idea: bool = False) -> None:\r\n+    def _process_audio(self, audio_data) -> None:\r\n         \"\"\"\r\n-        Синхронная обработка аудио с каскадом backend'ов и ретраями.\r\n-        :param is_idea: Если True, результат добавляется в список идей, а не в буфер обмена.\r\n+        Синхронная обработка аудио.\r\n+        Флаг self._is_idea определяет, нужно ли добавлять результат в список идей.\r\n         \"\"\"\r\n         from loguru import logger\r\n         from pathlib import Path\r\n         from datetime import datetime\r\n@@ -342,8 +327,13 @@\n             logger.warning(\"Processing is already in progress. Skipping new request.\")\r\n             return\r\n \r\n         try:\r\n+            # Reset recording state immediately after starting processing\r\n+            self._is_recording = False\r\n+            is_idea_flag = self._is_idea\r\n+            self._is_idea = False # Reset for the next recording\r\n+\r\n             self._last_audio_data = audio_data\r\n             self.state_changed.emit(\"processing\")\r\n \r\n             # ------------------------ вычисляем длительность аудио -----------------\r\n"
                },
                {
                    "date": 1764807474575,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -409,22 +409,22 @@\n                     _logger.exception(\"Unexpected LLM postprocess error: {}\", exc)\r\n                     self.message_shown.emit(\"Ошибка LLM-постпроцессинга. См. логи.\", 3000)\r\n \r\n                 # 4) показать оба варианта в окне (через сигнал)\r\n-                if not is_idea:\r\n-                    self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n-                    \r\n-                    # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена\r\n-                    self.clipboard.copy(processed_text or \"\")\r\n+                self.text_updated.emit(raw_text or \"\", processed_text or \"\")\r\n \r\n-                    # 6) авто-вставка текста через Ctrl+V (с ретраями внутри ClipboardManager)\r\n-                    self.clipboard.paste()\r\n-                else:\r\n-                    # Если это идея - добавляем в список идей и логируем\r\n+                # 5) положить ОБРАБОТАННЫЙ текст в буфер обмена (ВСЕГДА)\r\n+                self.clipboard.copy(processed_text or \"\")\r\n+\r\n+                # 6) авто-вставка текста через Ctrl+V (ВСЕГДА)\r\n+                self.clipboard.paste()\r\n+\r\n+                # 7) если это была идея, добавить в список идей\r\n+                if is_idea_flag:\r\n                     self.idea_added.emit(processed_text or \"\")\r\n                     self._log_idea(processed_text or \"\")\r\n \r\n-                # 7) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n+                # 8) сохранить распознавание в отдельный текстовый лог с ротацией по ~3 МБ\r\n                 try:\r\n                     if getattr(sys, \"frozen\", False):\r\n                         base_dir = Path(sys.executable).resolve().parent\r\n                     else:\r\n"
                }
            ],
            "date": 1764291847746,
            "name": "Commit-0",
            "content": "import sys\r\nfrom typing import Optional\r\n\r\nfrom PyQt6.QtWidgets import QApplication\r\n\r\nfrom config.settings import AppSettings\r\nfrom ui.floating_window import FloatingWindow\r\nfrom ui.system_tray import SystemTrayIcon\r\nfrom hotkey.hotkey_manager import HotKeyManager\r\nfrom audio.recorder import AudioRecorder\r\nfrom clipboard.clipboard_manager import ClipboardManager\r\nfrom recognition import create_recognizer\r\nfrom recognition.postprocessor import TextPostprocessor\r\nfrom utils.logger import setup_logging\r\n\r\n\r\nclass App:\r\n    \"\"\"\r\n    Main application class: wires UI, hotkeys, audio recorder, recognizer and clipboard.\r\n\r\n    MVP workflow:\r\n        global hotkey (record) down   -> start_recording()\r\n        global hotkey (record) up     -> stop_recording()\r\n        audio -> recognizer (Groq) -> postprocess -> clipboard.copy + paste\r\n    \"\"\"\r\n\r\n    def __init__(self) -> None:\r\n        self.qt_app = QApplication(sys.argv)\r\n\r\n        # Load settings and logging\r\n        self.settings = AppSettings.load_default()\r\n        setup_logging(self.settings.logging)\r\n\r\n        # Core components\r\n        self.window = FloatingWindow(self.settings.ui)\r\n        self.tray = SystemTrayIcon(self.window, self.settings.app)\r\n        self.clipboard = ClipboardManager()\r\n        self.audio_recorder = AudioRecorder(self.settings.audio)\r\n        self.recognizer = create_recognizer(self.settings.recognition)\r\n        self.postprocessor = TextPostprocessor(self.settings.postprocess)\r\n\r\n        # State\r\n        self._is_recording: bool = False\r\n\r\n        # Hotkeys\r\n        self.hotkeys = HotKeyManager(\r\n            record_hotkey=self.settings.hotkeys.record,\r\n            cancel_hotkey=self.settings.hotkeys.cancel,\r\n            toggle_window_hotkey=self.settings.hotkeys.toggle_window,\r\n            toggle_debug_hotkey=self.settings.hotkeys.toggle_debug,\r\n            on_record_press=self.start_recording,\r\n            on_record_release=self.stop_recording,\r\n            on_cancel=self.cancel_recording,\r\n            on_toggle_window=self.toggle_window_visibility,\r\n            on_toggle_debug=self.toggle_debug_mode,\r\n        )\r\n\r\n        # Wire UI signals\r\n        self.window.settings_requested.connect(self.open_settings_dialog)\r\n        self.window.exit_requested.connect(self.quit)\r\n        self.tray.show_window_requested.connect(self.show_window)\r\n        self.tray.settings_requested.connect(self.open_settings_dialog)\r\n        self.tray.toggle_debug_requested.connect(self.toggle_debug_mode)\r\n        self.tray.exit_requested.connect(self.quit)\r\n\r\n    # --------------------------------------------------------------------- UI\r\n\r\n    def show_window(self) -> None:\r\n        self.window.show()\r\n        self.window.raise_()\r\n        self.window.activateWindow()\r\n\r\n    def toggle_window_visibility(self) -> None:\r\n        if self.window.isVisible():\r\n            self.window.hide()\r\n        else:\r\n            self.show_window()\r\n\r\n    def open_settings_dialog(self) -> None:\r\n        # Placeholder: real implementation will open SettingsDialog\r\n        self.window.show_message(\"Settings dialog is not implemented yet (MVP skeleton).\")\r\n\r\n    # ----------------------------------------------------------------- Hotkeys\r\n\r\n    def start_recording(self) -> None:\r\n        if self._is_recording:\r\n            return\r\n        self._is_recording = True\r\n        self.window.set_state(\"recording\")\r\n\r\n        def on_finished(audio_data):\r\n            # Этот колбэк вызывается из потока рекордера.\r\n            # Для MVP просто передаём данные в обработку синхронно.\r\n            self._process_audio(audio_data)\r\n\r\n        self.audio_recorder.start(on_finished=on_finished)\r\n\r\n    def stop_recording(self) -> None:\r\n        if not self._is_recording:\r\n            return\r\n        self._is_recording = False\r\n        self.audio_recorder.stop()\r\n\r\n    def cancel_recording(self) -> None:\r\n        if not self._is_recording:\r\n            return\r\n        self._is_recording = False\r\n        self.audio_recorder.cancel()\r\n        self.window.set_state(\"idle\")\r\n\r\n    # ----------------------------------------------------------- Processing\r\n\r\n    def _process_audio(self, audio_data) -> None:\r\n        \"\"\"Synchronous processing for MVP; later can be moved to worker thread.\"\"\"\r\n        try:\r\n            self.window.set_state(\"processing\")\r\n            text = self.recognizer.transcribe(audio_data)\r\n            text = self.postprocessor.process(text)\r\n            self.clipboard.copy(text)\r\n            self.clipboard.paste()\r\n            self.window.set_state(\"ready\")\r\n        except Exception as exc:  # noqa: BLE001\r\n            from loguru import logger\r\n\r\n            logger.exception(\"Error during processing: {}\", exc)\r\n            self.window.set_state(\"error\")\r\n            self.window.show_message(\"Error during recognition. See logs.\")\r\n\r\n    # -------------------------------------------------------------- Debug\r\n\r\n    def toggle_debug_mode(self) -> None:\r\n        # Placeholder: will reconfigure logging level later\r\n        self.window.show_message(\"Toggle debug (not fully implemented yet).\")\r\n\r\n    # -------------------------------------------------------------- Lifecycle\r\n\r\n    def quit(self) -> None:\r\n        self.hotkeys.stop()\r\n        self.qt_app.quit()\r\n\r\n    def run(self) -> None:\r\n        self.hotkeys.start()\r\n        self.show_window()\r\n        sys.exit(self.qt_app.exec())\r\n\r\n\r\ndef main() -> None:\r\n    app = App()\r\n    app.run()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()"
        }
    ]
}
{
    "sourceFile": "tests/manual_llm_test.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1764470201454,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1764470259138,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,9 +6,9 @@\n SRC = ROOT / \"src\"\r\n if str(SRC) not in sys.path:\r\n     sys.path.insert(0, str(SRC))\r\n \r\n-from config.settings import AppSettings, load_settings\r\n+from config.settings import AppSettings\r\n from recognition.postprocessor import TextPostprocessor\r\n \r\n \r\n def print_header(title: str) -> None:\r\n"
                },
                {
                    "date": 1764470550329,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,10 +80,10 @@\n \r\n \r\n def main() -> None:\r\n     print_header(\"ЗАГРУЗКА НАСТРОЕК\")\r\n-    settings = load_settings()\r\n-    print(f\"config path: {settings.config_path}\")\r\n+    # Загружаем настройки так же, как это делает приложение:\r\n+    settings = AppSettings.load_default()\r\n     print(f\"recognition.backend: {settings.recognition.backend}\")\r\n     print(f\"postprocess.enabled: {settings.postprocess.enabled}\")\r\n     print(f\"postprocess.mode: {settings.postprocess.mode}\")\r\n     print(f\"postprocess.llm_backend: {settings.postprocess.llm_backend}\")\r\n"
                }
            ],
            "date": 1764470201454,
            "name": "Commit-0",
            "content": "import sys\r\nfrom pathlib import Path\r\n\r\n# Ensure src is on sys.path\r\nROOT = Path(__file__).resolve().parents[1]\r\nSRC = ROOT / \"src\"\r\nif str(SRC) not in sys.path:\r\n    sys.path.insert(0, str(SRC))\r\n\r\nfrom config.settings import AppSettings, load_settings\r\nfrom recognition.postprocessor import TextPostprocessor\r\n\r\n\r\ndef print_header(title: str) -> None:\r\n    print(\"\\n\" + \"=\" * 80)\r\n    print(title)\r\n    print(\"=\" * 80)\r\n\r\n\r\ndef run_llm_test(settings: AppSettings) -> None:\r\n    post_cfg = settings.postprocess\r\n    backend = (post_cfg.llm_backend or \"\").lower()\r\n\r\n    print_header(\"ТЕКУЩИЕ НАСТРОЙКИ LLM\")\r\n    print(f\"postprocess.enabled        = {post_cfg.enabled}\")\r\n    print(f\"postprocess.mode           = {post_cfg.mode}\")\r\n    print(f\"postprocess.llm_backend    = {post_cfg.llm_backend}\")\r\n    print(f\"Groq model (postprocess)   = {getattr(post_cfg.groq, 'model', '')}\")\r\n    print(f\"OpenAI model (postprocess) = {getattr(post_cfg.openai, 'model', '')}\")\r\n    print(f\"OpenAI base_url            = {getattr(post_cfg.openai, 'base_url', '')}\")\r\n    print(f\"Groq api_key set?          = {bool(getattr(post_cfg.groq, 'api_key', ''))}\")\r\n    print(f\"OpenAI api_key set?        = {bool(getattr(post_cfg.openai, 'api_key', ''))}\")\r\n\r\n    if not post_cfg.enabled:\r\n        print(\"\\n[SKIP] postprocess.enabled = false → LLM не используется.\")\r\n        return\r\n\r\n    if (post_cfg.mode or \"\").lower() != \"llm\":\r\n        print(f\"\\n[SKIP] postprocess.mode = {post_cfg.mode!r} (ожидается 'llm').\")\r\n        return\r\n\r\n    if backend not in {\"groq\", \"openai\"}:\r\n        print(f\"\\n[SKIP] postprocess.llm_backend = {post_cfg.llm_backend!r} (ожидается 'groq' или 'openai').\")\r\n        return\r\n\r\n    print_header(\"ЗАПУСК ТЕСТОВОГО ЗАПРОСА К LLM\")\r\n    print(f\"Backend: {backend}\")\r\n\r\n    postprocessor = TextPostprocessor(config=post_cfg)\r\n\r\n    test_text = \"привет как дела это тест без запятых\"\r\n    print(f\"\\nВходной текст: {test_text!r}\")\r\n\r\n    try:\r\n        result = postprocessor.process(test_text)\r\n    except Exception as exc:\r\n        print(\"\\n[ERROR] Исключение при вызове postprocessor.process():\")\r\n        print(f\"{type(exc).__name__}: {exc}\")\r\n        return\r\n\r\n    print(\"\\nРезультат postprocessor.process():\")\r\n    print(repr(result))\r\n\r\n    print_header(\"ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТА\")\r\n    if result == test_text:\r\n        print(\r\n            \"Текст совпадает с исходным.\\n\"\r\n            \"- Если в логах приложения есть сообщение вида\\n\"\r\n            \"  'LLM postprocess failed, fallback to regex-only',\\n\"\r\n            \"  значит LLM‑запрос упал и сработал fallback.\\n\"\r\n            \"- Если логов об ошибке LLM нет, значит LLM либо отключён,\\n\"\r\n            \"  либо режим postprocess.mode != 'llm'.\"\r\n        )\r\n    else:\r\n        print(\r\n            \"Текст ИЗМЕНИЛСЯ по сравнению с исходным.\\n\"\r\n            \"Это означает, что LLM‑постпроцессинг ОТРАБОТАЛ успешно\\n\"\r\n            \"(по крайней мере, без исключений на уровне клиента).\"\r\n        )\r\n\r\n\r\ndef main() -> None:\r\n    print_header(\"ЗАГРУЗКА НАСТРОЕК\")\r\n    settings = load_settings()\r\n    print(f\"config path: {settings.config_path}\")\r\n    print(f\"recognition.backend: {settings.recognition.backend}\")\r\n    print(f\"postprocess.enabled: {settings.postprocess.enabled}\")\r\n    print(f\"postprocess.mode: {settings.postprocess.mode}\")\r\n    print(f\"postprocess.llm_backend: {settings.postprocess.llm_backend}\")\r\n\r\n    run_llm_test(settings)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()"
        }
    ]
}
{
    "sourceFile": "docs/ARCHITECTURE.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1764477939558,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1764477939558,
            "name": "Commit-0",
            "content": "# VoiceCapture Architecture\r\n\r\nThis document describes the internal architecture of VoiceCapture: how modules are structured, how data flows through the system, and how configuration and backends are wired together.\r\n\r\nThe goal is to give a new contributor enough context to navigate the codebase and safely extend it.\r\n\r\n---\r\n\r\n## 1. High‑Level Overview\r\n\r\nVoiceCapture is a small desktop utility that:\r\n\r\n1. Listens for global hotkeys.\r\n2. Records audio from the system microphone.\r\n3. Sends audio to a speech‑to‑text backend (Groq, OpenAI, or local).\r\n4. Optionally post‑processes the text with an LLM.\r\n5. Copies the result to the clipboard and simulates `Ctrl+V` into the active window.\r\n6. Shows status and text in a floating always‑on‑top window and a system tray icon.\r\n\r\nMain entry point:\r\n\r\n- [`src/main.py`](src/main.py)\r\n  - Defines the `App` class, which wires together:\r\n    - Configuration (`AppSettings`)\r\n    - Audio recorder\r\n    - Recognition backend\r\n    - Text post‑processor\r\n    - Clipboard manager\r\n    - UI (floating window + tray)\r\n    - Hotkey manager\r\n    - Logging\r\n\r\n---\r\n\r\n## 2. Configuration Layer\r\n\r\n### 2.1. AppSettings and Config Dataclasses\r\n\r\nFile: [`src/config/settings.py`](src/config/settings.py:1)\r\n\r\nKey components:\r\n\r\n- `HotkeysConfig`\r\n- `AudioConfig`\r\n- `UIConfig`\r\n- `RecognitionLocalConfig`\r\n- `OpenAIRecognitionConfig`\r\n- `GroqRecognitionConfig`\r\n- `PostprocessConfig`\r\n- `AppSettings`\r\n\r\n`AppSettings` is the root configuration object. It is responsible for:\r\n\r\n- Loading YAML configuration from `src/config/config.yaml` (and later `config.local.yaml`).\r\n- Validating and normalizing values.\r\n- Providing typed access to all settings.\r\n\r\nImportant methods:\r\n\r\n- [`AppSettings.load_default()`](src/config/settings.py:132)\r\n  - Currently:\r\n    - Loads `config.yaml`.\r\n  - Planned:\r\n    - Load `config.yaml`.\r\n    - If present, load `config.local.yaml`.\r\n    - Merge `config.local.yaml` **over** `config.yaml` so local values override defaults.\r\n\r\n### 2.2. YAML Files\r\n\r\n- Default config: [`src/config/config.yaml`](src/config/config.yaml:1)\r\n  - Contains **no real API keys**.\r\n  - Safe to commit to GitHub.\r\n  - Defines:\r\n    - `recognition.backend` (`local` | `openai` | `groq`)\r\n    - `recognition.local` (model, device, compute_type, language, beam_size, temperature)\r\n    - `recognition.openai` (api_key placeholder, model, model_process, base_url, language)\r\n    - `recognition.groq` (api_key placeholder, model, model_process, language)\r\n    - `postprocess` (LLM backend and models)\r\n    - `audio` (sample rate, channels, max duration)\r\n    - `ui` (window size, opacity, compact mode)\r\n    - `hotkeys` (global hotkey combinations)\r\n\r\n- Local overrides (planned, not yet wired in code):\r\n  - `src/config/config.local.yaml`\r\n    - Ignored by `.gitignore`.\r\n    - Intended to hold real API keys and machine‑specific overrides.\r\n\r\n---\r\n\r\n## 3. Main Application Orchestration\r\n\r\nFile: [`src/main.py`](src/main.py:1)\r\n\r\n### 3.1. App Lifecycle\r\n\r\nClass: `App`\r\n\r\nKey responsibilities:\r\n\r\n1. Initialize logging via [`setup_logging`](src/utils/logger.py:1).\r\n2. Load configuration via `AppSettings.load_default()`.\r\n3. Create and wire:\r\n   - `AudioRecorder`\r\n   - Recognition backend (via `create_recognizer`)\r\n   - `TextPostprocessor`\r\n   - `ClipboardManager`\r\n   - `FloatingWindow`\r\n   - `SystemTrayIcon`\r\n   - `HotKeyManager`\r\n4. Connect signals/slots between UI, hotkeys, and core logic.\r\n5. Implement the main workflow:\r\n   - Start recording on hotkey press.\r\n   - Stop recording on hotkey release.\r\n   - Run recognition and post‑processing.\r\n   - Copy & paste result.\r\n   - Update UI state and logs.\r\n\r\nImportant methods (line numbers approximate):\r\n\r\n- [`App.__init__`](src/main.py:34)\r\n  - Loads config.\r\n  - Creates UI components.\r\n  - Creates recorder, recognizer, postprocessor, clipboard.\r\n  - Sets up hotkeys and connects signals.\r\n\r\n- [`App.start_recording`](src/main.py:178)\r\n  - Called when the record hotkey is pressed.\r\n  - Updates UI state to `recording`.\r\n  - Starts `AudioRecorder`.\r\n\r\n- [`App.stop_recording`](src/main.py:191)\r\n  - Called when the record hotkey is released.\r\n  - Stops `AudioRecorder`.\r\n  - Triggers `_process_audio` in a background task.\r\n\r\n- [`App._process_audio`](src/main.py:206)\r\n  - Core pipeline:\r\n    1. Reads recorded audio.\r\n    2. Sends it to the recognizer.\r\n    3. Runs `_simple_cleanup` and LLM post‑processing via `TextPostprocessor`.\r\n    4. Updates UI with raw and processed text.\r\n    5. Uses `ClipboardManager` to copy and paste the processed text.\r\n    6. Logs transcript to `logs/transcripts.log`.\r\n\r\n- [`App.toggle_debug_mode`](src/main.py:332)\r\n  - Currently a stub:\r\n    - Shows a message in the window.\r\n  - Planned:\r\n    - Toggle log level (INFO/DEBUG).\r\n    - Optionally show a debug panel or log viewer.\r\n\r\n---\r\n\r\n## 4. Audio Subsystem\r\n\r\nFile: [`src/audio/recorder.py`](src/audio/recorder.py:1)\r\n\r\nClass: `AudioRecorder`\r\n\r\nResponsibilities:\r\n\r\n- Manage audio capture from the default input device using `sounddevice.InputStream`.\r\n- Store audio in memory for later processing.\r\n- Respect configuration from `AudioConfig`:\r\n  - `sample_rate`\r\n  - `channels`\r\n  - `max_duration`\r\n\r\nKey points:\r\n\r\n- Format: `float32` samples.\r\n- Recording loop:\r\n  - Appends incoming audio chunks to an internal buffer.\r\n  - Stops when:\r\n    - `stop()` is called by `App.stop_recording()`, or\r\n    - `max_duration` is reached.\r\n- Conversion to WAV:\r\n  - Recognition backends (`groq_api`, `openai_api`, `gigaam_local`) handle conversion to WAV or tensor formats as needed.\r\n\r\nPlanned extensions:\r\n\r\n- [`audio/vad.py`](src/audio/vad.py:1) (not yet implemented):\r\n  - Simple VAD based on RMS/energy.\r\n  - Auto‑stop recording when silence > 1.5s.\r\n  - Integration into the recording loop to stop on silence instead of only manual stop / max duration.\r\n\r\n---\r\n\r\n## 5. Recognition Backends\r\n\r\nDirectory: [`src/recognition/`](src/recognition/__init__.py:1)\r\n\r\n### 5.1. Factory\r\n\r\nFile: [`src/recognition/__init__.py`](src/recognition/__init__.py:1)\r\n\r\nFunction: `create_recognizer(settings: AppSettings)`\r\n\r\n- Reads `settings.recognition.backend`:\r\n  - `\"groq\"` → `GroqWhisperRecognizer`\r\n  - `\"openai\"` → `OpenAIWhisperRecognizer`\r\n  - `\"local\"` → `GigaAMRecognizer` (currently; Whisper planned)\r\n- Passes relevant config sections to the chosen recognizer.\r\n\r\n### 5.2. Groq Whisper API\r\n\r\nFile: [`src/recognition/groq_api.py`](src/recognition/groq_api.py:1)\r\n\r\nClass: `GroqWhisperRecognizer`\r\n\r\n- Endpoint: `https://api.groq.com/openai/v1/audio/transcriptions`\r\n- Uses:\r\n  - `recognition.groq.api_key`\r\n  - `recognition.groq.model`\r\n  - `recognition.groq.language`\r\n- Responsibilities:\r\n  - Convert recorded audio to WAV.\r\n  - Send multipart/form‑data request to Groq.\r\n  - Handle:\r\n    - Timeouts\r\n    - Network errors\r\n    - HTTP 401 / 429 / other errors\r\n  - Return recognized text.\r\n\r\n### 5.3. OpenAI Whisper / OpenAI‑Compatible API\r\n\r\nFile: [`src/recognition/openai_api.py`](src/recognition/openai_api.py:1)\r\n\r\nClass: `OpenAIWhisperRecognizer`\r\n\r\n- Endpoint: `{base_url}/audio/transcriptions`\r\n  - `base_url` from `recognition.openai.base_url`.\r\n  - Allows using:\r\n    - Official OpenAI API.\r\n    - Self‑hosted / compatible endpoints (e.g. VoidAI).\r\n- Uses:\r\n  - `recognition.openai.api_key`\r\n  - `recognition.openai.model`\r\n  - `recognition.openai.language`\r\n- Responsibilities:\r\n  - Same as Groq recognizer, but with OpenAI‑style API.\r\n\r\n### 5.4. Local ASR (GigaAM)\r\n\r\nFile: [`src/recognition/gigaam_local.py`](src/recognition/gigaam_local.py:12)\r\n\r\nClass: `GigaAMRecognizer`\r\n\r\n- Uses `transformers.AutoModel` to load a local GigaAM‑v3 model.\r\n- Runs inference on the recorded audio locally (CPU/GPU depending on config).\r\n- Config:\r\n  - `recognition.local.model`\r\n  - `recognition.local.device`\r\n  - `recognition.local.compute_type`\r\n  - `recognition.local.language`\r\n  - `recognition.local.beam_size`\r\n  - `recognition.local.temperature`\r\n\r\nThis is not Whisper, but functionally satisfies “local ASR backend”.\r\n\r\n### 5.5. Planned: Local Whisper via faster‑whisper\r\n\r\nFile (planned): [`src/recognition/whisper_local.py`](src/recognition/whisper_local.py:1)\r\n\r\n- Implementation idea:\r\n  - Use `faster-whisper` to load a Whisper model.\r\n  - Respect `recognition.local` parameters:\r\n    - `model`\r\n    - `device`\r\n    - `compute_type`\r\n    - `language`\r\n    - `beam_size`\r\n    - `temperature`\r\n- Factory extension:\r\n  - Add `recognition.local.engine: \"gigaam\" | \"whisper\"`.\r\n  - `create_recognizer()` chooses between `GigaAMRecognizer` and `WhisperLocalRecognizer`.\r\n\r\n### 5.6. GPU Detection\r\n\r\nFile (planned): [`src/utils/gpu_check.py`](src/utils/gpu_check.py:1)\r\n\r\n- Functions:\r\n  - `has_cuda()`\r\n  - `get_gpu_info()`\r\n- Usage:\r\n  - Local ASR backends can:\r\n    - Prefer GPU when available.\r\n    - Warn user if GPU is not detected but `device=cuda` is configured.\r\n\r\n---\r\n\r\n## 6. Text Post‑Processing\r\n\r\nFile: [`src/recognition/postprocessor.py`](src/recognition/postprocessor.py:1)\r\n\r\nClass: `TextPostprocessor`\r\n\r\nResponsibilities:\r\n\r\n1. Simple cleanup:\r\n   - `_simple_cleanup(text)`:\r\n     - Regex‑based normalization.\r\n     - Trims whitespace, fixes common artifacts from ASR.\r\n2. LLM‑based correction (optional):\r\n   - Uses `postprocess.llm_backend`:\r\n     - `\"groq\"` → Groq LLM (e.g. Mixtral).\r\n     - `\"openai\"` → OpenAI LLM (e.g. GPT‑4).\r\n   - Uses:\r\n     - `postprocess.groq.model_process`\r\n     - `postprocess.openai.model_process`\r\n   - **API keys are taken from recognition config**:\r\n     - `recognition.groq.api_key`\r\n     - `recognition.openai.api_key`\r\n   - Prompt:\r\n     - Fix typos and punctuation.\r\n     - Do not change the meaning of the text.\r\n\r\nIntegration in `App`:\r\n\r\n- In [`App._process_audio`](src/main.py:268):\r\n  1. `raw_text = recognizer.transcribe(audio)`\r\n  2. `clean_text = self.postprocessor._simple_cleanup(raw_text)`\r\n  3. `processed_text = self.postprocessor.process(raw_text)` (LLM)\r\n  4. UI shows both:\r\n     - `set_raw_text(raw_text)`\r\n     - `set_processed_text(processed_text)`\r\n\r\n---\r\n\r\n## 7. Clipboard and Keyboard Simulation\r\n\r\nFile: [`src/clipboard/clipboard_manager.py`](src/clipboard/clipboard_manager.py:1)\r\n\r\nClass: `ClipboardManager`\r\n\r\nResponsibilities:\r\n\r\n- Copy text to the system clipboard using `pyperclip`.\r\n- Simulate `Ctrl+V` into the active window using `pynput`.\r\n- Implement retries and small delays to make paste more reliable.\r\n\r\nUsage in `App`:\r\n\r\n- In [`App._process_audio`](src/main.py:295):\r\n  - `self.clipboard.copy(processed_text)`\r\n  - `self.clipboard.paste()`\r\n\r\nThis allows the user to simply hold the hotkey, speak, and have the text appear in the active application.\r\n\r\n---\r\n\r\n## 8. UI Layer\r\n\r\nDirectory: [`src/ui/`](src/ui/floating_window.py:1)\r\n\r\n### 8.1. Floating Window\r\n\r\nFile: [`src/ui/floating_window.py`](src/ui/floating_window.py:33)\r\n\r\nClass: `FloatingWindow` (PySide6 widget)\r\n\r\nFeatures:\r\n\r\n- Frameless, always‑on‑top, translucent window:\r\n  - [`_init_window_flags`](src/ui/floating_window.py:74)\r\n- Size and opacity from `UIConfig`:\r\n  - [`_apply_config`](src/ui/floating_window.py:200)\r\n- Draggable:\r\n  - [`mousePressEvent`](src/ui/floating_window.py:344)\r\n  - [`mouseMoveEvent`](src/ui/floating_window.py:350)\r\n- Double‑click:\r\n  - [`mouseDoubleClickEvent`](src/ui/floating_window.py:360)\r\n  - Emits `settings_requested` signal.\r\n- States:\r\n  - `idle`, `recording`, `processing`, `ready`, `error`\r\n  - [`set_state`](src/ui/floating_window.py:209) updates icons/emoji and text.\r\n- Compact mode:\r\n  - [`set_compact`](src/ui/floating_window.py:249)\r\n  - [`_apply_compact_mode`](src/ui/floating_window.py:259)\r\n  - Shows a minimal microphone icon.\r\n\r\nSignals:\r\n\r\n- `settings_requested`\r\n- `exit_requested`\r\n- `copy_requested` (if user clicks on text blocks, etc.)\r\n\r\nPlanned enhancements:\r\n\r\n- Play sounds on state changes (start/stop/error) using `assets/sounds/*.wav`.\r\n\r\n### 8.2. System Tray\r\n\r\nFile: [`src/ui/system_tray.py`](src/ui/system_tray.py:1)\r\n\r\nClass: `SystemTrayIcon`\r\n\r\nFeatures:\r\n\r\n- Tray icon with context menu.\r\n- Signals:\r\n  - `show_window_requested`\r\n  - `settings_requested`\r\n  - `toggle_debug_requested`\r\n  - `exit_requested`\r\n\r\nIntegration:\r\n\r\n- In [`App.__init__`](src/main.py:34):\r\n  - Tray is created and signals are connected to `App` methods.\r\n\r\nPlanned behavior:\r\n\r\n- “Close to tray”:\r\n  - Clicking ✖️ in the window hides it but keeps the app running in the tray.\r\n  - Tray menu provides “Exit” for full shutdown.\r\n\r\n### 8.3. Settings Dialog\r\n\r\nFile: [`src/ui/settings_dialog.py`](src/ui/settings_dialog.py:1)\r\n\r\nClass: `SettingsDialog`\r\n\r\nResponsibilities:\r\n\r\n- Provide a UI for editing:\r\n  - Recognition backend (`local/openai/groq`).\r\n  - API keys for Groq / OpenAI.\r\n  - Models and language.\r\n  - Hotkeys.\r\n- Save changes back to `AppSettings` and persist them to YAML.\r\n\r\nThis dialog is opened from:\r\n\r\n- Double‑click on `FloatingWindow`.\r\n- Tray menu.\r\n- Possibly other UI elements.\r\n\r\n---\r\n\r\n## 9. Hotkeys\r\n\r\nDirectory: [`src/hotkey/`](src/hotkey/hotkey_manager.py:1)\r\n\r\nFile: [`src/hotkey/hotkey_manager.py`](src/hotkey/hotkey_manager.py:1)\r\n\r\nClass: `HotKeyManager`\r\n\r\nResponsibilities:\r\n\r\n- Register global hotkeys using `pynput`.\r\n- Map key combinations from `HotkeysConfig` to callbacks in `App`.\r\n\r\nDefault hotkeys (configurable):\r\n\r\n- `record` — `Ctrl + Win` (press = start, release = stop).\r\n- `cancel` — `Esc`.\r\n- `show_window` — `Ctrl + Alt + S`.\r\n- `toggle_debug` — `Ctrl + Alt + D`.\r\n\r\nIntegration:\r\n\r\n- In [`App.__init__`](src/main.py:79):\r\n  - `HotKeyManager` is created with all combinations from config.\r\n  - Callbacks are bound to `App.start_recording`, `App.stop_recording`, `App.toggle_debug_mode`, etc.\r\n\r\n---\r\n\r\n## 10. Logging and Debugging\r\n\r\nDirectory: [`src/utils/`](src/utils/logger.py:1)\r\n\r\nFile: [`src/utils/logger.py`](src/utils/logger.py:1)\r\n\r\nFunction: `setup_logging()`\r\n\r\n- Uses `loguru` for logging.\r\n- Configures:\r\n  - Console logging.\r\n  - File logging with rotation (e.g. `app.log`).\r\n- In `_process_audio`, transcripts are additionally logged to:\r\n  - `logs/transcripts.log` with rotation at ~3 MB.\r\n\r\nDebug mode:\r\n\r\n- Toggled via:\r\n  - Hotkey (`toggle_debug`).\r\n  - Tray menu.\r\n- Current implementation:\r\n  - Only shows a message in the floating window.\r\n- Planned:\r\n  - Switch log level between INFO and DEBUG.\r\n  - Optionally show a debug overlay or log viewer.\r\n\r\n---\r\n\r\n## 11. Tests\r\n\r\nDirectory: [`tests/`](tests/manual_llm_test.py:1)\r\n\r\nCurrent tests:\r\n\r\n- [`tests/manual_llm_test.py`](tests/manual_llm_test.py:1)\r\n  - Manual test for LLM post‑processing.\r\n  - Useful for verifying Groq/OpenAI integration with your keys.\r\n\r\nPlanned tests:\r\n\r\n- Unit tests:\r\n  - `test_audio_recorder.py` — basic recording and buffer behavior.\r\n  - `test_whisper_local.py` — local Whisper backend (once implemented).\r\n  - `test_clipboard.py` — clipboard copy/paste logic (with mocks).\r\n  - `test_config.py` — config loading and `config.local.yaml` merge.\r\n- Integration tests:\r\n  - End‑to‑end workflow:\r\n    - Simulate audio input.\r\n    - Run through recognizer and postprocessor.\r\n    - Verify clipboard content.\r\n\r\n---\r\n\r\n## 12. Extensibility Guidelines\r\n\r\n### 12.1. Adding a New Recognition Backend\r\n\r\n1. Create a new file in `src/recognition/`, e.g. [`my_backend.py`](src/recognition/my_backend.py:1).\r\n2. Implement a recognizer class with a `transcribe(audio_bytes | np.ndarray) -> str` method.\r\n3. Add configuration fields to:\r\n   - `AppSettings` / `Recognition*Config` in [`settings.py`](src/config/settings.py:1).\r\n   - `config.yaml` (with placeholders, no real keys).\r\n4. Extend `create_recognizer()` in [`__init__.py`](src/recognition/__init__.py:1) to handle the new backend.\r\n5. Optionally extend `SettingsDialog` to allow selecting and configuring the new backend.\r\n\r\n### 12.2. Adding New UI Elements\r\n\r\n- Use PySide6 widgets in:\r\n  - [`floating_window.py`](src/ui/floating_window.py:33) for always‑on‑top UI.\r\n  - [`settings_dialog.py`](src/ui/settings_dialog.py:1) for configuration.\r\n- Expose new actions via:\r\n  - Signals from UI to `App`.\r\n  - Methods in `App` that perform the actual logic.\r\n\r\n### 12.3. Working with Config and Secrets\r\n\r\n- Never hard‑code API keys in code or in `config.yaml`.\r\n- Use:\r\n  - `config.local.yaml` (ignored by git).\r\n  - Environment variables (once `.env` support is added).\r\n  - UI input that is sanitized before commit.\r\n\r\n---\r\n\r\n## 13. Summary\r\n\r\n- `App` in [`src/main.py`](src/main.py:34) is the central orchestrator.\r\n- Configuration is handled by `AppSettings` in [`src/config/settings.py`](src/config/settings.py:121) with YAML files in `src/config/`.\r\n- Audio is captured by `AudioRecorder` in [`src/audio/recorder.py`](src/audio/recorder.py:21).\r\n- Recognition backends live in `src/recognition/` and are selected by `create_recognizer()`.\r\n- Text post‑processing is done by `TextPostprocessor` in [`src/recognition/postprocessor.py`](src/recognition/postprocessor.py:1).\r\n- Clipboard operations are handled by `ClipboardManager` in [`src/clipboard/clipboard_manager.py`](src/clipboard/clipboard_manager.py:1).\r\n- UI is implemented with PySide6 in `src/ui/` (floating window, tray, settings dialog).\r\n- Hotkeys are managed by `HotKeyManager` in [`src/hotkey/hotkey_manager.py`](src/hotkey/hotkey_manager.py:1).\r\n- Logging is configured by `setup_logging` in [`src/utils/logger.py`](src/utils/logger.py:1).\r\n\r\nThis structure should make it straightforward to extend the app with new backends, UI features, and configuration options while keeping secrets safe and the public repository clean."
        }
    ]
}
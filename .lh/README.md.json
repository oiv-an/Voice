{
    "sourceFile": "README.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1764648009086,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1764649082256,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -87,9 +87,9 @@\n \r\n ui:\r\n   always_on_top: true\r\n   opacity: 0.9\r\n-  window_size: [600, 500]\r\n+  window_size: [600, 400]\r\n   auto_hide_after_paste: true\r\n   hide_delay: 2000\r\n \r\n logging:\r\n"
                },
                {
                    "date": 1764664111139,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -352,9 +352,9 @@\n ## Логирование\r\n \r\n Используется [`loguru`](src/utils/logger.py#L1).\r\n \r\n-Ключевые сообщения:\r\n+### Основные сообщения в консоль / app.log\r\n \r\n - При распознавании:\r\n   - `Trying recognition backend: {backend}`\r\n   - `Recognition succeeded with backend: {backend}`\r\n@@ -368,8 +368,41 @@\n     - `OpenAI LLM postprocess using api_key (first 8 chars): {prefix}***`\r\n - При ошибках LLM:\r\n   - `LLM postprocess failed, fallback to regex-only: {exc}`.\r\n \r\n+### Отдельный лог распознаваний (transcripts.log)\r\n+\r\n+Каждое успешное распознавание дополнительно сохраняется в отдельный текстовый лог‑файл:\r\n+\r\n+- Путь: `<base_dir>/logs/transcripts.log`, где:\r\n+  - `base_dir` — корень проекта при запуске из исходников;\r\n+  - либо папка рядом с `.exe` в собранной версии.\r\n+- Реализация — в методе [`App._process_audio()`](src/main.py:253).\r\n+\r\n+Для каждого распознавания в `transcripts.log` пишется блок вида:\r\n+\r\n+```text\r\n+[2025-12-02 11:23:45] backend=groq duration=3.524s\r\n+RAW: привет как дела\r\n+PROCESSED: Привет, как дела?\r\n+----------------------------------------\r\n+```\r\n+\r\n+Где:\r\n+\r\n+- `timestamp` — время завершения распознавания;\r\n+- `backend` — фактический backend, который вернул результат (`groq` / `openai` / `local`);\r\n+- `duration` — длительность аудио в секундах (по числу сэмплов и sample_rate);\r\n+- `RAW` — исходный текст от ASR;\r\n+- `PROCESSED` — текст после постобработки (regex + LLM, если включён).\r\n+\r\n+#### Ротация transcripts.log\r\n+\r\n+- Если размер `transcripts.log` достигает ~3 МБ:\r\n+  - текущий файл переименовывается в `transcripts_YYYYMMDD_HHMMSS.log`;\r\n+  - создаётся новый `transcripts.log`.\r\n+- Это позволяет хранить историю распознаваний без бесконечного роста файла.\r\n+\r\n ---\r\n \r\n ## Как использовать\r\n \r\n"
                }
            ],
            "date": 1764648009086,
            "name": "Commit-0",
            "content": "# VoiceCapture\r\n\r\n## Описание (RU)\r\n\r\nVoiceCapture — это десктоп‑утилита для Windows, которая:\r\n- записывает голос по глобальной горячей клавише;\r\n- отправляет аудио в выбранный backend распознавания (Groq / OpenAI / локальный GigaAM);\r\n- опционально прогоняет текст через LLM‑постпроцессинг (Groq или OpenAI);\r\n- копирует итоговый текст в буфер обмена и автоматически вставляет его (Ctrl+V).\r\n\r\nКлючевые цели текущей версии:\r\n- единый, предсказуемый конфиг `config.yaml`;\r\n- корректная работа всех backend’ов (Groq/OpenAI/local) для ASR и LLM;\r\n- консистентная работа окна настроек;\r\n- чистый, легко отлаживаемый пайплайн распознавания и постпроцессинга;\r\n- простая и надёжная локальная интеграция GigaAM‑v3 без longform и без Hugging Face токена.\r\n\r\n---\r\n\r\n## Архитектура конфигурации\r\n\r\n### Единый файл настроек\r\n\r\nВсе настройки хранятся только в одном файле:\r\n\r\n- `config.yaml` в корне рядом с `src/` и `requirements.txt`.\r\n\r\nЗагрузка/сохранение настроек реализована в [`AppSettings.load_default()`](src/config/settings.py#L132) и [`AppSettings.save_default()`](src/config/settings.py#L277).\r\n\r\nПри первом запуске, если `config.yaml` отсутствует, он создаётся автоматически с безопасными дефолтами (см. [`App._load_or_init_settings()`](src/main.py#L349)).\r\n\r\n### Структура AppSettings\r\n\r\nОсновной датакласс настроек — [`AppSettings`](src/config/settings.py#L121). Важные блоки:\r\n\r\n```yaml\r\napp:\r\n  name: VoiceCapture\r\n  version: 0.1.0\r\n  language: ru\r\n  debug: false\r\n\r\nhotkeys:\r\n  record: ctrl+win\r\n  cancel: esc\r\n  toggle_window: ctrl+alt+s\r\n  toggle_debug: ctrl+alt+d\r\n\r\naudio:\r\n  device: default\r\n  sample_rate: 16000\r\n  channels: 1\r\n  format: float32\r\n  max_duration: 120\r\n  vad_threshold: 0.5\r\n  vad_min_duration: 0.1\r\n\r\nrecognition:\r\n  backend: groq        # groq / openai / local\r\n  local:\r\n    model: large-v3\r\n    device: cuda\r\n    compute_type: float16\r\n    language: ru\r\n    beam_size: 5\r\n    temperature: 0.0\r\n  openai:\r\n    api_key: sk-...\r\n    model: gpt-4o-transcribe\r\n    model_process: gpt-5.1\r\n    language: ru\r\n    base_url: https://api.voidai.app/v1\r\n  groq:\r\n    api_key: gsk-...\r\n    model: whisper-large-v3\r\n    model_process: moonshotai/kimi-k2-instruct\r\n    language: ru\r\n\r\npostprocess:\r\n  enabled: true\r\n  mode: llm            # simple / llm\r\n  llm_backend: openai  # groq / openai\r\n  groq:\r\n    model: moonshotai/kimi-k2-instruct\r\n  openai:\r\n    model: gpt-5.1\r\n\r\nui:\r\n  always_on_top: true\r\n  opacity: 0.9\r\n  window_size: [600, 500]\r\n  auto_hide_after_paste: true\r\n  hide_delay: 2000\r\n\r\nlogging:\r\n  level: INFO\r\n  file: app.log\r\n  max_file_size: 10485760\r\n  backup_count: 3\r\n```\r\n\r\n#### recognition.*\r\n\r\nОпределено в:\r\n\r\n- [`OpenAIRecognitionConfig`](src/config/settings.py#L52)\r\n- [`GroqRecognitionConfig`](src/config/settings.py#L62)\r\n- [`LocalRecognitionConfig`](src/config/settings.py#L42)\r\n- [`RecognitionConfig`](src/config/settings.py#L73)\r\n\r\nКлючевые поля:\r\n\r\n- `recognition.backend` — текущий backend распознавания (`groq` / `openai` / `local`).\r\n- `recognition.local`:\r\n  - `model` — идентификатор локальной модели GigaAM‑v3 (используется внутри кода, по умолчанию `large-v3`).\r\n  - `device` — `\"cuda\"` или `\"cpu\"`; при `cuda` и отсутствии GPU автоматически падает на CPU.\r\n  - `compute_type`, `language`, `beam_size`, `temperature` — зарезервированы под локальные модели, сейчас используются минимально.\r\n  - **Ограничение:** локальный GigaAM‑backend обрабатывает только аудио до ~25 секунд. Всё, что длиннее, автоматически отдаётся в облачный backend (Groq/OpenAI) через каскад `_process_audio`.\r\n- `recognition.openai`:\r\n  - `api_key` — ключ к OpenAI‑совместимому API (или прокси).\r\n  - `model` — модель ASR (например, `gpt-4o-transcribe`).\r\n  - `model_process` — модель LLM для постпроцессинга (например, `gpt-5.1`).\r\n  - `language` — язык распознавания.\r\n  - `base_url` — **единственный** источник базового URL для OpenAI (ASR и LLM).\r\n- `recognition.groq`:\r\n  - `api_key` — ключ Groq.\r\n  - `model` — модель ASR (`whisper-large-v3`).\r\n  - `model_process` — модель LLM (`moonshotai/kimi-k2-instruct`).\r\n  - `language` — язык распознавания.\r\n\r\n#### postprocess.*\r\n\r\nОпределено в:\r\n\r\n- [`GroqPostprocessConfig`](src/config/settings.py#L84)\r\n- [`OpenAIPostprocessConfig`](src/config/settings.py#L88)\r\n- [`PostprocessConfig`](src/config/settings.py#L93)\r\n\r\nСодержит только:\r\n\r\n- `enabled` — включён ли постпроцессинг.\r\n- `mode` — `\"simple\"` (только regex) или `\"llm\"` (regex + LLM).\r\n- `llm_backend` — `\"groq\"` или `\"openai\"`.\r\n- `groq.model` — отображательная модель Groq LLM (для UI/конфига).\r\n- `openai.model` — отображательная модель OpenAI LLM.\r\n\r\n**Важно:** в `postprocess.*` **нет**:\r\n\r\n- `api_key`\r\n- `model_process`\r\n- `base_url`\r\n\r\nВсе ключи, модели LLM и URL живут в `recognition.*`.\r\n\r\nПри загрузке [`AppSettings.load_default()`](src/config/settings.py#L229) выкидывает из `postprocess.groq` и `postprocess.openai` любые старые поля `api_key`, `model`, `model_process`, `base_url`, если они остались в старом `config.yaml`.\r\n\r\n---\r\n\r\n## Окно настроек (SettingsDialog)\r\n\r\nРеализовано в [`SettingsDialog`](src/ui/settings_dialog.py#L22).\r\n\r\n### Привязка полей UI к AppSettings\r\n\r\nЗагрузка значений из настроек — [`_load_from_settings`](src/ui/settings_dialog.py#L172):\r\n\r\n- Сервис распознавания:\r\n  - Комбо \"Сервис распознавания\" ↔ `settings.recognition.backend`.\r\n- Groq API key:\r\n  - Поле \"Groq API key\" ↔ `settings.recognition.groq.api_key`.\r\n- OpenAI API key:\r\n  - Поле \"OpenAI API key\" ↔ `settings.recognition.openai.api_key`.\r\n- OpenAI Base URL:\r\n  - Поле \"OpenAI Base URL\" ↔ `settings.recognition.openai.base_url`.\r\n- Groq ASR model:\r\n  - Поле \"Groq ASR model\" ↔ `settings.recognition.groq.model`.\r\n- OpenAI ASR model:\r\n  - Поле \"OpenAI ASR model\" ↔ `settings.recognition.openai.model`.\r\n- Включение постпроцессинга:\r\n  - Чекбокс \"Включить постпроцессинг\" ↔ `settings.postprocess.enabled`.\r\n- Backend постпроцессинга:\r\n  - Комбо \"Сервис постпроцессинга\" ↔ `settings.postprocess.llm_backend`.\r\n- Groq LLM model:\r\n  - Поле \"Groq postprocess model\" ↔ `settings.recognition.groq.model_process`.\r\n- OpenAI LLM model:\r\n  - Поле \"OpenAI postprocess model\" ↔ `settings.recognition.openai.model_process`.\r\n\r\nСохранение — [`_build_new_settings`](src/ui/settings_dialog.py#L215):\r\n\r\n- Обновляет `RecognitionConfig`:\r\n  - `backend` из комбо.\r\n  - `openai.api_key`, `openai.base_url`, `openai.model`, `openai.model_process`.\r\n  - `groq.api_key`, `groq.model`, `groq.model_process`.\r\n- Обновляет `PostprocessConfig`:\r\n  - `enabled` из чекбокса.\r\n  - `llm_backend` из комбо.\r\n  - `groq.model` и `openai.model` как отображательные значения.\r\n\r\nТаким образом:\r\n\r\n- OpenAI Base URL в UI ↔ **только** `recognition.openai.base_url`.\r\n- LLM‑модели Groq/OpenAI в UI ↔ **только** `recognition.*.model_process`.\r\n\r\n---\r\n\r\n## Пайплайн распознавания и постпроцессинга\r\n\r\nОсновной класс приложения — [`App`](src/main.py#L18).\r\n\r\n### Загрузка настроек и компонентов\r\n\r\nВ конструкторе:\r\n\r\n1. Определяется `base_dir` (корень проекта или папка exe).\r\n2. Загружается `AppSettings` через [`_load_or_init_settings`](src/main.py#L349):\r\n   - Если `config.yaml` отсутствует — создаётся минимальный конфиг с `backend=local`.\r\n   - Затем вызывается [`AppSettings.load_default()`](src/config/settings.py#L132).\r\n3. Настраивается логирование [`setup_logging`](src/utils/logger.py#L1).\r\n4. Создаются:\r\n   - окно [`FloatingWindow`](src/ui/floating_window.py#L1),\r\n   - иконка в трее [`SystemTrayIcon`](src/ui/system_tray.py#L1),\r\n   - рекордер [`AudioRecorder`](src/audio/recorder.py#L1),\r\n   - распознаватель через фабрику [`create_recognizer`](src/recognition/__init__.py#L1).\r\n\r\n### Прокидывание настроек в TextPostprocessor\r\n\r\nКлючевой момент — блок в [`App.__init__`](src/main.py#L52) и [`App.open_settings_dialog`](src/main.py#L155):\r\n\r\n- Берём:\r\n  - `post_cfg = self.settings.postprocess`\r\n  - `rec_cfg = self.settings.recognition`\r\n- Для Groq LLM:\r\n  - `post_cfg.groq.api_key = rec_cfg.groq.api_key`\r\n  - `post_cfg.groq.model_process = rec_cfg.groq.model_process` (если пусто).\r\n- Для OpenAI LLM:\r\n  - `post_cfg.openai.api_key = rec_cfg.openai.api_key`\r\n  - `post_cfg.openai.model_process = rec_cfg.openai.model_process` (если пусто).\r\n  - `post_cfg.openai.base_url = rec_cfg.openai.base_url`.\r\n\r\nЗатем создаётся:\r\n\r\n- `self.postprocessor = TextPostprocessor(post_cfg)`.\r\n\r\nТаким образом, `TextPostprocessor` всегда видит:\r\n\r\n- API‑ключи из `recognition.*.api_key`.\r\n- LLM‑модели из `recognition.*.model_process`.\r\n- OpenAI Base URL из `recognition.openai.base_url`.\r\n\r\n### Каскад backend’ов распознавания\r\n\r\nМетод [`_process_audio`](src/main.py#L217):\r\n\r\n1. Собирает список backend’ов:\r\n   - сначала выбранный пользователем (`recognition.backend`),\r\n   - затем остальные (`[\"groq\", \"openai\", \"local\"]`) без дубликатов.\r\n2. Для каждого backend’а:\r\n   - временно подменяет `settings.recognition.backend`,\r\n   - создаёт recognizer через `create_recognizer`,\r\n   - вызывает `transcribe(audio_data)`.\r\n3. При успехе — выходит из цикла, при ошибке — логирует и пробует следующий backend.\r\n4. Если все упали — показывает последнюю ошибку.\r\n\r\nОсобенности локального backend’а GigaAM‑v3:\r\n\r\n- Реализован в [`GigaAMRecognizer`](src/recognition/gigaam_local.py#L12).\r\n- Использует только `model.transcribe(path)` без longform и без Hugging Face токена.\r\n- Перед вызовом `transcribe` оценивает длительность аудио:\r\n  - если длительность **> 25 секунд**, сразу выбрасывает контролируемый `RuntimeError(\"GigaAM-v3: аудио длиннее 25 секунд, используем облачный backend.\")`;\r\n  - это приводит к тому, что `_process_audio` переходит к следующему backend’у (обычно Groq).\r\n- Если сама модель GigaAM возвращает ошибку `\"Too long wav file, use 'transcribe_longform' method.\"`, она также заворачивается в `RuntimeError`, и каскад переходит к Groq/OpenAI.\r\n- Таким образом, локальный GigaAM используется только для коротких запросов (до ~25 секунд), а длинные автоматически обрабатываются облаком.\r\n\r\n### OpenAI ASR\r\n\r\nРеализован в [`OpenAIWhisperRecognizer`](src/recognition/openai_api.py#L19):\r\n\r\n- URL строится в [`_build_url`](src/recognition/openai_api.py#L36):\r\n\r\n  ```python\r\n  base = (self.config.base_url or \"\").strip()\r\n  if not base:\r\n      raise RuntimeError(\"OpenAI ASR: base_url не задан. Укажите 'OpenAI Base URL' в настройках.\")\r\n  base = base.rstrip(\"/\")\r\n  return f\"{base}{OPENAI_TRANSCRIBE_PATH}\"  # \"/audio/transcriptions\"\r\n  ```\r\n\r\n- Использует:\r\n  - `recognition.openai.api_key`,\r\n  - `recognition.openai.model`,\r\n  - `recognition.openai.language`,\r\n  - `recognition.openai.base_url`.\r\n\r\n### LLM‑постпроцессинг\r\n\r\nРеализован в [`TextPostprocessor`](src/recognition/postprocessor.py#L13).\r\n\r\nРежимы:\r\n\r\n- `enabled = False` → возвращает текст как есть.\r\n- `mode = \"simple\"` → только regex‑очистка [`_simple_cleanup`](src/recognition/postprocessor.py#L72).\r\n- `mode = \"llm\"` → regex + LLM.\r\n\r\n#### Общая логика\r\n\r\nМетод [`process`](src/recognition/postprocessor.py#L28):\r\n\r\n1. Если `enabled` = False → `_simple_cleanup`.\r\n2. Если `mode` = `\"simple\"` → `_simple_cleanup`.\r\n3. Иначе:\r\n   - делает `_simple_cleanup`,\r\n   - проверяет наличие API‑ключа для выбранного backend’а:\r\n     - Groq: `self.config.groq.api_key`,\r\n     - OpenAI: `self.config.openai.api_key`.\r\n   - если ключ пустой — логирует предупреждение и возвращает regex‑вариант.\r\n   - иначе вызывает [`_llm_cleanup`](src/recognition/postprocessor.py#L90).\r\n4. Любые исключения из LLM‑части ловятся, логируются, и возвращается regex‑вариант (UX не ломается).\r\n\r\n#### Groq LLM\r\n\r\n[`_llm_groq`](src/recognition/postprocessor.py#L108):\r\n\r\n- API‑ключ: `self.config.groq.api_key` (из `recognition.groq.api_key`).\r\n- Модель: `self.config.groq.model_process` (из `recognition.groq.model_process`).\r\n- URL: жёстко `https://api.groq.com/openai/v1/chat/completions`.\r\n- Логирует:\r\n  - модель,\r\n  - ошибки таймаута/сети/HTTP.\r\n\r\n#### OpenAI LLM\r\n\r\n[`_llm_openai`](src/recognition/postprocessor.py#L212):\r\n\r\n- API‑ключ: `self.config.openai.api_key` (из `recognition.openai.api_key`).\r\n- Модель:\r\n  - сначала `self.config.openai.model_process`,\r\n  - fallback на `self.config.openai.model`,\r\n  - если обе пустые — явная ошибка конфигурации.\r\n- Base URL:\r\n  - `self.config.openai.base_url` (из `recognition.openai.base_url`, прокинутый через `App`).\r\n  - если пустой — явная ошибка конфигурации.\r\n- URL: `base_url.rstrip(\"/\") + \"/chat/completions\"`.\r\n- Логирует:\r\n  - фактический URL,\r\n  - модель,\r\n  - первые 8 символов ключа (маскировано).\r\n\r\n**Важно:** в коде **нет** дефолтного `https://api.openai.com/v1`. Если `base_url` не задан — это ошибка конфигурации, а не скрытый дефолт.\r\n\r\n---\r\n\r\n## Логирование\r\n\r\nИспользуется [`loguru`](src/utils/logger.py#L1).\r\n\r\nКлючевые сообщения:\r\n\r\n- При распознавании:\r\n  - `Trying recognition backend: {backend}`\r\n  - `Recognition succeeded with backend: {backend}`\r\n- При LLM‑постпроцессинге:\r\n  - Groq:\r\n    - `Groq LLM postprocess using model: {model}`\r\n    - ошибки таймаута/сети/HTTP с указанием модели.\r\n  - OpenAI:\r\n    - `OpenAI LLM postprocess URL: {url}`\r\n    - `OpenAI LLM postprocess using model: {model}`\r\n    - `OpenAI LLM postprocess using api_key (first 8 chars): {prefix}***`\r\n- При ошибках LLM:\r\n  - `LLM postprocess failed, fallback to regex-only: {exc}`.\r\n\r\n---\r\n\r\n## Как использовать\r\n\r\n### Установка\r\n\r\n```bash\r\npip install -r requirements.txt\r\n```\r\n\r\n### Запуск\r\n\r\n```bash\r\npython src/main.py\r\n```\r\n\r\nПри первом запуске:\r\n\r\n- создастся `config.yaml` в корне;\r\n- backend по умолчанию — `local` (GigaAM);\r\n- локальный GigaAM будет использоваться только для коротких записей (до ~25 секунд);\r\n- для Groq/OpenAI нужно будет вручную ввести ключи и (для OpenAI) `base_url`.\r\n\r\n### Настройка backend’ов\r\n\r\n1. Открыть окно настроек (иконка ⚙️).\r\n2. В блоке \"Сервис распознавания\":\r\n   - выбрать `Groq` или `OpenAI` или `GigaAM-v3 (local)`;\r\n   - заполнить `Groq API key` и/или `OpenAI API key`;\r\n   - для OpenAI указать `OpenAI Base URL` (например, `https://api.voidai.app/v1`).\r\n3. В блоке \"Модели распознавания (ASR)\":\r\n   - указать модели Groq/OpenAI ASR.\r\n4. В блоке \"Постобработка текста (LLM)\":\r\n   - включить чекбокс \"Включить постпроцессинг\";\r\n   - выбрать backend постпроцессинга (`Groq` или `OpenAI`);\r\n   - указать модели LLM:\r\n     - `Groq postprocess model` ↔ `recognition.groq.model_process`;\r\n     - `OpenAI postprocess model` ↔ `recognition.openai.model_process`.\r\n5. Нажать OK — настройки сохранятся в `config.yaml`, recognizer и postprocessor будут пересозданы.\r\n\r\n---\r\n\r\n## Тестирование LLM‑постпроцессинга\r\n\r\nЕсть отдельный скрипт [`tests/manual_llm_test.py`](tests/manual_llm_test.py#L1):\r\n\r\n```bash\r\npython tests/manual_llm_test.py\r\n```\r\n\r\nОн:\r\n\r\n- загружает `AppSettings` так же, как основное приложение;\r\n- печатает текущие настройки LLM;\r\n- создаёт `TextPostprocessor` и прогоняет тестовый текст;\r\n- показывает, сработал ли LLM или был fallback на исходный текст.\r\n\r\n---\r\n\r\n## GitHub\r\n\r\nПроект рассчитан на выкладку в публичный репозиторий GitHub. Для этого:\r\n\r\n1. Убедитесь, что `config.yaml` добавлен в `.gitignore` и не содержит реальных ключей.\r\n2. В README (этот файл) описана актуальная архитектура конфигурации и пайплайна.\r\n3. Для публикации:\r\n   - создайте репозиторий на GitHub;\r\n   - добавьте этот проект;\r\n   - запушьте изменения.\r\n\r\n---\r\n\r\n# VoiceCapture (EN)\r\n\r\n## Overview\r\n\r\nVoiceCapture is a Windows desktop utility that:\r\n\r\n- records your voice using a global hotkey;\r\n- sends audio to a selected recognition backend (Groq / OpenAI / local GigaAM);\r\n- optionally runs the text through an LLM post‑processor (Groq or OpenAI);\r\n- copies the final text to the clipboard and auto‑pastes it (Ctrl+V).\r\n\r\nIn the final version:\r\n\r\n- the local GigaAM‑v3 backend is used only for short audio (up to ~25 seconds);\r\n- longer recordings are automatically handled by cloud backends (Groq/OpenAI);\r\n- there is no Hugging Face token or longform integration in the app code.\r\n\r\nCurrent version goals:\r\n\r\n- a single, predictable `config.yaml`;\r\n- correct behavior of all ASR and LLM backends (Groq/OpenAI/local);\r\n- consistent settings dialog behavior;\r\n- a clean, debuggable recognition + post‑processing pipeline.\r\n\r\n---\r\n\r\n## Configuration Architecture\r\n\r\n### Single config file\r\n\r\nAll settings live in a single file:\r\n\r\n- `config.yaml` in the project root (next to `src/` and `requirements.txt`).\r\n\r\nLoading/saving is implemented in [`AppSettings.load_default()`](src/config/settings.py#L132) and [`AppSettings.save_default()`](src/config/settings.py#L277).\r\n\r\nOn first run, if `config.yaml` does not exist, it is created with safe defaults (see [`App._load_or_init_settings()`](src/main.py#L349)).\r\n\r\n### AppSettings structure\r\n\r\nMain settings dataclass: [`AppSettings`](src/config/settings.py#L121).\r\n\r\nImportant blocks:\r\n\r\n- `app`, `hotkeys`, `audio`, `ui`, `logging` — straightforward.\r\n- `recognition` — all ASR and LLM **keys/models/URLs** live here.\r\n- `postprocess` — only flags and display models, no keys or URLs.\r\n\r\nSee the YAML example above in the Russian section; it is the same structure.\r\n\r\n#### recognition.*\r\n\r\nDefined in:\r\n\r\n- [`OpenAIRecognitionConfig`](src/config/settings.py#L52)\r\n- [`GroqRecognitionConfig`](src/config/settings.py#L62)\r\n- [`LocalRecognitionConfig`](src/config/settings.py#L42)\r\n- [`RecognitionConfig`](src/config/settings.py#L73)\r\n\r\nKey fields:\r\n\r\n- `recognition.backend` — current ASR backend (`groq` / `openai` / `local`).\r\n- `recognition.openai`:\r\n  - `api_key` — OpenAI‑compatible (or proxy) API key.\r\n  - `model` — ASR model (e.g. `gpt-4o-transcribe`).\r\n  - `model_process` — LLM model for post‑processing (e.g. `gpt-5.1`).\r\n  - `language` — recognition language.\r\n  - `base_url` — **single** source of truth for OpenAI base URL (used by both ASR and LLM).\r\n- `recognition.groq`:\r\n  - `api_key` — Groq key.\r\n  - `model` — ASR model (`whisper-large-v3`).\r\n  - `model_process` — LLM model (`moonshotai/kimi-k2-instruct`).\r\n  - `language` — recognition language.\r\n\r\n#### postprocess.*\r\n\r\nDefined in:\r\n\r\n- [`GroqPostprocessConfig`](src/config/settings.py#L84)\r\n- [`OpenAIPostprocessConfig`](src/config/settings.py#L88)\r\n- [`PostprocessConfig`](src/config/settings.py#L93)\r\n\r\nContains only:\r\n\r\n- `enabled` — whether post‑processing is enabled.\r\n- `mode` — `\"simple\"` (regex only) or `\"llm\"` (regex + LLM).\r\n- `llm_backend` — `\"groq\"` or `\"openai\"`.\r\n- `groq.model` — display Groq LLM model.\r\n- `openai.model` — display OpenAI LLM model.\r\n\r\n**Important:** `postprocess.*` does **not** contain:\r\n\r\n- `api_key`\r\n- `model_process`\r\n- `base_url`\r\n\r\nAll keys, LLM models and URLs live in `recognition.*`.\r\n\r\nOn load, [`AppSettings.load_default()`](src/config/settings.py#L229) drops any legacy `api_key`, `model`, `model_process`, `base_url` fields from `postprocess.groq` and `postprocess.openai`.\r\n\r\n---\r\n\r\n## Settings Dialog\r\n\r\nImplemented in [`SettingsDialog`](src/ui/settings_dialog.py#L22).\r\n\r\n### UI ↔ AppSettings mapping\r\n\r\nLoading from settings — [`_load_from_settings`](src/ui/settings_dialog.py#L172):\r\n\r\n- Recognition service combo ↔ `settings.recognition.backend`.\r\n- Groq API key field ↔ `settings.recognition.groq.api_key`.\r\n- OpenAI API key field ↔ `settings.recognition.openai.api_key`.\r\n- OpenAI Base URL field ↔ `settings.recognition.openai.base_url`.\r\n- Groq ASR model field ↔ `settings.recognition.groq.model`.\r\n- OpenAI ASR model field ↔ `settings.recognition.openai.model`.\r\n- Postprocess enabled checkbox ↔ `settings.postprocess.enabled`.\r\n- Postprocess backend combo ↔ `settings.postprocess.llm_backend`.\r\n- Groq postprocess model field ↔ `settings.recognition.groq.model_process`.\r\n- OpenAI postprocess model field ↔ `settings.recognition.openai.model_process`.\r\n\r\nSaving — [`_build_new_settings`](src/ui/settings_dialog.py#L215):\r\n\r\n- Updates `RecognitionConfig` with API keys, base URL, ASR models and LLM models.\r\n- Updates `PostprocessConfig` with:\r\n  - `enabled`, `llm_backend`,\r\n  - display models `groq.model` and `openai.model`.\r\n\r\nSo:\r\n\r\n- OpenAI Base URL in UI ↔ **only** `recognition.openai.base_url`.\r\n- Groq/OpenAI LLM models in UI ↔ **only** `recognition.*.model_process`.\r\n\r\n---\r\n\r\n## Recognition and Post‑processing Pipeline\r\n\r\nMain application class — [`App`](src/main.py#L18).\r\n\r\n### Settings and components\r\n\r\nIn `__init__`:\r\n\r\n1. Determine `base_dir` (project root or exe folder).\r\n2. Load `AppSettings` via [`_load_or_init_settings`](src/main.py#L349).\r\n3. Configure logging via [`setup_logging`](src/utils/logger.py#L1).\r\n4. Create:\r\n   - main window [`FloatingWindow`](src/ui/floating_window.py#L1),\r\n   - tray icon [`SystemTrayIcon`](src/ui/system_tray.py#L1),\r\n   - recorder [`AudioRecorder`](src/audio/recorder.py#L1),\r\n   - recognizer via [`create_recognizer`](src/recognition/__init__.py#L1).\r\n\r\n### Wiring settings into TextPostprocessor\r\n\r\nIn both [`App.__init__`](src/main.py#L52) and [`App.open_settings_dialog`](src/main.py#L155):\r\n\r\n- `post_cfg = self.settings.postprocess`\r\n- `rec_cfg = self.settings.recognition`\r\n\r\nFor Groq LLM:\r\n\r\n- `post_cfg.groq.api_key = rec_cfg.groq.api_key`\r\n- `post_cfg.groq.model_process = rec_cfg.groq.model_process` (if empty).\r\n\r\nFor OpenAI LLM:\r\n\r\n- `post_cfg.openai.api_key = rec_cfg.openai.api_key`\r\n- `post_cfg.openai.model_process = rec_cfg.openai.model_process` (if empty).\r\n- `post_cfg.openai.base_url = rec_cfg.openai.base_url`.\r\n\r\nThen:\r\n\r\n- `self.postprocessor = TextPostprocessor(post_cfg)`.\r\n\r\nThus `TextPostprocessor` always sees:\r\n\r\n- API keys from `recognition.*.api_key`,\r\n- LLM models from `recognition.*.model_process`,\r\n- OpenAI base URL from `recognition.openai.base_url`.\r\n\r\n### Backend cascade\r\n\r\n[`_process_audio`](src/main.py#L217):\r\n\r\n- Builds an ordered list of backends:\r\n  - primary from `recognition.backend`,\r\n  - then `[\"groq\", \"openai\", \"local\"]` without duplicates.\r\n- For each backend:\r\n  - temporarily sets `settings.recognition.backend`,\r\n  - creates recognizer via `create_recognizer`,\r\n  - calls `transcribe(audio_data)`.\r\n- On success — stops; on error — logs and tries next backend.\r\n- If all fail — shows the last error.\r\n\r\n### OpenAI ASR\r\n\r\n[`OpenAIWhisperRecognizer`](src/recognition/openai_api.py#L19):\r\n\r\n- `_build_url()` uses only `recognition.openai.base_url`:\r\n  - if empty → configuration error.\r\n  - otherwise → `base_url.rstrip(\"/\") + \"/audio/transcriptions\"`.\r\n\r\n### LLM Post‑processing\r\n\r\n[`TextPostprocessor`](src/recognition/postprocessor.py#L13):\r\n\r\n- `enabled = False` → original text.\r\n- `mode = \"simple\"` → regex only.\r\n- `mode = \"llm\"` → regex + LLM.\r\n\r\nCommon logic in [`process`](src/recognition/postprocessor.py#L28):\r\n\r\n- If no API key for selected backend → warning + regex only.\r\n- Any LLM exception → logged + regex only.\r\n\r\nGroq LLM — [`_llm_groq`](src/recognition/postprocessor.py#L108):\r\n\r\n- API key from `recognition.groq.api_key`.\r\n- Model from `recognition.groq.model_process`.\r\n- URL: `https://api.groq.com/openai/v1/chat/completions`.\r\n\r\nOpenAI LLM — [`_llm_openai`](src/recognition/postprocessor.py#L212):\r\n\r\n- API key from `recognition.openai.api_key`.\r\n- Model from `recognition.openai.model_process` with fallback to `recognition.openai.model`.\r\n- Base URL from `recognition.openai.base_url` (wired via `post_cfg.openai.base_url`).\r\n- URL: `base_url.rstrip(\"/\") + \"/chat/completions\"`.\r\n- No hardcoded `https://api.openai.com/v1` anywhere.\r\n\r\n---\r\n\r\n## Logging\r\n\r\nUsing [`loguru`](src/utils/logger.py#L1).\r\n\r\nKey logs:\r\n\r\n- ASR:\r\n  - `Trying recognition backend: {backend}`\r\n  - `Recognition succeeded with backend: {backend}`\r\n- LLM:\r\n  - Groq:\r\n    - `Groq LLM postprocess using model: {model}`\r\n    - detailed timeout/network/HTTP errors.\r\n  - OpenAI:\r\n    - `OpenAI LLM postprocess URL: {url}`\r\n    - `OpenAI LLM postprocess using model: {model}`\r\n    - `OpenAI LLM postprocess using api_key (first 8 chars): {prefix}***`\r\n- Fallback:\r\n  - `LLM postprocess failed, fallback to regex-only: {exc}`.\r\n\r\n---\r\n\r\n## Usage\r\n\r\n### Install\r\n\r\n```bash\r\npip install -r requirements.txt\r\n```\r\n\r\n### Run\r\n\r\n```bash\r\npython src/main.py\r\n```\r\n\r\nOn first run:\r\n\r\n- `config.yaml` is created in the project root.\r\n- Default backend is `local` (GigaAM).\r\n- Local GigaAM is used only for short recordings (up to ~25 seconds); longer ones will fall back to Groq/OpenAI.\r\n- You must manually set API keys and (for OpenAI) `base_url`.\r\n\r\n### Configure backends\r\n\r\n1. Open settings dialog (⚙️).\r\n2. In \"Recognition service\":\r\n   - choose `Groq`, `OpenAI` or `GigaAM-v3 (local)`;\r\n   - fill `Groq API key` and/or `OpenAI API key`;\r\n   - for OpenAI, set `OpenAI Base URL` (e.g. `https://api.voidai.app/v1`).\r\n3. In \"ASR models\":\r\n   - set Groq/OpenAI ASR models.\r\n4. In \"Text post‑processing (LLM)\":\r\n   - enable \"Enable postprocessing\";\r\n   - choose postprocess backend (`Groq` or `OpenAI`);\r\n   - set LLM models:\r\n     - `Groq postprocess model` ↔ `recognition.groq.model_process`;\r\n     - `OpenAI postprocess model` ↔ `recognition.openai.model_process`.\r\n5. Click OK — settings are saved to `config.yaml`, recognizer and postprocessor are recreated.\r\n\r\n---\r\n\r\n## Manual LLM test\r\n\r\nUse [`tests/manual_llm_test.py`](tests/manual_llm_test.py#L1):\r\n\r\n```bash\r\npython tests/manual_llm_test.py\r\n```\r\n\r\nIt:\r\n\r\n- loads `AppSettings` the same way as the app;\r\n- prints current LLM settings;\r\n- runs `TextPostprocessor.process()` on a test string;\r\n- shows whether LLM actually changed the text or fallback was used.\r\n\r\n---\r\n\r\n## GitHub\r\n\r\nTo publish this project on GitHub:\r\n\r\n1. Ensure `config.yaml` is in `.gitignore` and does not contain real API keys.\r\n2. Commit the source code and this updated `README.md`.\r\n3. Push to your GitHub repository.\r\n\r\nThis README describes the current configuration model and the recognition + post‑processing pipeline, including the unified handling of OpenAI/Groq backends and the single source of truth for `base_url` and models."
        }
    ]
}